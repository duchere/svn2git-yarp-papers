
\section{Discussion and Conclusions}

In this paper, we showed how causality can be probed at different
levels by the robot.  Initially the environment was the body of the
robot itself, then later a carefully circumscribed interaction with
the outside world.  This is reminiscent of Piaget's distinction
between primary and secondary circular
reactions~\cite{ginsburg78piaget}.  Objects are central to interacting
with the outside world.  We raised the issue of how an agent can
autonomously acquire a working definition of objects. 

In computer vision there is much to be gained by bringing a
manipulator into the equation.  Many variants and extensions to the
experimental ``poking'' strategy explored here are possible.  For
example, a robot might try to move an arm around {\em behind} the
object.  As the arm moves behind the object, it reveals its occluding
boundary.  This is a precursor to visually extracting shape
information while actually manipulating an object, which is more
complex since the object is also being moved and partially occluded by
the manipulator.  Another possible strategy that could be adopted as a
last resort for a confusing object might be to simply hit it firmly,
in the hopes of moving it some distance and potentially overcoming
local, accidental visual ambiguity.  Obviously this strategy cannot
always be used!  But there is plenty of room to be creative here.
%
%
\ifrev
%
There are also limitations in our current implementation that could
usefully be addressed.
%
The robot itself is not mobile, so its workspace is limited.  
%
There are also many constraints on the arm that make fine 
motor control impossible -- it cannot maintain all reachable 
poses indefinitely, and there is significant noise and some 
hysteresis in its analog sensors.
%
The robot will only attempt to reach towards a target that is 
actually accessible to its arm -- not too close, not too far, 
as determined using visual disparity.  In practice, this 
means that the ideal workspace is a table in front of the 
robot, and the motor control of the robot has been 
specifically tuned to work well in that situation.
%
A simple attention system and tracking mechanism are used to 
bring the robot's attention to a target.  This phase can fail 
if the robot gets distracted by some more salient (but 
unreachable) part of the scene.
%
Objects that move together are not individually segmented.
%
And segmentation does not always succeed, due to shadows,
or strong nearby edges.
%
\fi

\ifrev
In spite of some limitations, the robotic experiments support the view that reaching, grasping, and recognition
\else
The robotic experiments support the view that reaching, grasping, and recognition
\fi
can be learned by following a particular ontogenetic pathway without the
intervention of an external teacher.
This pathway is consistent with and inspired by what is
known of this process in biological systems (primates/mammals).
%although this evidence is rather sparse.
%
We have endeavored to build from as few innate components as possible, to
elucidate the visual and motor challenges faced by a learning robot rather
than simply solving them by fiat.
%
%There is relatively little evidence to work with, but it is at least clear that the 
%sequence of events leading to object manipulation/recognition cannot take
%an arbitrary form unless we assume that some/many of its components are innate.
Although newborns show amazing abilities \cite{spelke-2000} such as early imitation 
\cite{meltzoff-moore-1977}, face detection, etc, there is also evidence 
that the maturation of the brain is far from complete at birth and
complex perceptual abilities require a long time to emerge \cite{kovacs00human}.
%
We have given a simple existence proof that object segmentation,
recognition and localization can develop without any prior knowledge
of visual appearance.  We have also shown that, without any prior
knowledge of the human form, the robot can identify episodes when a
human is manipulating objects that are familiar to the robot purely by
the operational similarity of the human arm and its own manipulator in
this situation.  We believe such demonstrations are important both in
their own right, and in their elucidation of a concrete series of
steps that lead to a desired behavior.  This may serve a useful
reference point from which to investigate the biological solution to
the same problem -- although it can't provide the answers, it can at
least suggests useful questions.

%
%This is important, since segmentation and recognition as usually expressed 
%suffer from a chicken-and-egg problem, where views of an object must be
%segmented before its appearance can be learned...

%We cannot claim that this is the only possible view but it is certainly one worth
%investigating. Rephrasing Berkeley we can say:
%\begin{quote}
%...objects can only be known by
%\emph{action}. Vision is subject to illusions, 
%which arise from \emph{many different} problems...
%\end{quote}
%that AI guys know far too well

%Could relate some of this to the embodied intelligence ideas
%of Brooks... particularly the working hypothesis.

