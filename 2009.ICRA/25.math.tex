\subsection{Background}

Assume $\{\xx_i,y_i\}_{i=1}^l$, with $\xx_i \in \RR^m$ and $y_i \in
\{-1,1\}$, is a set of samples drawn from an unknown probability
distribution. We want to find a function $f(\xx)$ such that
$sgn(f(\xx))$ best determines the category of any future sample $\xx$
drawn from the same distribution. In Least-Squares Support Vector Machine (LS-SVM)
we construct a linear model $f(\xx)=\ww \cdot \phi(\xx) + b$, where
$\phi(\xx)$ is a non-linear function that maps the data in a fixed feature space.
However, rather than specifying the feature space directly,
it can be implied by a kernel function $K(\xx,\xx')$, giving the
inner product between the images of vectors in the feature
space, i.e. $K(\xx,\xx')=\phi(\xx) \cdot \phi(\xx')$.
A common kernel function is the isotropic Gaussian kernel
\begin{equation}
	K(\xx,\xx')=\exp(-\gamma ||x-x'||^2)
	\label{eq:rbf}
\end{equation}
that will be used in all our experiments.

The solution is found minimizing a regularized least-squares loss function \cite{Cristianini00}.
This approach is similar to the well-known formulation of Support Vector
Machines. The difference is that the loss function is the least square and it
does not induce a sparse solution. On the other hand it is possible to write
the leave-one-out error in closed form \cite{Rifkin07}. This is known to be
approximately an unbiased estimator of the classifier generalization error
\cite{LuntzB69}. This property is useful to find the best parameters for the
learning (e.g. $\gamma$ in (\ref{eq:rbf})) and it will be used in our
adaptation method.

\subsection{Model Adaptation}

We assume the system has some kind of previous model trained off-line on a big
number of auxiliary data. The system then starts acquiring new data, that are
assumed to come from a distribution that is close to the distribution of the
auxiliary data. Our desire is that using the auxiliary data should learn faster
than using the new data alone. Moreover the adaptation should use only the new
data for training 

Our formulation for the adaptation is similar to the one proposed in
\cite{YangYH07}.
We generalize their approach introducing a scaling factor for the previous
model and changing the loss into the standard square loss.
So we obtain the following optimization problem
\begin{align}
\min_{\ww} \frac{1}{2} \|\ww- \beta \ww'\|^2 + \frac{C}{2} \sum_{i=1}^N \xi^2 \\
subject to \ y_i = w \phi(\xx_i) + b + \xi_i
\label{eq:opt_prob}
\end{align}
\noindent where $\ww'$ is the previous model.
It is easy to show that the optimal solution is the form
\begin{equation}
\ww = \beta \ww' + \sum_{i=1}^N \alpha_i \xx_i, \alpha_i \in \RR
\end{equation}
\noindent hence the final solution is composed by the sum of the previous model
scaled by the parameter $\beta$, and a new model given by the new data points.
The introduction of the parameter $\beta$ introduces a degree of freedom that
can be used to downweight the importance of the previous model. When $\beta$
is $0$ we recover the original LS-SVM formulation, without any adaptation to
the previous data.
In the following we will show how it is possible to tune automatically this
parameter, without any additional computational cost and in a principled way.
As said before, with LS-SVM it is possible to write the leave-one-out error
in a closed form. It turns out that it is possible to do the same if with the
modified formulation (\ref{eq:opt_prob}). Hence it is possible to found the
parameter $\beta$ in order to minimize the leave-one-out error. In particular
for regression there is a closed formula for the optimal $\beta$.

Note that the previous model $\ww'$ can be obtained by any training algorithm,
as far as it can be expressed as a weighted sum of kernel functions.

We can generalize this approach even more and instead of considering only a
previous model, we suppose that we have many of them $\ww_i$. Again using the
closed formula of the leave-one-out we can at the same time chose the best
model $\ww_i$ for adaptation and its scaling factor $\beta$.