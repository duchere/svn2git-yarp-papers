In the framework of robotics for prosthetics, it is nowadays possible
to build mechanically advanced prostheses such as, e.g., mechanical
hands able to replicate a fair amount of the movements required by the
disabled to carry on living in a decent way. Attempts in this sense
include, e.g., the CyberHand porject \cite{...} and the i-LIMB hand by
Touch Bionics \cite{}. Still, a general sense of frustration impends,
as far as control is concerned. How is an amputee supposed to command
the prosthesis what to do (i.e., how to grasp an object) and with what
force (i.e., grasping a hammer or lifting an egg)?

To this end, two types of interfaces between the user's nervous system
and the prosthesis have been developed: \emph{invasive} and
\emph{non-invasive}. The former are supposed to guarantee a finer and
more precise control since they are based upon signals gathered from
the peripehric nervous system with surgical devices such as muscular
electrodes or brain implants; but on the other hand they require a lot
of work for the implantation and to ensure sterility.  The latter are
obviously easier to handle, manufacture and implant, but require a
much better signal conditioning, since they usually work with surface
(skin) signals or more advanced devices such as vision and gaze
tracking.

In the context of non-invasive interfaces for controlling mechanical
hands, a concrete possibility arises from \emph{forearm surface
electromyography (EMG)}, a technique by which muscle activation
potentials are gathered by electrodes placed on the patient's forearm
skin; these potentials are supposed to indicate what muscles the
patient is trying to activate, and with how much force. Surface EMG
is, in principle, a cheap and easy way of detecting what the patient
wants the prosthesis to do. Still, the EMG signal suffers from a
number of problems, among which the placement of the electrodes (which
cannot be supposed to be always precisely the same), signal drifting
and change due to sweat formation and muscular fatigue and
cross-talking among deep and superficial muscles. Therefore, willing
to build a \emph{map} relating EMG activation potentials and muscle
force (and therefore hand finger movements), one must resort to
advanced mathematical techniques.

In this paper, we pursue the approach based upon \emph{machine
learning} techniques already attmepted in, e.g., \cite{smagt}. Machine
learning methods aim at approximating a map such as the one described
above by choosing a function in a suitable functional space, based
upon a number \emph{example} known values. If the choice is good,
further points in the input space (in this case, EMG potential values)
can be predicted on-line, and the patient's intention to move a muscle
reconstructed.

So far, in literature, machine learning applied to surface EMG has
been able to \emph{classify} different postures of the hand. For
example, the surface EMG signal can be used ot detect whether the
patient is attempting a cylindric grasp or a two-finger grip \cite{};
but no indication about the amount of force involved in the grasping
act is detected, so that it is impossible to distinguish between,
e.g., a power grasp and a precision grip. Note that this is crucial in
everyday life, since applying the same amount of force while grasping
a hammer or an egg would result in slippage of the hammer or, worse,
breaking the egg.

We show here a detailed comparative analysis of what machine learning
can do when applied to such a problem. Over two days, we have gathered
forearm surface EMG data coming from an able-bodied subject while
gripping in four distinct ways a force sensor; we have then trained
three different machine learning systems to guess, from the EMG
signal,

\begin{enumerate}

  \item what kind of grasp the subject was doing, e.g., thumb and index
    finger, thumb and middle finger, thumb and ring finger or thumb
    and all other fingers; and

  \item how much force the subject was applying to the sensor, in
    order to understand whether the grasp was a power grasp or rather
    a precision grip.

\end{enumerate}

The three approaches we have experimented with are: $(a)$ a simple
feed-forward neural network with one hidden layer, $(b)$ a Support
Vector Machine with radial basis function kernel, $(c)$ Locally
Weighted Projection Regression. All approaches were trained on a
massive amount of data, but bearing in mind the following important
point: in a real setting, that is, when a patient is required to train
the prosthesis, training must eventually stop and the model so
obtained must give good prediction results for a long time --- picture
the ideal scenario in which training happens in the first day of use,
and then the prosthesis must be used in the following months or years
by the same person.

This has involved a careful analysis of the short- and medium-term
changes in the EMG signal coming from the same subject. In other
words, the correct way of \emph{sampling in the input space in a reasonable
amount of time} must be found. We are not yet in the position of
drawing rigorous conclusions about this, but it seems that a sensible
way ahead has been found.

Our numerical results indicate that, at best, a simple
one-hidden-layer neural network can reconstruct the type of grasp with
an accuracy of up to XX\%, and the applied force with an error of, at
best, XX Newtons over a range of about $50$N. The other approaches
yield slightly worse results, but are anyway usable, which seems to
indicate that machine learning as a whole is a viable approach.  All
in all, this looks highly encouraging in applying machine learning to
enable amputees gain a fine control over their prosthesis, also since
it is well-known \cite{...} that a remarkable amount of muscle
plasticity is still available in an arm stump, also several years
after the amputation.
