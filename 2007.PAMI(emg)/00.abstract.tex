One of the major problems when dealing with highly dexterous, active
hand prosthesis is their control by the patient wearing it. With the
advances in mechatronics, building prosthetic hands with multiple
active degrees of freedom is realisable, but actively controlling the
position and especially the exerted force of each finger cannot yet
be done naturally.

This paper deals with advanced robotic hand control via surface
electromyography (EMG). Building upon recent results, we show that
machine learning, together with a simple downsampling algorithm, can
be effectively used to control on-line, in real time, finger position
as well as finger force of a highly dexterous robotic hand. The system
determines the type of grasp a human subject is willing to use, and
the required amount of force involved, with a high degree of accuracy.

This represents a remarkable improvement with respect to the
state-of-the-art of feed-forward control of dexterous mechanical
hands, and opens up a scenario in which patients will be able to
control hand prostheses in a much finer way than it has so far been
possible.
