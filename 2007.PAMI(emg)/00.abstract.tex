One of the major problems when dealing with highly dexterous, active hand
prosthesis is their control by the patient wearing it. With the advances
in mechatronics, building prosthetic hands with multiple active degrees of
freedom is realisable, but actively controlling the position and especially
the exerted force of each finger cannot yet intuitively be done.

This paper deals with advanced robotic hand control via surface electromyography (EMG).
Building upon recent results, we show that machine learning,
together with a simple downsampling algorithm, can be effectively used
to control on-line, in real time, finger position as well as finger force
of a highly dexterous robotic hand. The
system determines the type of grasp a human subject is willing to use,
and the required amount of force involved, with a remarkable degree of
accuracy.

This paves the way for a better control of advanced hand prostheses
and opens up a scenario in which life conditions of amputees can be
effectively improved with respect to the state of the art.  Furthermore, it allows for the use of EMG
in teleoperation scenarios, in which force control is a required mode of operation.

