% This paper can be formatted using the peerreviewca
% (instead of conference) mode.
\documentclass[conference]{IEEEtran}
\usepackage{cite}      % Written by Donald Arseneau
                        % V1.6 and later of IEEEtran pre-defines the format
                        % of the cite.sty package \cite{} output to follow
                        % that of IEEE. Loading the cite package will
                        % result in citation numbers being automatically
                        % sorted and properly "ranged". i.e.,
                        % [1], [9], [2], [7], [5], [6]
                        % (without using cite.sty)
                        % will become:
                        % [1], [2], [5]--[7], [9] (using cite.sty)
                        % cite.sty's \cite will automatically add leading
                        % space, if needed. Use cite.sty's noadjust option
                        % (cite.sty V3.8 and later) if you want to turn this
                        % off. cite.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/cite/

\usepackage{graphicx}  % Written by David Carlisle and Sebastian Rahtz
                        % Required if you want graphics, photos, etc.
                        % graphicx.sty is already installed on most LaTeX
                        % systems. The latest version and documentation can
                        % be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
                        % Another good source of documentation is "Using
                        % Imported Graphics in LaTeX2e" by Keith Reckdahl
                        % which can be found as esplatex.ps and epslatex.pdf
                        % at: http://www.ctan.org/tex-archive/info/

%\usepackage{psfrag}    % Written by Craig Barratt, Michael C. Grant,
                        % and David Carlisle
                        % This package allows you to substitute LaTeX
                        % commands for text in imported EPS graphic files.
                        % In this way, LaTeX symbols can be placed into
                        % graphics that have been generated by other
                        % applications. You must use latex->dvips->ps2pdf
                        % workflow (not direct pdf output from pdflatex) if
                        % you wish to use this capability because it works
                        % via some PostScript tricks. Alternatively, the
                        % graphics could be processed as separate files via
                        % psfrag and dvips, then converted to PDF for
                        % inclusion in the main file which uses pdflatex.
                        % Docs are in "The PSfrag System" by Michael C. Grant
                        % and David Carlisle. There is also some information 
                        % about using psfrag in "Using Imported Graphics in
                        % LaTeX2e" by Keith Reckdahl which documents the
                        % graphicx package (see above). The psfrag package
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/psfrag/

%\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/

%\usepackage{url}       % Written by Donald Arseneau
                        % Provides better support for handling and breaking
                        % URLs. url.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/other/misc/
                        % Read the url.sty source comments for usage information.

%\usepackage{stfloats}  % Written by Sigitas Tolusis
                        % Gives LaTeX2e the ability to do double column
                        % floats at the bottom of the page as well as the top.
                        % (e.g., "\begin{figure*}[!b]" is not normally
                        % possible in LaTeX2e). This is an invasive package
                        % which rewrites many portions of the LaTeX2e output
                        % routines. It may not work with other packages that
                        % modify the LaTeX2e output routine and/or with other
                        % versions of LaTeX. The latest version and
                        % documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/sttools/
                        % Documentation is contained in the stfloats.sty
                        % comments as well as in the presfull.pdf file.
                        % Do not use the stfloats baselinefloat ability as
                        % IEEE does not allow \baselineskip to stretch.
                        % Authors submitting work to the IEEE should note
                        % that IEEE rarely uses double column equations and
                        % that authors should try to avoid such use.
                        % Do not be tempted to use the cuted.sty or
                        % midfloat.sty package (by the same author) as IEEE
                        % does not format its papers in such ways.

\usepackage{amsmath}   % From the American Mathematical Society
                        % A popular package that provides many helpful commands
                        % for dealing with mathematics. Note that the AMSmath
                        % package sets \interdisplaylinepenalty to 10000 thus
                        % preventing page breaks from occurring within multiline
                        % equations. Use:
%\interdisplaylinepenalty=2500
                        % after loading amsmath to restore such page breaks
                        % as IEEEtran.cls normally does. amsmath.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/

% Other popular packages for formatting tables and equations include:

%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty which improves the
% LaTeX2e array and tabular environments to provide better appearances and
% additional user controls. array.sty is already installed on most systems.
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

% Mark Wooding's extremely powerful MDW tools, especially mdwmath.sty and
% mdwtab.sty which are used to format equations and tables, respectively.
% The MDWtools set is already installed on most LaTeX systems. The lastest
% version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/mdwtools/

%
% \makeatletter
% \let\NAT@parse\undefined
% \makeatother
%
% Hyperref should be loaded differently depending on whether pdflatex
% or traditional latex is being used:
%
%\ifx\pdfoutput\undefined
%\usepackage[hypertex]{hyperref}
%\else
%\usepackage[pdftex,hypertexnames=false]{hyperref}
%\fi
%
% Pdflatex produces superior hyperref results and is the recommended
% compiler for such use.

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor IEEEtran}

\begin{document}

% paper title
\title{Autonomous hand localization and detection of a humanoid robot}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\authorblockN{Michael C. Bucko}
\authorblockA{LIRA-Lab, DIST, University of Genoa\\
viale Causa 13, 16145, Genova, Italy\\
Email: bucko@liralab.it}
\and
\authorblockN{Lorenzo Natale, Giulio Sandini}
\authorblockA{Italian Institute of Technology\\
via Morego 30, 16163, Genova, Italy\\
Email: lorenzo.natale,giulio.sandini@iit.it}
\and
\authorblockN{Giorgio Metta}
\authorblockA{University of Genoa and Italian Institute of Technology\\
via Morego 30, 16163, Genova\\
Email: giorgio.metta@liralab.it}
}


% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership


% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\authorblockN{Michael Shell\authorrefmark{1},
%Homer Simpson\authorrefmark{2},
%James Kirk\authorrefmark{3}, 
%Montgomery Scott\authorrefmark{3} and
%Eldon Tyrell\authorrefmark{4}}
%\authorblockA{\authorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: mshell@ece.gatech.edu}
%\authorblockA{\authorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\authorblockA{\authorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\authorblockA{\authorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}

% make the title area
\maketitle

\begin{abstract}


\end{abstract}

% no keywords

% For peer review papers, you can put extra information on the cover
% page as needed:
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
%
% for peerreview papers, inserts a page break and creates the second title.
% Will be ignored for other modes.
\IEEEpeerreviewmaketitle

% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class option
% should be used if it is desired that the figures are to be displayed while
% in draft mode.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
%
%\begin{figure}
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}


% An example of a double column floating figure using two subfigures.
%(The subfigure.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfigure command, the
% \label for the overall fgure must come after \caption.
% \hfil must be used as a separator to get equal spacing
%
%\begin{figure*}
%\centerline{\subfigure[Case I]{\includegraphics[width=2.5in]{subfigcase1}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex
%\label{fig_first_case}}
%\hfil
%\subfigure[Case II]{\includegraphics[width=2.5in]{subfigcase2}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}



% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
%\caption{An Example of a Table}
%\label{table_example}
%\begin{center}
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{center}
%\end{table}

% ***********************************************************************************************
%
%																								Introduction
%

\input{sec-introduction.tex}
\input{sec-prev.tex}
\input{sec-setup.tex}
\input{sec-method.tex}
\section{Method}\label{method}
% ***********************************************************************************************
The ability to subsequently detect the hand of the robot, firstly presupposes the localization of regions that show alike and causal movement within the scene, as already introduced in section \ref{intro}. For that we start by tracking all possible flocks of candidate regions in order to determine which of the moving regions could be a part of the robot. Candidate regions are image patches of size $N \times N$ pixels that can be tracked well and where its containing features define a clear and unambiguous common direction. Concurrently to the tracking, the relative motion of the moving arm joint is recorded in order to have a base for comparing the visual information in the decisive step where all the visually gained trajectories are correlated with the single arm joint behaviour. 
%
%
% -----------------------------------------------------------------------------------------------
%
%																			localization - Assumptions
%
\subsection{Assumptions}\label{method:localization:assumptions}
% -----------------------------------------------------------------------------------------------
Proprioceptive feedback allows us a lot of information to exploit for various tasks. As soon as James generates motion with its arm as sort of self-exploratory motion generation it will cause changes in the visual and sensory perception. The robot senses a moving arm part which again indicates him to be attentive on visual feedback. \textit{Feeling} changes, means that there is the possibility to \textit{see} some changes which will then be correlated to the self-caused action behavior. At the current stage of development of this algorithm a few assumptions have to be set. The single arm joint motion
\begin{enumerate}
	\item produces enough net displacement in the plane parallel to the camera's CCD,
	\item takes place within the visual field of the robot's eye
	\item while James is neither moving its head nor its eye.
\end{enumerate}
In later stages of these works maybe all these constraints can be eliminated or at least incrementally eliminated.


% ***********************************************************************************************
%
%																								Results
%
\section{Results}\label{results}
% ***********************************************************************************************
Each section introduced into some theoretical part to guide the reader through our possible approach of how a humanoid robot can autonomously localize in real-time its own hand and afterward detect its hand and why it is important to have such an algorithm. In this section we first name the experimental circumstances and then evaluate the the localization and the detection of the hand of the proposed method with the aid of the \textit{online} results and their \textit{offline} generated co-results of the same sequences.
%
%In each chapter we introduced some theoretical part to guide the reader through our possible approach of how a robot is able to autonomously localize and detect its hand and why it is so important to have such an algorithm. G. Metta et al.\ \cite{PRTL07-01} assume to have a/some visual model of the hand in order to be able to perform a visual guided reaching for grasping an object. Using visual servoing methods, where the arm speed is controlled based upon visual information and lead to a target object, requires the ability to measure the distance between hand and object. If such a visual model is available, reaching can be performed by a coarse approximative approach to the object using open-loop reaching and then perform the positioning for grasping by a closed-loop method. In the evaluation part we will first name the experimental circumstances, followed by the evaluation of the ``live'' results and the artificially gained co-results for equivalent test sets, but with different parameters.

% -----------------------------------------------------------------------------------------------
%
%																						test environment
%
\subsection{Test environment}\label{results:testenv}
% -----------------------------------------------------------------------------------------------
For the online tests James that was moving its arm in front of its face for a certain period of time. 
%
% -----------------------------------------------------------------------------------------------
%
%																	motor sensory stimulation / effection
%
\subsubsection{Motor sensory stimulation/effection}\label{results:motosensstim}
% -----------------------------------------------------------------------------------------------

% -----------------------------------------------------------------------------------------------
%
%																								evaluation
%
\subsection{Evaluation}\label{results:evaluation}
% -----------------------------------------------------------------------------------------------
Besides the original online test results, co-results had to be gained by re-executing the same tests offline from files without using the robot, but with different parameters. During the online tests running on the robot we recorded the original sequences and stored all visual and proprioceptive information. To guarantee a precise and sound evaluation exactly the same information had to be used on whose the method was applied again but only changing the correlation coefficient. Starting from these 10 online test runs we actually gained 100 results. The parameter of interest, the key parameter of this whole approach of finding the hand, is the correlation coefficient that matches trajectories from the different proprioception. Accuracy of our results can only be as good as the correlation threshold. All visual information with motor sensory information, or vice versa, correlate in some amount. So in the end the choice of the threshold defines the quality of the result. A threshold that accepts a low correlation coefficient from a visual and the motor trajectory, that in fact describes dissimilar behaviour, can not result in good localization. On the other hand, correlation can also be chosen too tight, with the effect that we really determine several exact positions of the hand, but unfortunately also skip too many patches that actually belong to the positive set as well, see figure \ref{fig:impactofcorr}. After all, correlation must be determined as a compromise between the well-known trade-offs accuracy and reliability.
%
\begin{figure}
	\begin{center}
		\includegraphics[width=3.5in]{imgs/results/impactofcorr.ps}
			\caption[Varying the correlation threshold.]{ This figure is illustrating how the correlation has an impact on the number of the correlating patches. From left to right: correlation 0.0, 0.6 and 0.94. }
			\label{fig:impactofcorr}
	\end{center}
\end{figure}
%
\subsubsection{Localization}
\label{results:evaluation:localization}
%
A possible way to rate the outcome of the hand localization process is to transform the visual results into a set of sound numbers. As correlation is the key factor for the accuracy of mapping causal action with motion perception, different outcomes of the same data sets are expected when changing the correlation threshold. Obviously different outcomes by varying the parameter do not mean different locations, but choosing a smaller or larger set of patches that define the region where the hand is located in the visive field. An overview of the results in form of numbers gives table \ref{tab:resultstatitistics}, where the entries were obtained by analyzing the recorded tracking sequences or from the robot's (or module's) output. 
%
The optimal solution had been achieved by manual evaluation of the tracking process and is therefore an absolute and convincing (expressive) measure, with which the automatic choice can be confronted. 

Depending on the correlation threshold patches can be chosen that do actually not belong to the hand. By increasing the correlation coefficient threshold the number of false-positives diminishes rapidly. In the middle graph the false-positive rate is much smaller, but of course also the true-positive rate diminishes. At a correlation threshold of 0.97 a really good classification can be achieved. In some cases, see in the bottom graph test sets 1 and 8-10, the exploitation of patches lying on the hand is very small, but we prefer a small set of patches that really lie on the hand, rather than having false positives. Figure \ref{fig:result:diag} shows the same 10 test series in a different diagram, where the true positive rate (black) and the false positive rate (white) are directly comparable in the bar graphs. FPR is in all cases really small and almost negligible. Test set 9 for instance could be a neglected one if we were applying the algorithm many times in a learning algorithm, on the other hand we can also see that the FPR diminishes by around 50\% when increasing the correlation coefficient. Using this diagram we can see, that raising the correlation threshold from 0.91 to 0.97 doubles the number of test sets without FPs. 

%
\begin{figure}
	\begin{center}
		\includegraphics[width=3.5in]{imgs/results/diag.ps}
			\caption[True and false positive rates of the 10 main test sets. ]{True and false positive rates of the 10 main test sets. The 10 test sets are displayed again with different correlation coefficient thresholds. The average ``learning'' over 10 sets show high reliability and very few FPs. Increasing the threshold from 0.91 to 0.97 effects an increase of the number of test sets without FP from four to 8 test sets.}
			\label{fig:result:diag}
	\end{center}
\end{figure}
%
%
An expressive judgment on the proposed method to localize the hand can be gained with the confrontation of the \textit{False-Positive-Ratio} against the \textit{True-Positive-Ratio} in order to rate our classification algorithm. For a two-class prediction system a graphical plot for visualizing performance and organizing classifiers, here the correlation coefficient, the Receiver-Operating-Characteristics (ROC) graphs plot the sensitivity versus (1-specificity) \cite{ROC04-03}. The entire set of outcomes are either marked as \textbf{P}ositives, which denote all correct solutions of patches that were following the hand, or \textbf{N}egatives, that are the whole set without the positive ones from all tracked patches. %A prediction can be falsely classified as a positive when it is actually negative, this false-alarm is called a \textbf{F}alse-\textbf{P}ositive. 
For a \textbf{T}rue-\textbf{P}ositive the actual and the prediction values are both positives, in our case TP determine the number of ``hand classified'' patches that have really been on the hand. %To build the ROC curve, only the FPR and the TPR are needed. 
The TPR, the sensitivity, determines how many positive instances have been correctly classified as positives among all positives available at one test. The ratio of costly false-positives among all negatives define the false-alarm rate, FPR, and is equal to 1-specificity. %A perfect classification would have hundred per cent specificity, no FP, and hundred per cent sensitivity, where all true positives are found, and would get the coordinate (0;1) in the ROC space. 
The ROC space illustrates the trade-off between true (y-axis) and false positives (x-axis). In order to get an expressive ROC the online tests have been reproduced offline for the correlation thresholds 0.0, 0.1, 0.2, ..., 0.9, 0.91, 0.97 and 1.0. In order to classify the patches behaviour and decide on the correctness of the methods output all the sequences had to be elaborated by hand. The outcome of the hand localization shows an extremely good ROC far away from any random classification and confirms the resulting ROIs, see examples in figure \ref{fig:roi}. Even under difficult and noisy circumstances it shows good results.
%
\begin{figure}
	\begin{center}
		\includegraphics[width=3.5in]{imgs/results/roc.ps}
			\caption[Receiver-Operating-Characteristics graph for the 10 main test sets. ]{Receiver-Operating-Characteristics graph for the 10 main test sets. The ROC has been created with the 10 raw data sets of the online tests and correlation from 0.0 to 1.0. Our ROC is nearly perfect. As a consequence, this objective ROC testimonies us an algorithm that is highly reliable finding the correct patches of the hand and this under different circumstances and environments. Already from very low correlation coefficients we can see that FPs are below 0.5. }
			\label{fig:result:roc}
	\end{center}
\end{figure}
%
%
\subsubsection{Detection (Segmentation)}
\label{results:evaluation:segmentation}
%
The segmentation process' result is simple to rate. By subtracting the background from the image where the hand had been localized, the foreground is recovered. A good result is achieved, if the foreground exactly depicts the hand. Having the background perfectly recovered with the method after A.Colombari et al \cite{} Completeness of the background initialization method depends a lot on choosing the correct amount of pictures and on the heuristic assumptions proposed in \cite{BICS06}. During tests and implementation we found out that a few constraints of the BICS algorithm are very strict and therefore can cause undesired results in a every day use of the algorithm in a robot where the hand for instance will not release all the background. The method is also too vulnerable if not at least two patches from the correspondent temporal footprint have seen entirely the background. Already a small entity, that differs in a patch from the real background, causes a large distance measure with the consequence to be excluded. One might think that in a sequence of 200 images it must be possible that each patch was fully revealed at least twice. Unfortunately under daily circumstances this constraint is not the case, as our experiments showed us. Embedding our entire algorithm in a learning mechanism could only partly solve the problem. During the evaluation we found out that it would actually make sense to selectively pick images with ``good'' properties for the BICS-algorithm. Images that are anyway present, and information about trajectories can help a lot in selecting images for a reliable, effective and efficient background retrieval. As an example, images could be chosen where the hand was not present in the ROI, what we can roughly assume by evaluating the trajectories of the ``robot''-patches. 

\section{Conclusion}
future work:
stereovision, fourier for extracting frequencies so that also head can move. neural network to use. better use of bics.

% conference papers do not normally have an appendix

% use section* for acknowledgement
\section*{Acknowledgment}
% optional entry into table of contents (if used)
%\addcontentsline{toc}{section}{Acknowledgment}
The authors would like to thank...

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section
% NOTE: BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/

% can use a bibliography generated by BibTeX as a .bbl file
% standard IEEE bibliography style from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/IEEEtran/bibtex
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,bib/paper}
\bibliography{bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to {\LaTeX}}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%@INPROCEEDINGS{JHRAUW06-12,
%  author = {Lorenzo Jamone and Giorgio Metta and Franscesco Nori and Giulio Sandini},
%  title = {James: A Humanoid Robot Acting over an Unstructured World},
%  booktitle = {6th IEEE-RAS International Conference on Humanoid Robots},
%  year = {2006},
%  pages = {143-150},
%  address = {Genova, Italy},
%  month = {December},
%  note = {Humanoids},
%  abstract = {The recent trend of humanoid robotics research has been deeply influenced
%	by concepts such as embodiment, embodied interaction and emergence.
%	In our view, these concepts, beside shaping the controller, should
%	guide the very design process of the modern humanoid robotic platforms.
%	In this paper, we discuss how these principles have been applied
%	to the design of a humanoid robot called James. James has been designed
%	by considering an object manipulation scenario and by explicitly
%	taking into account embodiment, interaction and the exploitation
%	of smart design solutions. The robot is equipped with moving eyes,
%	neck, arm and hand, and a rich set of sensors, enabling proprioceptive,
%	kinesthetic, tactile and visual sensing. A great deal of effort
%	has been devoted to the design of the hand and touch sensors. Experiments,
%	e.g. tactile object classification, have been performed, to validate
%	the quality of the robot perceptual capabilities.},
%  pdf = {G:\Science\james\JHRAUW06-12.pdf},
%  timestamp = {2007.03.10},
%  url = {http://www.robotcub.org/misc/review2/06_Jamone_Metta_Nori_Sandini.pdf}
%}
%
%\end{thebibliography}
%

% that's all folks
\end{document}


