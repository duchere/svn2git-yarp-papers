From paulfitz@ai.mit.edu Tue Feb 11 13:37:25 2003
Date: Sun, 9 Feb 2003 12:02:04 -0500 (EST)
From: Paul Fitzpatrick <paulfitz@ai.mit.edu>
To: Giorgio Metta <pasa@dist.unige.it>
Subject: Re: PTRS/WGW02/06

    [ The following text is in the "X-UNKNOWN" character set. ]
    [ Your display is set for the "US-ASCII" character set.  ]
    [ Some characters may be displayed incorrectly. ]



My take on the niggles:


> REVIEWER 1
> ==========
>
> Title: Grounding vision through experimental manipulation
>
> Authors: Paul Fitzpatrick and Giorgio Metta
>
> This paper presents a defence of the idea that manipulating objects by
> an autonomous robot helps vision.
>
> However the paper is unclear on many points.
>
> - The term "grounding vision" is not explained in the paper, so it is
> difficult for the reader to evaluate the contributions of the paper.

True; I think it is possible that we never mention the word "grounding"
outside of the title.  Easy to fix.

> - The target audience is unclear.  For instance, in section 1, it is
> noted that the complexity of vision cannot be grasped intuitively.
> For those who work in artificial vision, the complexity of vision is
> painfully clear.  So, this note must be directed to readers naïve in
> computer vision.

Strange interpretation of the word "intuitive".  Easy to fix.

> However, the justification of the work described
> in the paper heavily relies on knowledge of previous work by Ballard
> (1991) that is not described at all, thus assuming a reader specialized
> in the domain.  Similarly, in p.6, the authors refer to "long-standing
> problems in machine vision" without making them explicit.

This is not a problem if we correct the misapprehension that we are
talking to naive readers.  Wouldn't be bad to summarize this stuff briefly
though!

> - The statement that vision is full of illusions (p.2) is true in a
> philosophical sense, and in some specially designed experiments.  However,
> everyday vision is very effective at correctly recognizing objects, even
> with few cues.  Hence, the "crucial" contribution of tapping an object
> (p.3) is a little bit overstated.

The reviewer interprets illusions in a very technical sense -- perhaps
"ambiguity" would be a better word.  Also, objection would be muted if we
were more careful to point out we are talking in a developmental context,
where "everyday vision" is a distant target.

> - The paper suggests that tapping will lead to a "manipulation-driven
> representation of objects" (p.3).  However, what their results show is
> that when you move an object, it can be separated from the background,
> smartly filled in and its principal axes determined.  Then, if this is
> repeated many times, one can determine the probability that the object
> rolls by a given angle.  Is the probability graph the representation of
> the object?  There is a mention of a colour segmentation method, but no
> details are given.

[a quick citation of Swain&Ballard (I think) would not go amiss for the
color histogram stuff; not sure where the reviewer saw color
*segmentation* though]

> Maybe the whole process of building a representation
> should be made more explicit.  What information is stored?  How is
> the learning procedure organized? (For example, does the object need
> to be put back in the same place after each tapping?)  Both pieces of
> information would help understand what "manipulation-driven representation
> of objects" is.  These would also make more clear how much this approach
> is suitable for truly autonomous robots.

This is a potentially difficult objection; I think we did the best we
could here, and it will be hard to be clearer without a lot more detail.
Let me mark this TRICKY-BIT #1 -- REPRESENTATION.

> - The work on mirror neurons is quite obscure.  On p.5, it is said that
> affordance neurons and mirror neurons are found in area F5.  Both seem
> to be active when observing manipulation tasks.  Are they not the same?

Easy :)

> Similarly to Ballard's paper that is key in the argumentation of the
> paper, Gallese's paper is key to the argumentation about mirror neurons.
> The authors should give more details on the experiments described in these
> papers.  In particular, the conclusion that "object and goal-directedness
> of the actions represent an important component in the understanding of
> the intentions of others" needs more careful elaboration.  At present,
> it is unclear how "these results" support that statement.

Not sure if I agree with this.  Still, a few more sentences could be
produced.  Easy.

> - P.6.  What is the meaning of "bootstrap perception"?

Replace phrase with something clearer.  Easy.

> - Figure 8 (p.10).  Is the arm "tapping the object" or "following a
> pre-programmed trajectory that brings it in contact with the object"?
> The first description communicates the notion of an intentional movement
> directed towards an object.  As I understand it , the robot has neither
> intentions nor the notion of what an object is.  (On p.11, the target
> seems actually defined by the authors, not the robot).  Maybe the caption
> could be corrected?

There is room for clarification here -- we need to be clearer where the
target comes from.  Figure 8 is weak ground because it is that early
sequence I did where the arm just makes a sweep without being connected to
the attention system.  Perhaps I should replace it with a newer
sequence.  Anyway, there is no real problem here.

> - More about mirror neurons.  In the paper (p.16), the robot tries to
> determine the movement of an operator by observing how the object moves.
> Is the object required in animal experiments?  If not, the relation of
> this work with mirror neurons is very tenuous.  This could be left out
> of the paper to make more space for other clarifications called for above.

Hmm.  What do you think about this?  I think we are talking about
DEVELOPMENT here, for which of course there is no mirror neuron
stuff.  We are proposing a developmental path that could led to the
observed kind of representation.  Clarification worthwhile.

> - P.18.  The notes about predicting the future and inverting causal
> relations are very speculative, it seems, and unsupported.

Pfff :).  I'd be happy to ignore this point.

> Overall, the authors should make more clear what problem they try to
> solve and explain in more details how they solve it.

:-)


>
> REVIEWER 2
> ==========
>
> This paper provides a detailed discussion as to how causality can be
> probed at different levels by a robot.  It provides a linkage between the
> authors' work and neurobiology.  The paper is well written and provides
> a good review of the subject matter.  The discussion on examining
> the results of poking and observing the motion are of some interest.
> Regarding figure 14, the definition of the principal axis of a cube and
> ball need to be more carefully considered.  Can the principal axis of
> a ball be defined (given its symmetry)?

easy


> In addition:
>
> * does the cube roll or slide?

easy

> * is the direction of the ball only dependant on the direction of the
> "poke"?  What about the ball's dynamics and the surface?

easy

> The following also require attention:
>
> * The reference to Berkeley needs to be clarified.
>
> * Some of the images are rather small, particularly 6 and 7 where it is
> difficult to see the fine detail.

easy

> I would like to see this paper published due to is high accessibility and
> scope.

I agree ;)


> REVIEWER 3
> ==========
>
> Fitzpatrick and Metta: Grounding vision through experimental manipulation
>
> Having read the paper, I would have liked to see more discussion on
> two points:
>
> (1) The idea that by actively manipulating an object and observing the
> results -- taking into account proprioceptive information -- one can
> separate object and background seems so obvious that one wonders why it
> hasn't been done before.  In fact, the authors refer to Ballard's work of
> eleven years ago, but do not enter a deeper discussion.  The experimental
> results are fine, and the overall point is interesting, but I feel it
> should be argued more strongly what the contribution of this paper is,
> in contrast to existing work.

Okay we need to talk about Ballard a bit.

> (2) The attempt to move towards a "passive" understanding of objects and
> their affordances (mirror neuron, section 10) by learning the effects of
> the four possible actions, and the responses of four different objects to
> these actions) first, and then analysing the results of human-performed
> actions, is interesting, and the results look promising.  However, it
> seems that the approach is crucially dependent on the fact that there
> is only a small number of possible actions, and probably also on the
> fact that there is a small number of objects.  How will this scale?
> Is this approach suitable for anything but the smallest set of actions
> and objects?  If it isn't, that wouldn't necessarily be to the detriment
> of the paper but we would like to know.

Yes, good question, don't think we can say much about this.

> Also, the authors should discuss how much the method discussed in section
> 10 is dependent on the correct object identification. What happens if
> the bottle is confused with the car?

reasonable, easy.

> Figures 6 and 7 are hard to read.

easy

> The flipper is found by a heuristic (p.10).  How much does this heuristic
> influence the generality of the method?

looks like that figure is confusing, better update it (and the text)

> The significance of section 9 is unclear.  Neither the objectives nor
> the results presented there seem particularly relevant to the paper,
> and the paper might benefit from the omission of that section.

Okay maybe we can just omit that then -- it is fine by me.

> The term "signature explosion of movement" (p.12) should be explained.
> The sixth sentence from the top on p.14 is incomplete ("simply by checking
> whether its arm ...").

okay easy.

> The discussion of results on p.15 should be expanded.  What is counted
> as a "mistake"?  How were these measured?

easy enough...



hmm not so bad overall!

