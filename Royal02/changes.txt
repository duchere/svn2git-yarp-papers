[my comments marked with *** or !!!]
[!!! means "pending" -- not done yet]

REVIEWER 1
==========

Title: Grounding vision through experimental manipulation

Authors: Paul Fitzpatrick and Giorgio Metta

This paper presents a defence of the idea that manipulating objects by
an autonomous robot helps vision.

However the paper is unclear on many points.

- The term "grounding vision" is not explained in the paper, so it is
difficult for the reader to evaluate the contributions of the paper.

*** Terminology problem, "grounding" is widely used term in robotics.
*** FIX: added text in section 3, paragraph 2 (addition in capitals here):
***   "Figure [fig] illustrates three levels of causal complexity
***    we would like our robot to probe, SO 
***    THAT IT CAN DEVELOP ROBUST, EMPIRICALLY FOUNDED
***    REPRESENTATIONS OF THE WORLD AROUND IT
***    (OFTEN REFERRED TO AS ``GROUNDED'' REPRESENTATIONS [CITATION]).


- The target audience is unclear.  For instance, in section 1, it is
noted that the complexity of vision cannot be grasped intuitively.
For those who work in artificial vision, the complexity of vision is
painfully clear.  So, this note must be directed to readers naïve in
computer vision.  However, the justification of the work described
in the paper heavily relies on knowledge of previous work by Ballard
(1991) that is not described at all, thus assuming a reader specialized
in the domain.  

*** Authors did not intend "grasp at an intuitive level" to mean 
*** specialist-trained judgements -- section 1+2 are present primarily
*** for the benefit of non-specialists.
*** FIX: added text in section 1:
***   "the motivation for this work can be difficult FOR THOSE OUTSIDE
***    THE FIELD OF VISION RESEARCH to grasp at an intuitive level.
***    FOR THIS REASON, we begin out paper by seeking to clarify..."

Similarly, in p.6, the authors refer to "long-standing
problems in machine vision" without making them explicit.

** FIX: added text in section 5, paragraph 3:
***   "... allow us to tackle long-standing problems in machine vision
***    SUCH AS FIGURE/GROUND SEPARATION AND OBJECT RECOGNITION
***    in an innovative way."

- The statement that vision is full of illusions (p.2) is true in a
philosophical sense, and in some specially designed experiments.  However,
everyday vision is very effective at correctly recognizing objects, even
with few cues.  Hence, the "crucial" contribution of tapping an object
(p.3) is a little bit overstated.

*** Terminology problem: reviewer interprets illusion in narrow technical
*** sense, authors intended it in sense used by source quoted (Berkeley 1972)
*** FIX: replaced word "illusion" with "ambiguity" in final paragraph
*** of section 2:
***    "... while it is true that vision is full of AMBIGUITY, this
***     AMBIGUITY evaporates when the robot can reach out..."

*** Context problem: "crucial" contribution of poking is not in
*** mature, everyday vision, but during development, when vision
*** is immature and more in need of guidance.
*** FIX: added text to section 3 paragraph 1:
***    "the ability to perform 'controlled experiments' DURING THE
***     PROCESS OF DEVELOPMENT, ... is crucial to getting to grips
***     with an otherwise complex and uncertain world."

- The paper suggests that tapping will lead to a "manipulation-driven
representation of objects" (p.3).  However, what their results show is
that when you move an object, it can be separated from the background,
smartly filled in and its principal axes determined.  Then, if this is
repeated many times, one can determine the probability that the object
rolls by a given angle.  Is the probability graph the representation of
the object?  

*** Very reasonable point of clarification
*** FIX: added text to section 10.  New paragraph, paragraph 4.
***    "At the end of the learning procedure the robot has built a
***     representation of each object in terms of:
***     + Pictorial information in the form of colour histograms,
***     following [CITATION].
***     + A measure of the average area of the object, an
***       index of the elongation of the object with respect to 
***       its principal axis, and a set of Hu moments [CITATION].
***     + Detailed histograms of the displacement of the object 
***       given that a particular motor primitive was used with
***       respect to the initial orientation of the object.
***     + The summary histograms shown in Figure 14
***       which capture the overall response of each object to poking."


There is a mention of a colour segmentation method, but no
details are given.  

*** FIX: clarified text in section 10, paragraph 6 (was paragraph 4)
*** and added citation to Swain&Ballard:
***    "based on the same COLOUR HISTOGRAM PROCEDURE used 
***     during training [CITATION]"


Maybe the whole process of building a representation
should be made more explicit.  What information is stored? 

*** FIX: detailed in new paragraph section 10, paragraph 4, as given above.

How is
the learning procedure organized? (For example, does the object need
to be put back in the same place after each tapping?)  Both pieces of
information would help understand what "manipulation-driven representation
of objects" is.  These would also make more clear how much this approach
is suitable for truly autonomous robots.

*** Object doesn't need to be in same place or orientation.
*** We believe the paper addresses the details of the learning
*** procedure, but perhaps the overall picture gets buried under 
*** those details.
*** FIX: added explanatory anecdote, in section 10, (new) paragraph 5:
***    "The learning procedure is designed to be robust, 
        with data gathered opportunistically during the unconstrained 
        interaction of a human with the robot.  For example, while the 
        robot was being trained, a teenager visiting the laboratory 
        happened to wander by the robot, and became curious as to what 
        it was doing.  He put his baseball cap on Cog's table, and it 
        promptly got poked, was correctly segmented, and became
        part of the robot's training data (it was clustered by colour with
        the similarly-coloured ball)."

- The work on mirror neurons is quite obscure.  On p.5, it is said that
affordance neurons and mirror neurons are found in area F5.  Both seem
to be active when observing manipulation tasks.  Are they not the same?

*** No they are not the same.  The first class of neuron is activated
*** by simply fixating an object, the second is not.
*** Confusion caused by sentence in section 4 introducing mirror neurons:
***    "They found another class of grasping neurons that also respond 
***     during observation of somebody else's action."
*** This sentence is misleading, although the one after it is clear:
***    "A typical cell of this class (called mirror neuron) indeed 
***     responds in two situations: i) when executing a 
***     manipulative gesture, and ii) when observing somebody 
***     else executing the same action."
*** FIX: replaced misleading sentence (section 4, last paragraph) with:
***    "They found a distinct class of neuron that responds
        specifically to actions on objects, rather than the 
        mere presence of that object at the point of fixation."


Similarly to Ballard's paper that is key in the argumentation of the
paper, Gallese's paper is key to the argumentation about mirror neurons.
The authors should give more details on the experiments described in these
papers.  In particular, the conclusion that "object and goal-directedness
of the actions represent an important component in the understanding of
the intentions of others" needs more careful elaboration.  At present,
it is unclear how "these results" support that statement.

*** pending

- P.6.  What is the meaning of "bootstrap perception"?

*** Terminology problem: "bootstrap" is widely used term in computer science
!!! FIX: replaced phrase

- Figure 8 (p.10).  Is the arm "tapping the object" or "following a
pre-programmed trajectory that brings it in contact with the object"?
The first description communicates the notion of an intentional movement
directed towards an object.  As I understand it , the robot has neither
intentions nor the notion of what an object is.  (On p.11, the target
seems actually defined by the authors, not the robot).  Maybe the caption
could be corrected?

*** Use of intentional stance
!!! FIX: replaced text with something more technical

- More about mirror neurons.  In the paper (p.16), the robot tries to
determine the movement of an operator by observing how the object moves.
Is the object required in animal experiments?  If not, the relation of
this work with mirror neurons is very tenuous.  This could be left out
of the paper to make more space for other clarifications called for above.

*** Objects are absolutely required in animal experiments

- P.18.  The notes about predicting the future and inverting causal
relations are very speculative, it seems, and unsupported.

*** Speculative in terms of biological evidence, but an
*** entirely reasonable next step in terms of robotic implementation.

Overall, the authors should make more clear what problem they try to
solve and explain in more details how they solve it.

*** We believe the changes made will do that; certainly they address
*** the specific concerns of this reviewer.



REVIEWER 2
==========

This paper provides a detailed discussion as to how causality can be
probed at different levels by a robot.  It provides a linkage between the
authors' work and neurobiology.  The paper is well written and provides
a good review of the subject matter.  The discussion on examining
the results of poking and observing the motion are of some interest.
Regarding figure 14, the definition of the principal axis of a cube and
ball need to be more carefully considered.  Can the principal axis of
a ball be defined (given its symmetry)?

*** Answer: no, not reliably, and figure 14 actually reflects this
*** through the flatness of the graph relative to the objects with
*** well-defined principal axes.
!!! FIX: Mention this in figure caption.

In addition:

* does the cube roll or slide?

*** Answer: it slides.
!!! FIX: Mention this in figure caption.

* is the direction of the ball only dependant on the direction of the
"poke"?  What about the ball's dynamics and the surface?

*** We do have data on this, omitted for space constraints.
!!! FIX: [no action taken]

The following also require attention:

* The reference to Berkeley needs to be clarified.

!!! FIX: [no specific action taken; mirror neuron text expanded for
!!! FIX:  first reviewer]

* Some of the images are rather small, particularly 6 and 7 where it is
difficult to see the fine detail.

*** PDF conversion problem -- image resolution was dropped significantly
!!! FIX: smarter conversion

I would like to see this paper published due to is high accessibility and
scope.


REVIEWER 3
==========

Fitzpatrick and Metta: Grounding vision through experimental manipulation

Summary 

The paper presents a series of experiments conducted with the upper-torso
humanoid robot Cog, whose purpose it was to achieve image segmentation
and visual scene interpretation through object manipulation.  In a first
series of experiments, background was separated from object and robot arm
by means of image differencing or background modelling, while the robot's
gaze was fixed (thus not inducing any optic flow).  In a second set of
experiments, the authors attempted to develop artificial mirror neurons
in the robot, i.e. neurons that fire either when an action is performed,
or when its performance is merely observed.  The method employed was to
learn the typical response of a small number (four) of objects to one
of four actions, and subsequently to identify the action performed by
a human operator, using this knowledge.

Discussion 

The paper is very well written, and makes interesting reading.  The
fundamental point that action should be linked with perception ("active
perception") is well taken, and also by now widely accepted in robotics.
This paper makes an interesting contribution to how this can be achieved.

Having read the paper, I would have liked to see more discussion on
two points:

(1) The idea that by actively manipulating an object and observing the
results -- taking into account proprioceptive information -- one can
separate object and background seems so obvious that one wonders why it
hasn't been done before.  In fact, the authors refer to Ballard's work of
eleven years ago, but do not enter a deeper discussion.  The experimental
results are fine, and the overall point is interesting, but I feel it
should be argued more strongly what the contribution of this paper is,
in contrast to existing work.

!!! FIX: added some contrasts.

(2) The attempt to move towards a "passive" understanding of objects and
their affordances (mirror neuron, section 10) by learning the effects of
the four possible actions, and the responses of four different objects to
these actions) first, and then analysing the results of human-performed
actions, is interesting, and the results look promising.  However, it
seems that the approach is crucially dependent on the fact that there
is only a small number of possible actions, and probably also on the
fact that there is a small number of objects.  How will this scale?
Is this approach suitable for anything but the smallest set of actions
and objects?  If it isn't, that wouldn't necessarily be to the detriment
of the paper but we would like to know.

!!! FIX: added some text on this to conclusions

Also, the authors should discuss how much the method discussed in section
10 is dependent on the correct object identification. What happens if
the bottle is confused with the car?

*** Answer: robot will naturally do the wrong thing
!!! FIX: added some text on this

Smaller points 

Figures 6 and 7 are hard to read. 

!!! FIX: pdf conversion, mentioned earlier

The flipper is found by a heuristic (p.10).  How much does this heuristic
influence the generality of the method?

!!! FIX: updated text

The significance of section 9 is unclear.  Neither the objectives nor
the results presented there seem particularly relevant to the paper,
and the paper might benefit from the omission of that section.

!!! FIX: Dropped section?

The term "signature explosion of movement" (p.12) should be explained.
The sixth sentence from the top on p.14 is incomplete ("simply by checking
whether its arm ...").

!!! FIX: smoothed text
*** The sixth sentence from the top on p.14 had ambiguous parse
!!! FIX: reworded it

The discussion of results on p.15 should be expanded.  What is counted
as a "mistake"?  How were these measured?

!!! FIX: added explanation

