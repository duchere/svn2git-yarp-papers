\section{Objects and actions in robotic systems}

Certainly, vision and action are intertwined at a very basic level in
humans.  While an experienced adult can interpret visual scenes
perfectly well without acting upon them, linking action and perception
seems crucial to the developmental process that leads to that
competence.  While not focusing on development, many researchers in
machine vision have adopted the view that vision and action need to be
tightly integrated for functional reasons.  Their work is loosely
termed ``active vision''.

A vision system is said to be {\em active} if it is embedded within a
physical platform that can act to improve perceptual performance.  For
example, a robot's cameras might servo a rapidly moving target to
stabilize the image and keep the target in view.  In fact, active
vision is often equated with moving cameras, although in this paper we
use it in a broader sense of any controllable resource recruited to
serve vision (including, in our case, arm motion).

Historically, a number of logically distinct ideas are often
associated with active vision.  The first is that vision should be
approached within the the context of an overall task or
purpose~\cite{aloimonos87active}.  If an observer can engage in
controlled motion, it can integrate data from frame to frame to solve
problems that are ill-posed statically.  Well-chosen motion can
simplify the computation required for widely studied vision problems,
such as stereo matching~\cite{bajcsy88active,ballard91animate}.  These
interwoven ideas about active vision are teased apart
in~\cite{tarr94computational}.  

In our work, we show that the entire body can usefully be recruited to
cooperate with the vision system, and we need not limit ourselves to
just the head.  In particular, we show that probing arm movements
can be very revealing, and allow us to tackle lost-standing problems 
in machine vision in an innovative way.

%%We now describe the active vision platform we employ, and the 
%%experiments we performed with it.
