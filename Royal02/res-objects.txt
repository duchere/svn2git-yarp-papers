Objects and actions

The example of the cross composed of prime numbers is a novel (albeit
unlikely) type of segmentation in our experience as adult humans. We
might imagine that in our infancy, we had to initially form a set of
such criteria to solve the object identification/segmentation problem
in more mundane circumstances.  We ask the question of whether we can
discover these criteria during ontogenesis.

Humans differentiate from other primates -- and tool-user primates from
non tool-user -- for their ability to manipulate their environment
(sometimes adversely). Our capacities are mirrored in the brain by the
size of the cortex controlling them. Neuroscience has shown that our
brains possess large cortical areas devoted to the control of
manipulation -- not surprisingly given that encephalization evolved
for the purpose of adaptively controlling action [1].

A good conceptual schema, though perhaps a little extreme, sees the
visual information following two distinct pathways in the brain,
namely, the dorsal and the ventral. We would like to stress that
actually the two pathways are not completely segregated but rather
complement each other and interact in different ways [3].

This concept of two distinct visual systems was initially proposed by
Ungerleider and Mishkin (Ungerleider and Mishkin 1982) and succesively
refined by Milner and Goodale [2]. The dorsal pathway controls action
directly and pragmatically, conversely, the ventral takes care of more
conceptual skills such as object recognition.

Objects are thought to maintain a double "identity" whether they are
used in perceptual or in motor tasks. The concept of size, for
example, might be represented multiple times in different brain
areas. Observation of agnosic patients (Jeannerod, 1997) shows an even
more complicated relationship than the simple dorsal/ventral dichotomy
would suggest. Althought some patients could not grasp generic objects
(e.g. cylinders), they could correctly preshape the hand to grasp
known objects (e.g. a lipstick): interpreted in terms of the
two-pathway system, this implies that the ventral representation of
the object can supply the dorsal system with size information. What we
consciously perceive as "size" is rather a collection of different
percepts interacting in a complicated way, and under pathological
circumstances they can be separated from each other. One of the
"identities" of objects is thus connected to motor performance.

That such pathways develop and are not completely innate is suggested
by the results of Kovacs (Kovacs, 2000). She has shown that perceptual
grouping is slow to develop and continues to improve well beyond early
childhood (14 years). Long-range contour integration was tested and
this work elucidated how this ability develops to enable extended
spatial grouping. This results further suggest that the development of
action might precede that of categorization: it is well enstablished
that by 4 months of age infants can process complex motion stimuli,
depth, and color.  Roughly at the same age reaching becomes more
consistent [4]. That is, action comes first supported by the pragmatic
use of diverse sensory modalities, perception conversely is a long
developing process. More studies are needed though to ascertain how
the dorsal pathway (action) influences the ventral (perception) both
in situations similar to the examples mentionded before and during
ontogenesis.

The dorsal stream connects the parietal lobe to the premotor cortex,
which project heavily onto the primary motor cortex to eventually
control movements. For many years the premotor cortex was considered
just another big motor area [cite]. New studies (Jeannerod, 1997) have
demonstrated that this is not the case. In fact, recently, researchers
identified neurons in the area F5 of the frontal cortex [5] that are
activated in two situations: i) when acting onto an object
(e.g. grasping), and ii) when looking at the same object (visual
response). Their firing pattern was quite specific, building a link
between the size of the object and the applied grasp type (e.g. a
small object requires a precision grip).
 
These neurons were called canonical. This was quite an astonishing
discovery because area F5 was believed to be only a motoric area. A
possible interpretation is that the brain stores a representation of
objects in motor terms, and uses these representations to generate an
appropriate response to objects (the concept of Gibsonian affordances
translated in neural terms [6]).

The gap from object manipulation to hand gesture
production/recognition is small.  In fact F5 contains another class of
neurons called mirror neurons. A mirror neuron responds in two
situations: i) when executing a manipulative gesture, and ii) when
observing somebody else executing the same action. These neurons
provide a link between the observation of somebody else’s and our own
actions.  Beside the recognition of manipulative actions, they seem to
support imitative behaviors. An intriguing theory proposed by
Rizzolatti and Arbib [7] associates mirror neurons to language and to
the motor theory of language.

Thinking too much in terms of the dorsal/ventral dichotomy is still
misleading.  There are neurons in area STS (superior temporal sulcus,
which is a ventral area) that respond to the sight and specific
posture of the hand. They are quasi-mirror neurons but they lack the
motor component (they do not fire in the dark).  Area STS is supposed
to provide the visual information about the posture of the hand to F5
[cite].

Another important class of neurons in premotor cortex is found in area
F4 (Fogassi et al., 1996). While F5 is more concerned with the distal
muscles (i.e. the hand), F4 controls more proximal muscles
(i.e. reaching). A subset of neurons in F4 has a somatosensory, visual
and motor receptive field. The visual receptive field (RF) extends in
3D from a given body part, for example, the forearm. The somatosensory
RF is usually in register with the visual one. Finally, motor
information is integrated into the representation by maintaining the
RF anchored to the correspondent body part (the forearm in this
example) irrespective of the relative position of the head and arm.


A working hypothesis

In the light of these results, we see at least two reasons why
intelligence needs to be embodied. First, if robots are to tell us
something about the functioning of our brains, we have to study its
development in the proper setting, that is, with the robot acting in
the environment. As we have seen action is fundamental to a set of
highly cognitive skills including imitation and language. Perceptual
tasks are also be influenced by action. Second, to build better
robots, adaptive to their environment, there is probably no
alternative but to build them following to some extent biological
principles. The same constraints encountered by biological agents
during ontogenesis are encountered by the robot during its simulated
development.

Certainly, vision and action are intertwined at a very basic level.






[1]
Maturana, R.H. and F.J. Varela, 
The three of knowledge, the biological roots of human understanding. 
Revised Edition ed. 1998, Boston & London: Shambhala Publications, Inc. 269.

[2]
Milner, D.A. and M.A. Goodale, 
The Visual Brain in Action. Oxford Psychology. Vol. 27. 1995, 
Oxford: Oxford University Press.

[3]
Jeannerod, M., 
The Cognitive Neuroscience of Action. Fundamentals of Cognitive Neuroscience, 
ed. M.J. Farah and M.H. Johnson. 1997, Cambrige, MA and Oxford UK: 
Blackwell Publishers Inc. 236.

[4]
Konczak, J.,
///

[5]
Fadiga, L., et al., Visuomotor neurons: ambiguity of the discharge of 
'motor' perception? Internation Journal of Psychophysiology, 2000. 35(2-3): p. 165-177.

[6]
Gibson, J.J., 
The theory of affordances, in Perceiving, acting and knowing: toward an 
ecological psychology, R. Shaw and J. Bransford, Editors. 1977, 
Lawrence Erlbaum: Hillsdale. p. 67-82.

[7]
Rizzolatti, G. and M.A. Arbib, 
Language within our grasp. Trends in Neurosciences, 1998. 21(5): p. 188-194


	