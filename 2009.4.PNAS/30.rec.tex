\section{The Audio-Motor-Map}
\label{sec:rec}

\subsection{Training the AMM}
\label{subsec:amm_setup}

The procedure for building the AMM closely follows that outlined in
\cite{papcun,richmond,richmond2007} for a multi-layer perceptron neural network.
For each of the $1157$ audio sequences, the spectrogram is evaluated
over $20$-milliseconds long Hamming windows (slices), using a $20$-filter
Mel-scale filterbank between $20$Hz and $2$KHz. Each slice overlaps by $10$ milliseconds with
the preceding slice. Each single sample of \vlio, \alio, \vttu\ and \attu\ is
then associated to $19$ surrounding spectrogram slices, covering
about $200$ milliseconds of speech and centered around the sample itself. With this
"sliding spectrogram window" method, the four trajectories are completely reconstructed.
%Figure \ref{fig:amm} graphically represents the procedure.
The Mel filters, the spectrogram and (later on) the cepstral coefficients of the audio
signal are extracted using the off-the-shelf speech recognition Matlab package
\emph{Voicebox} \cite{voicebox}.

About $15000$ samples are extracted from the original $1157$
audio/motor sequences; each input sample consists of $19\cdot 20 = 380$ real
numbers, while the output space is given by the $4$ trajectory points of
the motor signals. A feed-forward neural network is set up in order to
build the AMM, with $380$ input units, one hidden layer with $15$ units and
$4$ output units; the net is trained via the Scaled Conjugate Gradient
Descent method \cite{MOLLER93} and the activation is a logistic sigmoidal function.

Training is done via early stopping on the appropriate validation set (see the previous
Section for the details about CV). This procedure is repeated over $10$ random restarts, and then
the network with best average performance over the $4$ output dimensions is stored.
%We have manually verified that all training sessions end by validation stopping
%(as opposed to bumping into the maximum number of training epochs, which we set
%for safety at a large value, $200$).
The performance measure is Matlab's embedded mean-square-error with regularisation
function, in which after some initial experiments we set the regularisation
parameter at $0.714$. This value, as well as all other parameters, have been found in
an initial experimentation phase, by slightly altering values suggested in literature
and/or in the Matlab manual.

No sample normalisation is performed, in order to preserve the time structure of the
spectrogram windows. Targets are normalised in order to lie within the range $[0.1,0.9]$,
since the logistic activation function has asymptotic values of $0$ and $1$.

\subsection{Evaluating the AMM}
\label{subsec:amm_results}

Figure \ref{fig:amm_perf} shows a quantitative assessment of the performance
of the AMM. The measure of performance is the NRMSE (Normalized Root Mean Square Error),
where the normalisation is over the range of each testing data set. The NRMSE
ranges from $16.60\% \pm 1.07\%$ (\vlio, \cob) to $8.19\% \pm 0.62\%$ (\vttu, \spkc).
Regression upon \vlio\ shows the largest error overall. Moreover, the error is on average
larger for the per-coarticulation CV schemas.

Although these figures do not really indicate whether AMM-reconstructed MIs will be
effective in phoneme discrimination, they show that the error rate in regression has
limited magnitude and does not differ dramatically across CV schemas and output signals.
Qualitative inspection of the results (one example is given in Figure \ref{fig:example})
shows that the AMM-reconstructed motor signals are on average rather
similar to the real ones, at least as far as the range of values is concerned.

A definite trend is apparent, favouring the reconstruction of \vlio\ over \vttu\ when
bilabials are presented to the AMM and vice-versa; the trend is numerically confirmed
by checking the Pearson correlation coefficient between AMM-reconstructed and real MIs
according to whether labials (/b/,/p/) or dentals (/d/,/t/) are presented as input
to the AMM. As one can see in Figure \ref{fig:DD}, when the \overall\ CV schema is used,
a ``double dissociation'' pattern appears when comparing the correlation coefficients of
\vlio\ and \vttu\ AMM-reconstructed from labials or dentals
($0.8822 \pm 0.0119$ versus $0.3381 \pm 0.0281$ with Student's t-test $p<0.01$ for \vlio, and
 $0.9280 \pm 0.0096$ versus $0.5548 \pm 0.0236$, $p<0.01$, for \vttu).
In other words, when the AMM
``hears'' /b/ or /p/, it reconstruct effectively the trajectory of the lips, but less
reliably that of the tongue tip; and dually, it reconstructs better the latter one when
presented with /d/ or /t/. This pattern is repeated to an almost uniform extent when the
other CV schemas are used, and also when \alio\ and \attu\ are checked.
