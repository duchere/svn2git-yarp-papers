This section describes our mathematical framework. We first introduce
the basic notation (Section \ref{sec:back}), then we present our algorithm
for online model adaptation (Section \ref{sec:adapt}).

\subsection{Background}
\label{sec:back}

Assume $\xx_i \in \RR^m$ is an input vector and $y_i \in \RR$ is its
associated output.  Given a set $\{\xx_i,y_i\}_{i=1}^l$ of samples
drawn from an unknown probability distribution, we want to find a
function $f(\xx)$ such that it determines best
%determines 
the corresponding 
%associated 
$y$ for any future sample $\xx$.
%drawn from the same distribution.
This is a general framework that includes both regression and
classification. The problem can be solved in various
ways. Here we will use kernel methods and in particular Least-Squares
Support Vector Machines (LS-SVM) \cite{Cristianini00}. In LS-SVM the
function $f(\xx)$ is built as a linear model $\ww \cdot \phi(\xx) +
b$, where $\phi(\cdot)$ is a non-linear function mapping input samples
to a high-dimensional (possibly infinite-dimensional) Hilbert space
called \emph{feature space}. Rather than being directly specified, the
feature space is usually induced by a \emph{kernel function}
$K(\xx,\xx')$ which evaluates the inner product of two samples in the
feature space itself,
%between the images of vectors in the feature space,
i.e. $K(\xx,\xx')=\phi(\xx) \cdot \phi(\xx')$. A common kernel
function is the Gaussian kernel
\begin{equation}
  K(\xx,\xx')=\exp(-\gamma ||x-x'||^2)
  \label{eq:rbf}
\end{equation}
\noindent that will be used in all our experiments.

The parameters of the linear model, $\ww$ and $b$, are found by
minimizing a regularized least-squares loss function
\cite{Cristianini00}. This approach is similar to the well-known
formulation of Support Vector Machines (SVMs), the difference being
that the loss function is the square loss.
%and it
While this does not induce a sparse solution,
% On the other hand 
it makes it possible to write the leave-one-out error in closed form and with a negligible additional computational cost \cite{Rifkin07}. This is known to be approximately an unbiased
estimator of the classifier generalization error \cite{LuntzB69}. This
property is useful to find the best parameters for learning
(e.g. $\gamma$ in (\ref{eq:rbf})) and it will be used in our
adaptation method. Note that we use the same formulation to solve both
regression and classification problems.

\subsection{Model Adaptation}
\label{sec:adapt}

Let us assume we have $N$ pre-trained models stored in memory, trained
off-line on data acquired on $N$ different subjects. When the
prosthetic hand starts to be used by subject $N+1$, the system begins
to acquire new data. Given the differences among the subjects' arms
and as well in the placement of the electrodes, these new data will
belong to a new probability distribution, in general different from the $N$
previously modeled and stored. Still, as all subjects perform the
same grasp types, it is reasonable to expect that the new distribution
will be \emph{close} to at least one of those already modeled;
%We assume that the system has a number of previous models trained off-line on a
%number of different persons. The system then starts acquiring new data, coming
%from the person wearing the prosthetic hand. Given the differences in the
%electrodes placement and between the different subjects, the new data will
%belong to a distribution that is different from the ones of the other stored
%subject. Still we expect that the new distribution will be \emph{close} to at
%least one of the stored ones. 
then, it should be possible to use one of the pre-trained model as a
\emph{starting point} for training using the new data.
We expect that, by doing so, learning should be faster
than using the new data alone. To solve this problem we
generalize the framework for adaptation proposed in \cite{YangYH07} for SVMs:
the basic idea is to slightly change the regularization term of the
SVM cost functional, so that the solution will be "close" to the pre-trained
one. The optimization problem is \cite{YangYH07}

\begin{align}
  \min_{\ww,b} \frac{1}{2} \|\ww- \ww'\|^2 + C \sum_{i=1}^l \xi_i \nonumber \\
  \mbox{subject to} \;\;
  \xi_i \geq 0,\;\; y_i \ww \cdot \phi(\xx_i) + b \geq 1-\xi_i
  \label{eq:opt_prob_orig}
\end{align}

\noindent where $\ww'$ is a pre-trained model.
%In our opinion the above formulation has the disadvantage of giving a fixed
%weight to the previous model. 
In order to tune the closeness of $\ww$ to $\ww'$, we introduce a scaling factor
$\beta$ weighing the pre-trained model; also, we use the square loss and therefore
resort to the LS-SVM formulation. This way the leave-one-out error can be evaluated
in closed form, enabling automatic tuning of $\beta$. The optimization problem
reads now like this:

\begin{align} 
  \min_{\ww,b} \frac{1}{2} \|\ww- \beta \ww'\|^2 + \frac{C}{2} \sum_{i=1}^l \xi_i^2 \nonumber \\
  \mbox{subject to} \;\; y_i = \ww \cdot \phi(\xx_i) + b + \xi_i
  \label{eq:opt_prob}
\end{align}

\noindent and its solution is

\begin{equation}
  \ww = \beta \ww' + \sum_{i=1}^l \alpha_i \phi(\xx_i), \; \alpha_i \in \RR~.
  \label{eq:sol}
\end{equation}

Hence, the adapted model is given by the sum of the pre-trained model
$\ww'$ (weighted by $\beta$) and a new model $\ww$ obtained from the new samples.
(Note that when $\beta$ is $0$ we recover the original LS-SVM
formulation without any adaptation to previous data.)
As far as the leave-one-out error is concerned,
%let $v_i$ denote the
%$i$'th element of vector $\boldsymbol{v}$ and $M_{ij}$ the $(i,j)$'th element of matrix
%$\boldsymbol{M}$; let also $\boldsymbol{Y}$ be the vector of the $y_i, i=1,\cdots,l$, whereas %$\hat{\boldsymbol{Y}}$ is the vector of the predictions of the previous model $\ww'$ on the $l$ training samples. %Lastly, let $\boldsymbol{K}$ denote the kernel matrix, i.e., $K_{ij}=K(\xx_i,\xx_j)$. It is then possible to show %that the $\boldsymbol{\alpha}$ in (\ref{eq:sol}) evaluates to
we have that

\begin{align}
   \boldsymbol{\alpha}&=\boldsymbol{R} (\boldsymbol{Y}-\beta \hat{\boldsymbol{Y}})
\end{align}

\noindent where
$\boldsymbol{\alpha}$ is the vector of the $\alpha_i$'s in (\ref{eq:sol}),
$\boldsymbol{Y}$ is the vector of the $y_i$,
$\hat{\boldsymbol{Y}}$ is the vector of the predictions of the previous model, and
$\boldsymbol{R}=(\boldsymbol{K}+1/C)^{-1}$ with
$\boldsymbol{K}$ denoting the kernel matrix, i.e., $K_{ij}=K(\xx_i,\xx_j)$.
Let $\boldsymbol{\alpha}'=\boldsymbol{R}\boldsymbol{Y}$ and
$\boldsymbol{\alpha}''=\boldsymbol{R}\hat{\boldsymbol{Y}}$; from the equation above,
and using the same steps in \cite{Cawley06}, we have that the
prediction on sample $i$, when removed from the training set, is

\begin{align}
	y_i - \frac{\alpha'_i}{R_{ii}} + \beta \frac{\alpha''_i}{R_{ii}}
%	y_i - y^{-i} = \frac{\alpha'_i}{R_{ii}} - \beta \frac{\alpha''_i}{R_{ii}}
\end{align}

\noindent from which the leave-one-out-error is easily evaluated, according
to the required measure of accuracy for the problem at hand. Notice that,
in the above formula, $\beta$ is the only parameter; hence,
it is possible to set it optimally in order to minimize the leave-one-out error
while at the same time choosing the best pre-trained model for adaptation.

Notice also that the complexity of the algorithm is dominated by the evaluation
of the matrix $\boldsymbol{R}$, which must anyway occur while training; thus,
the computational complexity of evaluating the leave-one-out error is negligible, if
compared to the complexity of training. As a last remark,
we underline that the pre-trained model $\ww'$ can be
obtained by any training algorithm, as far as it can be expressed as a
weighted sum of kernel functions.  The framework is therefore very
general.
