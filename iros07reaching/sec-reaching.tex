\section{Reaching}
\label{sec:reaching}

In this section, we describe the two approaches we followed to solve
the reaching task on our robot. The first method 
uses the forward mapping between the arm joint space and the three 
dimensional position of the hand represented in the head reference 
frame. The second method uses a visual servoing technique to control the 
speed of the arm to minimize the position of the hand in the 
image plane with respect to a desired target (the fixated object).

\subsection{Open Loop Reaching} \label{sec:openReaching}
%
Suppose that the robot is tracking a target as described 
in Section \ref{Sec:gazecontrol}. In the assumption of perfect 
tracking (the visual error is zero), the three dimensional spatial position 
of the target with respect to the robot, denoted $\tilde {\mathbf x}_{target} 
\in \mathbb R^3$, 
is a function of the head configuration $\mathbf q_{head} =
\begin{bmatrix} \theta_y & \theta_p & \theta_r & \alpha_v^d & \alpha_v^c & \alpha_t^c \end{bmatrix}^\top \in \mathbb R^6$.
However, the representation of the target position, 
$\tilde {\mathbf x}_{target}$, in terms of the full head configuration, 
$\mathbf q_{head}$, is clearly redundant.
Specifically, the same target position can be represented by different 
head configurations. To obtain a one to one mapping between the target 
position and the head configuration we have to analyze the 
gaze controller. The latter maintains $\theta_r$ stationary 
($\theta_r^d = 0$) and poses additional constraints on the head joints. 
In particular we know from section \ref{Sec:gazecontrol} that the 
controller minimizes $\alpha_t^c$ and $\alpha^c_v$ (see equation 
(\ref{Eq:HeadEyeControl})) so that they asymptotically
converge to zero ($\alpha_t^c \rightarrow 0$ and 
$\alpha_v^c \rightarrow 0$). Ideally, after 
fixation is achieved, we have $
\mathbf {q}_{head}=
\begin{bmatrix} \theta_y & \theta_p & 0 & \alpha_v^d & 0 & 0 \end{bmatrix}^\top \in \mathbb R^6.
$
%
Since there exists a one to one mapping between the three dimensional 
position of the target 
$\tilde {\mathbf x}_{target}$ and the three non-zero variables 
$\theta_y$, $\theta_p$ and $\alpha_v^d$, we can define $
\mathbf x_{target}=
\begin{bmatrix} \theta_y & \theta_p & \alpha_v^d\end{bmatrix}^\top \in \mathbb R^3.
$
%
This new variable $\mathbf x_{target} \in \mathbb R^3$ uniquely codes the 
spatial position of the target in a way that resembles a three dimensional 
polar representation. In particular $\theta_y$ and $\theta_p$ code 
respectively \emph{azimuth} and \emph{elevation}, while \emph{distance} is 
substituted with $\alpha_v$ (the \emph{vergence} angle). 

If the robot tracks the hand, the same subset of the head joint space 
can be used to code the spatial location of the hand: $
\xhand=
\begin{bmatrix} \theta_y & \theta_p & \alpha_v^d\end{bmatrix}^\top \in \mathbb R^3.
$
%
Under these assumptions, the \emph{forward mapping} 
$f_{arm} : \mathbb R^4 \longrightarrow \mathbb R^3$
relates the arm configuration $\qarm$ with the position of the hand 
$\xhand$:
%
\begin{equation} 
\label{Eq:forward}
\mathbf x_{hand}=f_{arm}(\mathbf q_{arm}), \qquad f_{arm} : \mathbb R^4 \longrightarrow \mathbb R^3.\end{equation}
%
In the next section we show how a neural network could be trained to approximate
the arm forward mapping (Eq. \ref{Eq:forward}).

Suppose now that the robot is fixating a target and that we want to control 
the robot to reach for it. Formally the problem can be formulated 
as determining the value of $\qarm$ which solves the 
following optimization problem:
%
\begin{equation} 
\label{Eq:reaching1}
  \displaystyle\min_{\qarm} \left(J\right)=\displaystyle\min_{\qarm}
  \left\|\mathbf x_{hand} - \mathbf x_{target}\right\|^2,
\end{equation}
%
where $\mathbf x_{target}$ is measured from the encoders of the head, while 
$\mathbf x_{hand}$ is computed from $\qarm$ through Eq. (\ref{Eq:forward}).
Given the redundancy of the arm kinematics the minimization 
(\ref{Eq:reaching1}) has infinite solutions. We constrained the problem by 
forcing one of the joints, for example joint number 2 (one of the shoulder joints), to remain as close 
as possible to a predefined value $q_{20}$:
%
\begin{equation} 
\label{Eq:reaching2}
  \displaystyle\min_{\qarm}\left(J_c\right)=\displaystyle\min_{\qarm}
  \left[
  \left\|\mathbf x_{hand} - \mathbf x_{target}\right\|^2 + \left(q_{arm,2}-q_{20}\right)^2
  \right].
\end{equation}

The optimization of (\ref{Eq:reaching2}) can be performed numerically using 
various algorithms. In our implementation, we used 
the downhill simplex method \cite{ne:Computer:65} as implemented in 
\cite{mo:Press:90}.

\subsection{Learning the open loop reaching} 
\label{sec:learning-open-loop}
%
To learn the forward map of Eq. (\ref{Eq:forward}) we programmed 
the robot to perform random movements with the arm (chosen to uniformly sample 
a predefined region in the robot workspace). During this ``exploratory'' 
phase the robot tracked the hand, and collected samples of the form: $
%
\left(\begin{array}{cc}
  \qarm^i , \xhand^i\end{array}\right)_{i = 0,1\dots}$.
%
 A neural network was then trained to learn the relation:
%
\begin{equation} 
  \xhand=\hat{f}_{arm}\left(\qarm \right),
\end{equation}
%
which approximates Eq. (\ref{Eq:forward}).

In the experiment reported in this paper we collected a data set of 
about 2890 samples that we divided in a training set ($N_{train}=2168$
 samples) and 
a test set ($N_{test}=725$ samples). The neural network we employed was the 
Receptive Field Weighted Regression model proposed 
by \cite{schaal98Constructive}. This network implements an online learning
method, meaning that a learning step is performed every time a new 
sample is presented to the network. All samples in the training set were shown
to the network in a random order. After each training step the 
performance of the network was validated on the whole test set, by computing
the Mean Squared Error (\emph{MSE}) between each sample in the test set, 
$\xhand^i$, and the corresponding network output, 
$\mathbf{\hat{x}}_{hand}^i$:
%
\begin{equation}
\emph{MSE}=\frac{1}{N_{test}}\sum_{i=0}^{N_{test}-1}\|\xhand^i- \hat{\mathbf{x}}_{hand}^i\|^2
\end{equation}
%
The plot in figure \ref{Fig:learningerrors}
shows the trend of the error on the test set during learning. At the end of
the training the network reached the performance of $\emph{MSE}=5.7$ 
(with $\emph{STD}=10.4$).

In the experiment reported in this paper the network was trained offline. 
This was done to simplify the analysis of the results and to perform cross-validation 
on a predefined test set. However, the learning algorithm we used is purely 
incremental (each sample was shown to the network only once and immediately 
discarded), so in this regard it would be straightforward to convert the 
same approach to an online implementation.

\subsection{Closed Loop Reaching} \label{Eq:ClosedLoop}
%
If the robot could visually measure the distance
between the hand and the target, then reaching could also be solved
visually, by implementing a closed control loop. The underlying idea consists in
performing a preliminary (open loop) reaching movement and then refining the action
by visually correcting any residual error. 

We know that the Jacobian matrix relates arm velocities $\dot {\mathbf q}_{arm}$
with hand velocities in the image plane $\dot {\mathbf u}_{hand} = \left[ 
\begin{array}{ccc}
  \dot u_r & \dot u_l & \dot v_{l}
\end{array} \right]^\top$:
\begin{equation} 
  \dot {\mathbf u}_{hand}=
  \tilde{\mathbf J}\left(\mathbf q_{arm}, \mathbf q_{head}\right)
  \dot {\mathbf q}_{arm},
\end{equation}
where $\tilde{\jacobian} \in \mathbb R^{3 \times 4}$ depends on 
both the configuration of the arm and the head. In practice, assuming 
sufficiently small arm movements $\deltaqarm$, we can use the following 
approximation:
%
\begin{equation} 
\label{eq:jacobian1}
  \deltauhand=
  \tilde{\mathbf J}\left(\mathbf q_{arm}, \mathbf q_{head}\right)
  \deltaqarm,
\end{equation}
where $\deltauhand$ = $[ \Delta u_r$, $\Delta u_l$, $\Delta v_{l}]^\top$
is the image plane displacement resulting from the arm movement $\deltaqarm$. 
Due to the additional constraints posed by the head tracker, we showed
that only a subset of $\qhead$, $\xtarget$, is 
sufficient to uniquely identify the position of the head, so we 
can rewrite equation (\ref{eq:jacobian1}) as:
%
\begin{equation}
\label{eq:jacobian2}
  \deltauhand=
  \tilde{\jacobian}\left(\qarm, \xtarget\right)
  \deltaqarm, \qquad \tilde{\jacobian} \in \mathbb R^{3 \times 4}.
\end{equation}
%

Moreover, after the preliminary open loop reaching movement, we know
that $\xtarget = \hat f(\qarm)$ so that  Eq.
(\ref{eq:jacobian2}) can be further simplified to:
%
\begin{equation} 
\label{eq:jacobian3}
  \deltauhand=
  \jacobian \left(\qarm\right)
  \deltaqarm,\qquad \jacobian \in \mathbb R^{3\times4}
\end{equation}
%
where $\jacobian$ depends only on the arm joint configuration $\qarm$.

Suppose now that the robot has to reach for an object, whose visual position is 
represented by $\utarget$. To solve this problem 
the controller of the arm needs to compute the arm command which minimizes 
the error:
%
\begin{equation}
  e=\left\|\uhand-\utarget\right\|^2.
\end{equation}
%
When the head tracker has achieved convergence on the object, 
$\utarget \approx 0 $ and $e$ $\approx \left\|\uhand\right\|^2$.
Due to the redundancy of the arm, the minimization of $e$ can have
infinite solutions. Among them, the minimum norm solution corresponds
to the minimum joint speeds, that is:
%
\begin{equation}
\mathbf{\dot q}_{arm}=-k \cdot \jacobian^\# \uhand, 
\qquad \jacobian^\# \in \mathbb R^{4 \times 3},
\end{equation}
%
where $\jacobian^\#$ is the Moore-Penrose pseudo-inverse of $\jacobian$.

\subsection{Learning the Arm Jacobian}
%
In the previous section we used the Jacobian of the manipulator
$\jacobian$ (actually its pseudo-inverse $\jacobian^\#$) to 
control the arm to reach for a visually identified object. In 
this section we describe a procedure by which the robot can 
autonomously acquire $\jacobian$ and $\jacobian^\#$.

As described in Section \ref{sec:learning-open-loop}, the robot 
moves the arm randomly, while maintaining gaze on the hand. At 
the end of each movement $j$ the arm is in a configuration 
$\qarm^j$,  while the eyes are fixating the hand 
($\uhand \approx 0$) with a straight gaze
(the head tracker has reached convergence). Each 
arm configuration corresponds to a different value of 
$\jacobian_j=\jacobian\left(\qarm^j\right)$. 
Now the robot inhibits the head tracker and performs a sequence $m$
of small arm movements $\deltaqarm^k$ which perturb $\uhand$ of small amounts $\deltauhand^k$:$
  \left(\begin{array}{cc}
    \deltauhand^k , 
	\deltaqarm^k \end{array}
  \right)_{k = 0,1\dots,m}
$. All $m$ perturbations $\deltauhand^k$ and 
$\deltaqarm^k$ are linearly related through $\jacobian_i$ 
as described in Eq. (\ref{eq:jacobian2}). From these $m$ 
observations we can derive a least squares estimation of $\jacobian_j$ from 
which, in turn, we can compute the pseudo-inverse $\jacobian_j^\#$. 

Re-iterating this procedure leads to the collection of a series of examples:
$  \left(\begin{array}{cc}
    \qarm^j , \jacobian_j^\# \end{array}\right)_{j = 0,1\dots}$.
An approximation $\hat{\jacobian}^\#$ of $\jacobian^\#$ is finally
obtained by training a neural network:
%
\begin{equation}
\mathbf{g}\left(\qarm\right), \qquad g : \mathbb R^4 \longrightarrow \mathbb R^{12},
\end{equation}
%
whose output components are the coefficients of 
$\hat{\jacobian}^\# \in \mathbb R^{4 \times 3}$.

We report here the result of a learning session. The robot explored 210 
different arm positions $\qarm^j$ randomly distributed within a region of 
the workspace. In each of these positions the robot executed $m=10$ 
perturbations $\deltaqarm^k$ and estimated an example $\jacobian^\#_j$ for 
the neural network. Overall we collected 210 samples for $\jacobian^\#$. 
We trained the neural network on a subset of $N_{train}=158$ elements 
(training set); each 
sample was shown to the network only once and then discarded. Following each 
training step, we evaluated the performance of the network by computing 
\emph{MSE} on the remaining $N_{test}=52$ elements 
(test set). At the 
end of the training the error on the test set was $\emph{MSE}=2$ 
($\emph{STD}=7.1$). Figure \ref{Fig:learningerrors} reports the plot of 
the error during learning.
%
\begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{30mm}{\includegraphics[width=35mm]{./Figure/reachingError1.eps}}  & \hspace{.1cm} &
	  \parbox{30mm}{\includegraphics[width=35mm]{./Figure/jacobian-error.eps}}
  \end{tabular}
\end{center}
\caption{Left: learning of the arm forward function. Right: learning the 
arm jacobian. The plots represent the \emph{MSE} on 
the test set during learning. See text for more details}\label{Fig:learningerrors}
\end{figure}

