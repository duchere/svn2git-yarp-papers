In this section we report the experimental evaluation of OISVMs. We
first test the method on a set of databases commonly used in the
machine learning community (section \ref{exp:ml}); we then apply it to
the more realistic scenario of indoor place recognition across
different viewpoints and illumination conditions (section
\ref{exp:idol2}).

OISVMs have been implemented in Matlab and tested against the Matlab
wrapper for LIBSVM v2.82 \cite{ChangL01}. For the sake of comparison,
LIBSVM has been modified as suggested by the Authors in order to use
the squared norm of the slack variables $\xi$ in the cost function
(i.e., setting $p=2$ in \ref{eqn:svm_primal}); this modified version
is called LIBSVM-2 in the following. In the case of finite-dimensional
kernels, we only show the performance of LIBSVM-2 against OISVMs with
$\eta$ at machine precision, since the solution found by OISVM is
exactly equivalent; in the case of the infinite-dimensional kernel, we
show curves for various values of $\eta$.

\subsection{Experiments with Standard Benchmark Databases}
\label{exp:ml}

Figure \ref{fig:ad7} and Table \ref{table:t1} show the above
comparison on some standard benchmark databases, taken from the UCI
repository \cite{Newman+Hettich+Blake+Merz:1998}. For each benchmark,
data are obtained by running $10$ random $75\%/25\%$ train/test runs.

\begin{figure*}[!ht]
  \centering \footnotesize
  \begin{tabular}{cc}
  \includegraphics[width=0.47\linewidth]{figs/results/finite_kernel.pdf} &
  \includegraphics[width=0.47\linewidth]{figs/results/adult7.pdf}
  \end{tabular}
  \caption{Comparison of OISVM and LIBSVM on the UCI \emph{Diabetes}
  (left pane) and \emph{Adult7} (right pane) benchmark. Diabetes is
  solved using a cubic kernel (finite dimension), while Adult7 is
  solved using a Gaussian kernel (infinite dimension).}
\label{fig:ad7}
\end{figure*}

\begin{table*}
\begin{center}
\begin{tabular}[!h]{|l|c|c|c|}
\hline
   Benchm. & test error     & \% SVs          & \% SVs        \\
           &                & vs. norm-1      & vs. norm-2    \\ \hline
    Breast & $-0.47\pm0.82$ & $10.2\pm0.87$   & $22.1\pm1.77$ \\
  Diabetes & $0.52\pm2.1$   & $40.2\pm2.1$    & $55.2\pm2.73$ \\
  German   & $-0.40\pm1.15$ & $6.1\pm0.23$    & $9.2\pm0.35$  \\
  Heart    & $0.45\pm1.01$  & $10.3\pm0.56$   & $15.5\pm0.94$ \\ \hline
\end{tabular}
\end{center}
\label{table:t1}
\caption{Comparison of OISVM and LIBSVM on more UCI benchmarks, solved
 using a Gaussian kernel.}
\end{table*}

Consider Figure \ref{fig:ad7}, left pane: when all samples have been
loaded, LIBSVM-2 has about $427$ SVs, and LIBSVM about $290$. The
kernel used is cubic and the benchmark has $8$ features, therefore the
dimension of the space induced by the kernel is $\binom{10}{3} = 120$;
and, as expected, OISVM stops acquiring new SVs when there are exactly
$120$, although it loads a few more before reaching the limit. The
accuracy (not displayed) is exactly the same.

Consider now Figure \ref{fig:ad7}, right pane: the kernel used is
Gaussian and its dimension is infinite. The benchmark is relevantly
large (16100 samples) and complex (123 features). Nevertheless, with
an $\eta$ as small as $0.1$, at the end OISVM has less than $5\%$ of
the SVs used by LIBSVM-2 and less than $8\%$ with respect to
LIBSVM. The loss in accuracy is $0.063\%$ worse than that of LIBSVM-2.

Lastly, consider Table \ref{table:t1}, which shows the very same data
in compact form for $4$ more of the UCI databases. OISVMs attain a
number of SVs which is about $6\%$ to slightly more than $55\%$ of
LIBSVM, whereas the accuracy is basically the same, being
\emph{better} than LIBSVM in two cases (\emph{Diabetes}, this time
solved via a Gaussian kernel, and
\emph{Heart}).
