This file was created with JabRef 2.2b2.
Encoding: Cp1252

@ARTICLE{Billard,
  author = {M. A. Arbib and A. Billard and M. Iacoboni and E. Oztop},
  title = {Synthetic brain imaging: grasping, mirror neurons and imitation.},
  journal = {Neural Netw},
  year = {2000},
  volume = {13},
  pages = {975--997},
  number = {8-9},
  abstract = {The article contributes to the quest to relate global data on brain
	and behavior (e.g. from PET, Positron Emission Tomography, and fMRI.
	functional Magnetic Resonance Imaging) to the underpinning neural
	networks. Models tied to human brain imaging data often focus on
	a few "boxes" based on brain regions associated with exceptionally
	high blood flow, rather than analyzing the cooperative computation
	of multiple brain regions. For analysis directly at the level of
	such data, a schema-based model may be most appropriate. To further
	address neurophysiological data, the Synthetic PET imaging method
	uses computational models of biological neural circuitry based on
	animal data to predict and analyze the results of human PET studies.
	This technique makes use of the hypothesis that rCBF (regional cerebral
	blood flow) is correlated with the integrated synaptic activity
	in a localized brain region. We also describe the possible extension
	of the Synthetic PET method to fMRI. The second half of the paper
	then exemplifies this general research program with two case studies,
	one on visuo-motor processing for control of grasping (Section 3
	in which the focus is on Synthetic PET) and the imitation of motor
	skills (Sections 4 and 5, with a focus on Synthetic fMRI). Our discussion
	of imitation pays particular attention to data on the mirror system
	in monkey (neural circuitry which allows the brain to recognize
	actions as well as execute them). Finally, Section 6 outlines the
	immense challenges in integrating models of different portions of
	the nervous system which address detailed neurophysiological data
	from studies of primates and other species; summarizes key issues
	for developing the methodology of Synthetic Brain Imaging; and shows
	how comparative neuroscience and evolutionary arguments will allow
	us to extend Synthetic Brain Imaging even to language and other
	cognitive functions for which few or no animal data are available.},
  keywords = {Animals; Brain; Brain Mapping; Functional Laterality; Haplorhini;
	Humans; Magnetic Resonance Imaging; Models, Neurological; Nerve
	Net; Neurons; Psychomotor Performance; Regional Blood Flow; Tomography,
	Emission-Computed},
  owner = {Ale},
  pii = {S0893-6080(00)00070-8},
  pmid = {11156205},
  timestamp = {2007.03.13}
}

@PHDTHESIS{tesiCarlos,
  author = {Carlos Beltr{\'a}n-Gonz{\'a}lez},
  title = {Toward Predictive Robotics: The Role of Vision and Prediction on
	the Development of Active Systems.},
  school = {Doctoral Degree Thesis in Electronics and Informatics, XVIo Course,
	University of Genova},
  year = {2005}
}

@ARTICLE{Blakemore,
  author = {Sarah-Jayne Blakemore and Chris Frith},
  title = {The role of motor contagion in the prediction of action.},
  journal = {Neuropsychologia},
  year = {2005},
  volume = {43},
  pages = {260--267},
  number = {2},
  abstract = {It has been proposed that actions are intrinsically linked to perception.
	The idea behind these theories is that observing, imagining or in
	any way representing an action excites the motor programs used to
	execute that same action. There is neurophysiological evidence that
	neurons in premotor cortex of monkeys respond both during movement
	execution and during the observation of goal-directed action ('mirror
	neurons'). In humans, a proportion of the brain regions involved
	in executing actions are activated by the mere observation of action
	(the 'mirror system'). In this paper, we briefly review recent empirical
	studies of the mirror system, and discuss studies demonstrating
	interference effects between observed and executed movements. This
	interference, which might be a form of 'motor contagion', seems
	to arise specifically from the observation of biological movements,
	whether or not these movements are goal-directed. We suggest that
	this crude motor contagion is the first step in a more sophisticated
	predictive system that allows us to infer goals from the observation
	of actions.},
  doi = {10.1016/j.neuropsychologia.2004.11.012},
  keywords = {Humans; Movement; Nerve Net; Neurons; Perception; Psychomotor Performance},
  owner = {Ale},
  pii = {S0028-3932(04)00288-X},
  pmid = {15707910},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1016/j.neuropsychologia.2004.11.012}
}

@ARTICLE{Bootsma,
  author = {R. J. Bootsma and V. Fayt and F. T. Zaal and M. Laurent},
  title = {On the information-based regulation of movement : what Wann (1996)
	may want to consider.},
  journal = {Journal of Experimental Psychology: Human Perception and Performance.},
  year = {1997},
  volume = {23},
  pages = {1282--1289}
}

@ARTICLE{Buccino,
  author = {Giovanni Buccino and Ana Solodkin and Steven L Small},
  title = {Functions of the mirror neuron system: implications for neurorehabilitation.},
  journal = {Cogn Behav Neurol},
  year = {2006},
  volume = {19},
  pages = {55--63},
  number = {1},
  month = {Mar},
  abstract = {Mirror neurons discharge during the execution of hand object-directed
	actions and during the observation of the same actions performed
	by other individuals. These neurons were first identified in the
	ventral premotor cortex (area F5) and later on in the inferior parietal
	lobule of monkey brain, thus constituting the mirror neuron system.
	More recently, mirror neurons for mouth object-directed actions
	have also been found in the monkey. Several pieces of experimental
	data demonstrate that a mirror neuron system devoted to hand, mouth,
	and foot actions is also present in humans. In the present paper
	we review the experimental evidence on the role of the mirror neuron
	system in action understanding, imitation learning of novel complex
	actions, and internal rehearsal (motor imagery) of actions. On the
	basis of features of the mirror neuron system and its role in action
	understanding and imitation, we discuss the possible use of action
	observation and imitation as an approach for systematic training
	in the rehabilitation of patients with motor impairment of the upper
	limb after stroke.},
  keywords = {Animals; Brain Damage, Chronic; Cerebrovascular Accident; Functional
	Laterality; Hand; Haplorhini; Humans; Imitative Behavior; Motor
	Cortex; Motor Skills; Neural Pathways; Neuronal Plasticity; Physical
	Therapy Modalities; Recovery of Function},
  owner = {Ale},
  pii = {00146965-200603000-00007},
  pmid = {16633020},
  timestamp = {2007.03.13}
}

@ARTICLE{Fadiga,
  author = {L. Fadiga and L. Fogassi and G. Pavesi and G. Rizzolatti},
  title = {Motor facilitation during action observation: a magnetic stimulation
	study.},
  journal = {J Neurophysiol},
  year = {1995},
  volume = {73},
  pages = {2608--2611},
  number = {6},
  month = {Jun},
  abstract = {1. We stimulated the motor cortex of normal subjects (transcranial
	magnetic stimulation) while they 1) observed an experimenter grasping
	3D-objects, 2) looked at the same 3D-objects, 3) observed an experimenter
	tracing geometrical figures in the air with his arm, and 4) detected
	the dimming of a light. Motor evoked potentials (MEPs) were recorded
	from hand muscles. 2. We found that MEPs significantly increased
	during the conditions in which subjects observed movements. The
	MEP pattern reflected the pattern of muscle activity recorded when
	the subjects executed the observed actions. 3. We conclude that
	in humans there is a system matching action observation and execution.
	This system resembles the one recently described in the monkey.},
  keywords = {Arm; Electromyography; Evoked Potentials; Hand; Hand Strength; Humans;
	Magnetics; Motor Cortex; Movement; Muscle Contraction; Muscles;
	Psychomotor Performance},
  owner = {Ale},
  pmid = {7666169},
  timestamp = {2007.03.13}
}

@ARTICLE{Claes,
  author = {Terje Falck-Ytter and Gustaf Gredebäck and Claes von Hofsten},
  title = {Infants predict other people's action goals.},
  journal = {Nat Neurosci},
  year = {2006},
  volume = {9},
  pages = {878--879},
  number = {7},
  month = {Jul},
  abstract = {Do infants come to understand other people's actions through a mirror
	neuron system that maps an observed action onto motor representations
	of that action? We demonstrate that a specialized system for action
	perception guides proactive goal-directed eye movements in 12-month-old
	but not in 6-month-old infants, providing direct support for this
	view. The activation of this system requires observing an interaction
	between the hand of the agent and an object.},
  doi = {10.1038/nn1729},
  keywords = {Adult; Age Factors; Analysis of Variance; Child Development; Concept
	Formation; Eye Movements; Female; Goals; Humans; Imitative Behavior;
	Infant; Intention; Male; Personal Construct Theory; Photic Stimulation;
	Predictive Value of Tests; Time Factors; Visual Perception},
  owner = {Ale},
  pii = {nn1729},
  pmid = {16783366},
  timestamp = {2007.02.23},
  url = {http://dx.doi.org/10.1038/nn1729}
}

@MANUAL{YARP,
  title = {YARP: Yet Another Robot Platform.},
  author = {Paul Fitzpatrick and Giorgio Metta},
  organization = {MIT Computer Science Artificial Intelligence Laboratory},
  address = {http://sourceforge.net/projects/yarp0},
  year = {2004}
}

@ARTICLE{Flanagan_grip,
  author = {JR. Flanagan and AM. Wing},
  title = {The role of internal models in motion planning and control: evidence
	from grip force adjustments during movements of hand-held loads.},
  journal = {J Neurosci},
  year = {1997},
  volume = {17},
  pages = {1519--1528}
}

@ARTICLE{Flanagan,
  author = {J. Randall Flanagan and Roland S Johansson},
  title = {Action plans used in action observation.},
  journal = {Nature},
  year = {2003},
  volume = {424},
  pages = {769--771},
  number = {6950},
  month = {Aug},
  abstract = {How do we understand the actions of others? According to the direct
	matching hypothesis, action understanding results from a mechanism
	that maps an observed action onto motor representations of that
	action. Although supported by neurophysiological and brain-imaging
	studies, direct evidence for this hypothesis is sparse. In visually
	guided actions, task-specific proactive eye movements are crucial
	for planning and control. Because the eyes are free to move when
	observing such actions, the direct matching hypothesis predicts
	that subjects should produce eye movements similar to those produced
	when they perform the tasks. If an observer analyses action through
	purely visual means, however, eye movements will be linked reactively
	to the observed action. Here we show that when subjects observe
	a block stacking task, the coordination between their gaze and the
	actor's hand is predictive, rather than reactive, and is highly
	similar to the gaze-hand coordination when they perform the task
	themselves. These results indicate that during action observation
	subjects implement eye motor programs directed by motor representations
	of manual actions and thus provide strong evidence for the direct
	matching hypothesis.},
  doi = {10.1038/nature01861},
  keywords = {Adult; Eye Movements; Female; Hand; Humans; Male; Models, Biological;
	Movement; Photic Stimulation; Psychomotor Performance; Vision},
  owner = {Ale},
  pii = {nature01861},
  pmid = {12917683},
  timestamp = {2007.03.12},
  url = {http://dx.doi.org/10.1038/nature01861}
}

@ARTICLE{Gallese_social,
  author = {Vittorio Gallese},
  title = {The manifold nature of interpersonal relations: the quest for a common
	mechanism.},
  journal = {Philos Trans R Soc Lond B Biol Sci},
  year = {2003},
  volume = {358},
  pages = {517--528},
  number = {1431},
  month = {Mar},
  abstract = {It has been proposed that the capacity to code the 'like me' analogy
	between self and others constitutes a basic prerequisite and a starting
	point for social cognition. It is by means of this self/other equivalence
	that meaningful social bonds can be established, that we can recognize
	others as similar to us, and that imitation can take place. In this
	article I discuss recent neurophysiological and brain imaging data
	on monkeys and humans, showing that the 'like me' analogy may rest
	upon a series of 'mirror-matching' mechanisms. A new conceptual
	tool able to capture the richness of the experiences we share with
	others is introduced: the shared manifold of intersubjectivity.
	I propose that all kinds of interpersonal relations (imitation,
	empathy and the attribution of intentions) depend, at a basic level,
	on the constitution of a shared manifold space. This shared space
	is functionally characterized by automatic, unconscious embodied
	simulation routines.},
  doi = {10.1098/rstb.2002.1234},
  keywords = {Cognition; Empathy; Humans; Imitative Behavior; Interpersonal Relations;
	Social Behavior; Social Identification; Social Perception},
  owner = {Ale},
  pmid = {12689377},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1098/rstb.2002.1234}
}

@ARTICLE{Gallese,
  author = {V. Gallese and L. Fadiga and L. Fogassi and G. Rizzolatti},
  title = {Action recognition in the premotor cortex.},
  journal = {Brain},
  year = {1996},
  volume = {119 ( Pt 2)},
  pages = {593--609},
  month = {Apr},
  abstract = {We recorded electrical activity from 532 neurons in the rostral part
	of inferior area 6 (area F5) of two macaque monkeys. Previous data
	had shown that neurons of this area discharge during goal-directed
	hand and mouth movements. We describe here the properties of a newly
	discovered set of F5 neurons ("mirror neurons', n = 92) all of which
	became active both when the monkey performed a given action and
	when it observed a similar action performed by the experimenter.
	Mirror neurons, in order to be visually triggered, required an interaction
	between the agent of the action and the object of it. The sight
	of the agent alone or of the object alone (three-dimensional objects,
	food) were ineffective. Hand and the mouth were by far the most
	effective agents. The actions most represented among those activating
	mirror neurons were grasping, manipulating and placing. In most
	mirror neurons (92\%) there was a clear relation between the visual
	action they responded to and the motor response they coded. In approximately
	30\% of mirror neurons the congruence was very strict and the effective
	observed and executed actions corresponded both in terms of general
	action (e.g. grasping) and in terms of the way in which that action
	was executed (e.g. precision grip). We conclude by proposing that
	mirror neurons form a system for matching observation and execution
	of motor actions. We discuss the possible role of this system in
	action recognition and, given the proposed homology between F5 and
	human Brocca's region, we posit that a matching system, similar
	to that of mirror neurons exists in humans and could be involved
	in recognition of actions as well as phonetic gestures.},
  keywords = {Animals; Electromyography; Evoked Potentials, Visual; Frontal Lobe;
	Macaca; Motor Activity; Motor Cortex; Neurons},
  owner = {Ale},
  pmid = {8800951},
  timestamp = {2007.03.13}
}

@BOOK{Gibson,
  title = {The senses considered as perceptual systems.},
  publisher = {Allen {\&} Unwin},
  year = {1966},
  author = {J. J. Gibson},
  address = {London, UK}
}

@ARTICLE{Goodale,
  author = {M. A. Goodale and D. Pelisson and C. Prablanc},
  title = {Large adjustments in visually guided reaching do not depend on vision
	of the hand or perception of target displacement.},
  journal = {Nature},
  year = {1986},
  volume = {320},
  pages = {748--750},
  number = {6064},
  abstract = {When we reach towards an object that suddenly appears in our peripheral
	visual field, not only does our arm extend towards the object, but
	our eyes, head and body also move in such a way that the image of
	the object falls on the fovea. Popular models of how reaching movements
	are programmed have argued that while the first part of the limb
	movement is ballistic, subsequent corrections to the trajectory
	are made on the basis of dynamic feedback about the relative positions
	of the hand and the target provided by central vision. These models
	have assumed that the adjustments are dependent on seeing the hand
	moving with respect to the target. Here we present evidence that
	a change in the position of a visual target during a reaching movement
	can modify the trajectory even when vision of the hand is prevented.
	Moreover, these dynamic corrections to the trajectory of the moving
	limb occur without the subject perceiving the change in target location.
	These findings demonstrate that visual feedback about the relative
	position of the hand and target is not necessary for visually driven
	corrections in reaching to occur, and the mechanisms that maintain
	the apparent stability of a target in space are dissociable from
	those that mediate the visuomotor output directed at that target.},
  doi = {10.1038/320748a0},
  keywords = {Feedback; Humans; Movement; Vision; Visual Perception},
  owner = {Ale},
  pmid = {3703000},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1038/320748a0}
}

@ARTICLE{Gray,
  author = {R. Gray and D. Regan},
  title = {Accuracy of estimating time to collision using binocular and monocular
	information.},
  journal = {Vision Res},
  year = {1998},
  volume = {38},
  pages = {499--512},
  number = {4},
  month = {Feb},
  abstract = {We measured both the just-noticeable difference in time to collision
	(TTC) with an approaching object, and the absolute accuracy in estimating
	TTC in the following cases: only binocular information available;
	only monocular information available; both binocular and monocular
	information available as in the everyday situation. Observers could
	discriminate trial-to-trial variations in TTC on the basis of binocular
	information alone: the just-noticeable difference in TTC (5.1-9.8\%)
	was the same for a small (0.03 deg) target and for a large (0.7
	deg) target. In line with previous reports, when only monocular
	information was available, the just-noticeable difference in TTC
	was 5.8-12\% for the large target. However, observers could not
	reliably discriminate trial-to-trial variations in TTC with the
	small target when only monocular information was available. When
	both binocular and monocular information was available, the just-noticeable
	difference in TTC for the large target was not significantly different
	from when only binocular or only monocular information was available.
	Observers could make reliable estimates of absolute TTC using binocular
	information only. Errors ranged from 2.5 to 10\% for the large target,
	and 2.6 to 3.0\% for the small target, all being overestimates.
	Errors for the small target were the same or lower than errors for
	the large target. Observers could make reliable estimates of TTC
	with the large target using monocular information only. Errors ranged
	from 2.0 to 12\%, all being underestimates. Since monocular information
	did not provide a basis for reliable estimates of absolute TTC with
	the small target we conclude that, in everyday conditions, accurate
	estimates of TTC with small targets are based on binocular information
	when the object is small and is no more than a few metres away.
	Errors in estimating absolute TTC were lower in the case where both
	binocular and monocular information were available (as in the everyday
	situation) than when only binocular information or only monocular
	information was available. Errors ranged from 1.3 to 2.7\%. An error
	of 1.3\% approaches the accuracy required to explain the +/- 2.0-2.5
	msec accuracy with which top sports players can estimate the instant
	of impact between bat and ball.},
  keywords = {Depth Perception; Differential Threshold; Female; Humans; Male; Mathematics;
	Middle Aged; Motion Perception; Psychometrics; Time Factors; Vision,
	Binocular; Vision, Monocular},
  owner = {Ale},
  pii = {S0042-6989(97)00230-7},
  pmid = {9536374},
  timestamp = {2007.03.13}
}

@INPROCEEDINGS{paper_palline,
  author = {MM. Hayhoe and N. Mennie and B. Sullivan and K. Gorgos},
  title = {The role of Internal Models and Prediction in Catching balls.},
  booktitle = {From Reactive to Anticipatory Cognitive Embodied Systems.},
  year = {2005},
  organization = {American Association for Artificial Intelligence (AAAI).}
}

@BOOK{Hochberg,
  title = {Multiple Comparison Procedures.},
  publisher = {Wiley},
  year = {1987},
  author = { Y. Hochberg and A. C. Tamhane}
}

@ARTICLE{Claes_catch,
  author = {C. von Hofsten and P. Vishton and E. S. Spelke and Q. Feng and K.
	Rosander},
  title = {Predictive action in infancy: tracking and reaching for moving objects.},
  journal = {Cognition},
  year = {1998},
  volume = {67},
  pages = {255--285}
}

@ARTICLE{Iacoboni,
  author = {Marco Iacoboni},
  title = {Neural mechanisms of imitation.},
  journal = {Curr Opin Neurobiol},
  year = {2005},
  volume = {15},
  pages = {632--637},
  number = {6},
  month = {Dec},
  abstract = {Recent advances in our knowledge of the neural mechanisms of imitation
	suggest that there is a core circuitry of imitation comprising the
	superior temporal sulcus and the 'mirror neuron system', which consists
	of the posterior inferior frontal gyrus and adjacent ventral premotor
	cortex, as well as the rostral inferior parietal lobule. This core
	circuitry communicates with other neural systems according to the
	type of imitation performed. Imitative learning is supported by
	interaction of the core circuitry of imitation with the dorsolateral
	prefrontal cortex and perhaps motor preparation areas--namely, the
	mesial frontal, dorsal premotor and superior parietal areas. By
	contrast, imitation as a form of social mirroring is supported by
	interaction of the core circuitry of imitation with the limbic system.},
  doi = {10.1016/j.conb.2005.10.010},
  keywords = {Animals; Cerebral Cortex; Diagnostic Imaging; Humans; Interpersonal
	Relations; Learning; Mental Processes; Neurons},
  owner = {Ale},
  pii = {S0959-4388(05)00159-5},
  pmid = {16271461},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1016/j.conb.2005.10.010}
}

@ARTICLE{Jeannerod,
  author = {M. Jeannerod},
  title = {The representing brain: neural correlates of motor intention and
	imagery.},
  journal = {Behav. Brain Sci.},
  year = {1994},
  volume = {17},
  pages = {187--245}
}

@ARTICLE{Kawato,
  author = {M. Kawato},
  title = {Internal models for motor control and trajectory planning.},
  journal = {Curr Opin Neurobiol},
  year = {1999},
  volume = {9},
  pages = {718--727},
  number = {6},
  month = {Dec},
  abstract = {A number of internal model concepts are now widespread in neuroscience
	and cognitive science. These concepts are supported by behavioral,
	neurophysiological, and imaging data; furthermore, these models
	have had their structures and functions revealed by such data. In
	particular, a specific theory on inverse dynamics model learning
	is directly supported by unit recordings from cerebellar Purkinje
	cells. Multiple paired forward inverse models describing how diverse
	objects and environments can be controlled and learned separately
	have recently been proposed. The 'minimum variance model' is another
	major recent advance in the computational theory of motor control.
	This model integrates two furiously disputed approaches on trajectory
	planning, strongly suggesting that both kinematic and dynamic internal
	models are utilized in movement planning and control.},
  keywords = {Animals; Brain; Humans; Models, Neurological; Motor Activity; Psychomotor
	Performance},
  owner = {Ale},
  pii = {S0959-4388(99)00028-8},
  pmid = {10607637},
  timestamp = {2007.03.13}
}

@ARTICLE{Keysers2004,
  author = {Christian Keysers and David I Perrett},
  title = {Demystifying social cognition: a Hebbian perspective.},
  journal = {Trends Cogn Sci},
  year = {2004},
  volume = {8},
  pages = {501--507},
  number = {11},
  month = {Nov},
  abstract = {For humans and monkeys, understanding the actions of others is central
	to survival. Here we review the physiological properties of three
	cortical areas involved in this capacity: the STS, PF and F5. Based
	on the anatomical connections of these areas, and the Hebbian learning
	rule, we propose a simple but powerful account of how the monkey
	brain can learn to understand the actions of others by associating
	them with self-produced actions, at the same time discriminating
	its own actions from those of others. As this system appears also
	to exist in man, this network model can provide a framework for
	understanding human social perception.},
  doi = {10.1016/j.tics.2004.09.005},
  keywords = {Animals; Cerebral Cortex; Cognition; Haplorhini; Humans; Motor Neurons;
	Nerve Net; Psychomotor Performance; Social Perception; Visual Perception},
  owner = {Ale},
  pii = {S1364-6613(04)00243-8},
  pmid = {15491904},
  timestamp = {2007.03.12},
  url = {http://dx.doi.org/10.1016/j.tics.2004.09.005}
}

@MANUAL{GLUT,
  title = {The OpenGL Utility Toolkit (GLUT) Programming Interface},
  author = {Mark J. Kilgard},
  organization = {Silicon Graphics Inc.},
  month = {Dec},
  year = {1997},
  note = {API Version 3}
}

@ARTICLE{Dizio2,
  author = {J. R. Lackner and P. Dizio},
  title = {Gravitoinertial force background level affects adaptation to coriolis
	force perturbations of reaching movements.},
  journal = {J Neurophysiol},
  year = {1998},
  volume = {80},
  pages = {546--553},
  number = {2},
  month = {Aug},
  abstract = {We evaluated the combined effects on reaching movements of the transient,
	movement-dependent Coriolis forces and the static centrifugal forces
	generated in a rotating environment. Specifically, we assessed the
	effects of comparable Coriolis force perturbations in different
	static force backgrounds. Two groups of subjects made reaching movements
	toward a just-extinguished visual target before rotation began,
	during 10 rpm counterclockwise rotation, and after rotation ceased.
	One group was seated on the axis of rotation, the other 2.23 m away.
	The resultant of gravity and centrifugal force on the hand was 1.0
	g for the on-center group during 10 rpm rotation, and 1.031 g for
	the off-center group because of the 0.25 g centrifugal force present.
	For both groups, rightward Coriolis forces, approximately 0.2 g
	peak, were generated during voluntary arm movements. The endpoints
	and paths of the initial per-rotation movements were deviated rightward
	for both groups by comparable amounts. Within 10 subsequent reaches,
	the on-center group regained baseline accuracy and straight-line
	paths; however, even after 40 movements the off-center group had
	not resumed baseline endpoint accuracy. Mirror-image aftereffects
	occurred when rotation stopped. These findings demonstrate that
	manual control is disrupted by transient Coriolis force perturbations
	and that adaptation can occur even in the absence of visual feedback.
	An increase, even a small one, in background force level above normal
	gravity does not affect the size of the reaching errors induced
	by Coriolis forces nor does it affect the rate of reacquiring straight
	reaching paths; however, it does hinder restoration of reaching
	accuracy.},
  keywords = {Adaptation, Physiological; Arm; Conditioning (Psychology); Coriolis
	Force; Gravity, Altered; Humans; Movement; Multivariate Analysis;
	Psychomotor Performance},
  owner = {Ale},
  pmid = {9705449},
  timestamp = {2007.03.13}
}

@ARTICLE{Dizio,
  author = {J. R. Lackner and P. Dizio},
  title = {Rapid adaptation to Coriolis force perturbations of arm trajectory.},
  journal = {J Neurophysiol},
  year = {1994},
  volume = {72},
  pages = {299--313},
  number = {1},
  month = {Jul},
  abstract = {1. Forward reaching movements made during body rotation generate tangential
	Coriolis forces that are proportional to the cross product of the
	angular velocity of rotation and the linear velocity of the arm.
	Coriolis forces are inertial forces that do not involve mechanical
	contact. Virtually no constant centrifugal forces will be present
	in the background when motion of the arm generates transient Coriolis
	forces if the radius of body rotation is small. 2. We measured the
	trajectories of arm movements made in darkness to a visual target
	that was extinguished as movement began. The reaching movements
	were made prerotation, during rotation at 10 rpm in a fully enclosed
	rotating room, and postrotation. During testing the subject was
	seated at the center of the room and pointed radially. Neither visual
	nor tactile feedback about movement accuracy was present. 3. In
	experiment 1, subjects reached at a fast or slow rate and their
	hands made contact with a horizontal surface at the end of the reach.
	Their initial perrotary movements were highly significantly deviated
	relative to prerotation in both trajectories and end-points in the
	direction of the transient Coriolis forces that had been generated
	during the reaches. Despite the absence of visual and tactile feedback
	about reaching accuracy, all subjects rapidly regained straight
	movement trajectories and accurate endpoints. Postrotation, transient
	errors of opposite sign were present for both trajectories and endpoints.
	4. In a second experiment the conditions were identical except that
	subjects pointed just above the location of the extinguished target
	so that no surface contact was involved. All subjects showed significant
	initial perrotation deviations of trajectories and endpoints in
	the direction of the transient Coriolis forces. With repeated reaches
	the trajectories, as viewed from above, again became straight, but
	there was only partial restoration of endpoint accuracy, so that
	subjects reached in a straight line to the wrong place. Aftereffects
	of opposite sign were transiently present in the postrotary movements.
	5. These observations fail to support current equilibrium point
	models, both alpha and lambda, of movement control. Such theories
	would not predict endpoint errors under our experimental conditions,
	in which the Coriolis force is absent at the beginning and end of
	a movement. Our results indicate that detailed aspects of movement
	trajectory are being continuously monitored on the basis of proprioceptive
	feedback in relation to motor commands. Adaptive compensations can
	be initiated after one perturbation despite the absence of either
	visual or tactile feedback about movement trajectory and endpoint
	error. Moreover, movement trajectory and end-point can be remapped
	independently.(ABSTRACT TRUNCATED AT 400 WORDS)},
  keywords = {Acceleration; Attention; Humans; Individuality; Kinesthesis; Musculoskeletal
	Equilibrium; Orientation; Psychomotor Performance; Reaction Time;
	Rotation},
  owner = {Ale},
  pmid = {7965013},
  timestamp = {2007.03.13}
}

@INCOLLECTION{Lacquaniti_book,
  author = {F. Lacquaniti and M. Carrozzo and N. A. Borghese},
  title = {The role of vision in tuning anticipatory motor responses of the
	limbs.},
  booktitle = {Multisensory control of movement.},
  publisher = {Oxford University Press},
  year = {1993},
  editor = {A. Berthoz},
  pages = {379--393},
  address = {Oxford, UK}
}

@ARTICLE{Lacquaniti1,
  author = {F. Lacquaniti and C. Maioli},
  title = {The role of preparation in tuning anticipatory and reflex responses
	during catching.},
  journal = {J Neurosci},
  year = {1989},
  volume = {9},
  pages = {134--148},
  number = {1},
  month = {Jan},
  abstract = {The pattern of muscle responses associated with catching a ball in
	the presence of vision was investigated by independently varying
	the height of the drop and the mass of the ball. It was found that
	the anticipatory EMG responses comprised early and late components.
	The early components were produced at a roughly constant latency
	(about 130 msec) from the time of ball release. Their mean amplitude
	decreased with increasing height of fall. Late components represented
	the major build-up of muscle activity preceding the ball's impact
	and were accompanied by limb flexion. Their onset time was roughly
	constant (about 100 msec) with respect to the time of impact (except
	in wrist extensors). This indicates that the timing of these responses
	was based on an accurate estimate of the instantaneous values of
	the time-to-contact (time remaining before impact). The mean amplitude
	of the late anticipatory responses increased linearly with the expected
	momentum of the ball at impact. The reflex responses evoked by the
	ball's impact consisted in a short-latency coactivation of flexor
	and extensor muscles at the elbow and wrist joints. Their mean amplitude
	generally increased with the intensity of the perturbation both
	in the stretched muscles and in the shortening muscles. We argue
	that both the anticipatory and the reflex coactivation are centrally
	preset in preparation for catching and are instrumental for stabilizing
	limb posture after impact. A model with linear, time-varying viscoelastic
	coefficients was used to assess the neural and mechanical contributions
	to the damping of limb oscillations induced by the ball's impact.
	The model demonstrates that (1) anticipatory muscle stiffening and
	anticipatory flexion of the limb are synergistic in building up
	resistance of the hand to vertical displacement and (2) the reflex
	coactivation produces a further increment of hand stiffness and
	viscosity which tends to offset the decrement which would result
	from the limb extension produced by the impact.},
  keywords = {Adult; Arm; Biomechanics; Hand; Humans; Male; Middle Aged; Motor Activity;
	Motor Skills; Muscles; Psychomotor Performance; Reflex; Time Factors;
	Vision},
  owner = {Ale},
  pmid = {2913200},
  timestamp = {2007.03.13}
}

@ARTICLE{Lee,
  author = {D. N. Lee and F. R. van der Weel and T. Hitchcock and E. Matejowsky
	and J. D. Pettigrew},
  title = {Common principle of guidance by echolocation and vision.},
  journal = {J Comp Physiol [A]},
  year = {1992},
  volume = {171},
  pages = {563--571},
  number = {5},
  month = {Dec},
  abstract = {1. Using echolocation, bats move as gracefully as birds through the
	cluttered environment, suggesting common principles of optic and
	acoustic guidance. We tested the idea by analysing braking control
	of bats (Macroderma gigas) flying through a narrow aperture with
	eyes covered and uncovered. 2. Though braking control would seem
	to require rapid detection of distance and velocity and computation
	of deceleration, simpler control is possible using the tau function
	of any sensory variable S that is a power function of distance to
	aperture. Tau function of S is tau (S) = S/S (the dot means time
	derivative). Controlled braking is achievable by keeping tau (S)
	constant. 3. Previous experiments indicated the tau (S) constant
	procedure is followed by humans and birds in visually controlling
	braking. Analysis of the bats' flight trajectories indicated they
	too followed the braking procedure using echolocation. 4. The tau
	function of echo-delay or of echo-intensity or of angle subtended
	by directions of echoes from two points on the approach surface
	could be used to control braking. Aperture size was modulated during
	flight on some trials in an attempt to test between these possibilities,
	but the results were inconclusive.},
  keywords = {Animals; Chiroptera; Conditioning, Operant; Echolocation; Female;
	Flight, Animal; Food; Reward; Vision},
  owner = {Ale},
  pmid = {1494137},
  timestamp = {2007.03.13}
}

@ARTICLE{Liberman,
  author = {Liberman and  Whalen},
  title = {On the relation of speech to language.},
  journal = {Trends Cogn Sci},
  year = {2000},
  volume = {4},
  pages = {187--196},
  number = {5},
  month = {May},
  abstract = {There are two widely divergent theories about the relation of speech
	to language. The more conventional view holds that the elements
	of speech are sounds that rely for their production and perception
	on two wholly separate processes, neither of which is distinctly
	linguistic. Accordingly, the primary motor and perceptual representations
	are inappropriate for linguistic purposes until a cognitive process
	of some sort has connected them to language and to each other. The
	less conventional theory takes the speech elements to be articulatory
	gestures that are the primary objects of both production and perception.
	Those gestures form a natural class that serves a linguistic function
	and no other. Therefore, their representations are immediately linguistic,
	requiring no cognitive intervention to make them appropriate for
	use by the other components of the language system. The unconventional
	view provides the more plausible answers to three important questions:
	(1) How was the necessary parity between speaker and listener established
	in evolution, and how maintained? (2) How does speech meet the special
	requirements that underlie its ability, unique among natural communication
	systems, to encode an indefinitely large number of meanings? (3)
	What biological properties of speech make it easier than the reading
	and writing of its alphabetic transcription?},
  owner = {Ale},
  pii = {S1364-6613(00)01471-6},
  pmid = {10782105},
  timestamp = {2007.03.13}
}

@INPROCEEDINGS{McIntyre2,
  author = {J. McIntyre and P. Senot and P. Prevost and M. Zago and F. Lacquaniti
	and A. Berthoz},
  title = {The use of on-line perceptual invariants versus cognitive internal
	models for the predictive control of movement and action.},
  booktitle = {Neural Engineering.},
  year = {2003},
  pages = {438--441},
  note = {Conference Proceedings. First International IEEE EMBS Conference}
}

@ARTICLE{McIntyre,
  author = {J. McIntyre and M. Zago and A. Berthoz and F. Lacquaniti},
  title = {Does the brain model Newton's laws?},
  journal = {Nat Neurosci},
  year = {2001},
  volume = {4},
  pages = {693--694},
  number = {7},
  month = {Jul},
  doi = {10.1038/89477},
  keywords = {Brain; Gravitation; Movement; Physics; Psychomotor Performance; Space
	Flight; Weightlessness},
  owner = {Ale},
  pii = {89477},
  pmid = {11426224},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1038/89477}
}

@ARTICLE{MettaFitz,
  author = {G. Metta and P. Fitzpatrick},
  title = {Early Integration of Vision and Manipulation.},
  journal = {Adaptive Behavior},
  year = {2003},
  volume = {11},
  pages = {109--128},
  number = {2}
}

@INPROCEEDINGS{RobotCub,
  author = {G. Metta and D. Vernon and G. Sandini},
  title = {The RobotCub Approach to the Development of Cognition.},
  booktitle = {Implications of Emergent Systems for a Common Research Agenda in
	Epigenetic Robotics.},
  year = {2005}
}

@ARTICLE{Mussa,
  author = {F. A. Mussa-Ivaldi and E. Bizzi},
  title = {Motor learning through the combination of primitives.},
  journal = {Philos Trans R Soc Lond B Biol Sci},
  year = {2000},
  volume = {355},
  pages = {1755--1769},
  number = {1404},
  month = {Dec},
  abstract = {In this paper we discuss a new perspective on how the central nervous
	system (CNS) represents and solves some of the most fundamental
	computational problems of motor control. In particular, we consider
	the task of transforming a planned limb movement into an adequate
	set of motor commands. To carry out this task the CNS must solve
	a complex inverse dynamic problem. This problem involves the transformation
	from a desired motion to the forces that are needed to drive the
	limb. The inverse dynamic problem is a hard computational challenge
	because of the need to coordinate multiple limb segments and because
	of the continuous changes in the mechanical properties of the limbs
	and of the environment with which they come in contact. A number
	of studies of motor learning have provided support for the idea
	that the CNS creates, updates and exploits internal representations
	of limb dynamics in order to deal with the complexity of inverse
	dynamics. Here we discuss how such internal representations are
	likely to be built by combining the modular primitives in the spinal
	cord as well as other building blocks found in higher brain structures.
	Experimental studies on spinalized frogs and rats have led to the
	conclusion that the premotor circuits within the spinal cord are
	organized into a set of discrete modules. Each module, when activated,
	induces a specific force field and the simultaneous activation of
	multiple modules leads to the vectorial combination of the corresponding
	fields. We regard these force fields as computational primitives
	that are used by the CNS for generating a rich grammar of motor
	behaviours.},
  keywords = {Animals; Central Nervous System; Extremities; Humans; Learning; Memory;
	Models, Biological; Motion; Motor Cortex; Rats; Spinal Cord},
  owner = {Ale},
  pmid = {11205339},
  timestamp = {2007.03.13}
}

@ARTICLE{Pellegrino,
  author = {G. di Pellegrino and L. Fadiga and L. Fogassi and V. Gallese and
	G. Rizzolatti},
  title = {Understanding motor events: a neurophysiological study.},
  journal = {Exp Brain Res},
  year = {1992},
  volume = {91},
  pages = {176--180},
  number = {1},
  abstract = {Neurons of the rostral part of inferior premotor cortex of the monkey
	discharge during goal-directed hand movements such as grasping,
	holding, and tearing. We report here that many of these neurons
	become active also when the monkey observes specific, meaningful
	hand movements performed by the experimenters. The effective experimenters'
	movements include among others placing or retrieving a piece of
	food from a table, grasping food from another experimenter's hand,
	and manipulating objects. There is always a clear link between the
	effective observed movement and that executed by the monkey and,
	often, only movements of the experimenter identical to those controlled
	by a given neuron are able to activate it. These findings indicate
	that premotor neurons can retrieve movements not only on the basis
	of stimulus characteristics, as previously described, but also on
	the basis of the meaning of the observed actions.},
  keywords = {Animals; Arm; Electrophysiology; Hand; Macaca nemestrina; Motor Cortex;
	Motor Neurons; Movement; Muscles; Neurons},
  owner = {Ale},
  pmid = {1301372},
  timestamp = {2007.03.13}
}

@ARTICLE{Port,
  author = {N. L. Port and D. Lee and P. Dassonville and A. P. Georgopoulos},
  title = {Manual interception of moving targets. I. Performance and movement
	initiation.},
  journal = {Exp Brain Res},
  year = {1997},
  volume = {116},
  pages = {406--420},
  number = {3},
  month = {Oct},
  abstract = {We investigated the capacities of human subjects to intercept moving
	targets in a two-dimensional (2D) space. Subjects were instructed
	to intercept moving targets on a computer screen using a cursor
	controlled by an articulated 2D manipulandum. A target was presented
	in 1 of 18 combinations of three acceleration types (constant acceleration,
	constant deceleration, and constant velocity) and six target motion
	times, from 0.5 to 2.0 s. First, subjects held the cursor in a start
	zone located at the bottom of the screen along the vertical meridian.
	After a pseudorandom hold period, the target appeared in the lower
	left or right corner of the screen and traveled at 45 degrees toward
	an interception zone located on the vertical meridian 12.5 cm above
	the start zone. For a trial to be considered successful, the subject's
	cursor had to enter the interception zone within 100 ms of the target's
	arrival at the center of the interception zone and stay inside a
	slightly larger hold zone. Trials in which the cursor arrived more
	than 100 ms before the target were classified as "early errors,"
	whereas trials in which the cursor arrived more than 100 ms after
	the target were classified as "late errors." Given the criteria
	above, the task proved to be difficult for the subjects. Only 41.3\%
	(1080 out of 2614) of the movements were successful, whereas the
	remaining 58.7\% were temporal (i.e., early or late) errors. A large
	majority of the early errors occurred in trials with decelerating
	targets, and their percentage tended to increase with longer target
	motion times. In contrast, late errors occurred in relation to all
	three target acceleration types, and their percentage tended to
	decrease with longer target motion times. Three models of movement
	initiation were investigated. First, the threshold-distance model,
	originally proposed for optokinetic eye movements to constant-velocity
	visual stimuli, maintains that response time is composed of two
	parts, a constant processing time and the time required for the
	stimulus to travel a threshold distance. This model only partially
	fit our data. Second, the threshold-tau model, originally proposed
	as a strategy for movement initiation, assumes that the subject
	uses the first-order estimate of time-to-contact (tau) to determine
	when to initiate the interception movement. Similar to the threshold
	distance model, the threshold-tau model only partially fit the data.
	Finally, a dual-strategy model was developed which allowed for the
	adoption of either of the two strategies for movement initiation;
	namely, a strategy based on the threshold-distance model ("reactive"
	strategy) and another based on the threshold-tau model ("predictive"
	strategy). This model provided a good fit to the data. In fact,
	individual subjects preferred to use one or the other strategy.
	This preference was allowed to be manifested at long target motion
	times, whereas shorter target motion times (i.e., 0.5 s and 0.8
	s) forced the subjects to use only the reactive strategy.},
  keywords = {Adult; Analysis of Variance; Computer Simulation; Female; Humans;
	Male; Motion; Psychomotor Performance; Reproducibility of Results},
  owner = {Ale},
  pmid = {9372290},
  timestamp = {2007.03.13}
}

@ARTICLE{Pozzo,
  author = {Thierry Pozzo and Charalambos Papaxanthis and Jean Luc Petit and
	Nicolas Schweighofer and Natale Stucchi},
  title = {Kinematic features of movement tunes perception and action coupling.},
  journal = {Behav Brain Res},
  year = {2006},
  volume = {169},
  pages = {75--82},
  number = {1},
  month = {Apr},
  abstract = {How do we extrapolate the final position of hand trajectory that suddenly
	vanishes behind a wall? Studies showing maintenance of cortical
	activity after objects in motion disappear suggest that internal
	model of action may be recalled to reconstruct the missing part
	of the trajectory. Although supported by neurophysiological and
	brain imaging studies, behavioural evidence for this hypothesis
	is sparse. Further, in humans, it is unknown if the recall of internal
	model of action at motion observation can be tuned with kinematic
	features of movement. Here, we propose a novel experiment to address
	this question. Each stimulus consisted of a dot moving either upwards
	or downwards, and corresponding to vertical arm movements that were
	masked in the last part of the trajectory. The stimulus could either
	move according to biological and or non-biological kinematic laws
	of pointing tasks. We compared subjects' estimations of the stimulus
	vanishing or final positions after biological and after non-biological
	motion displays. Subjects systematically overestimated the vanishing
	and final position for the two directions (up and down) and the
	two kinematics displayed (biological and non-biological). However,
	estimation of the final position decreased in precision and increased
	in variability for movements that violated the kinematic laws of
	arm pointing task. The results suggest that motion inference does
	not rely only upon visual extrapolating mechanisms based on past
	visual trajectory information. We propose that motion estimation
	relies on internal models that contain specific kinematic details
	of vertical arm movement, which can be rapidly recalled during motion
	observation.},
  doi = {10.1016/j.bbr.2005.12.005},
  keywords = {Adult; Biomechanics; Distance Perception; Female; Humans; Imagination;
	Male; Motion Perception; Pattern Recognition, Visual; Problem Solving},
  owner = {Ale},
  pii = {S0166-4328(05)00546-2},
  pmid = {16430976},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1016/j.bbr.2005.12.005}
}

@ARTICLE{Regan,
  author = {Regan and  Gray},
  title = {Visually guided collision avoidance and collision achievement.},
  journal = {Trends Cogn Sci},
  year = {2000},
  volume = {4},
  pages = {99--107},
  number = {3},
  month = {Mar},
  abstract = {To survive on today's highways, a driver must have highly developed
	skills in visually guided collision avoidance. To play such games
	as cricket, tennis or baseball demands accurate, precise and reliable
	collision achievement. This review discusses evidence that some
	of these tasks are performed by predicting where an object will
	be at some sharply defined instant, several hundred milliseconds
	in the future, while other tasks are performed by utilizing the
	fact that some of our motor actions change what we see in ways that
	obey lawful relationships, and can therefore be learned. Several
	monocular and binocular visual correlates of the direction of an
	object's motion relative to the observer's head have been derived
	theoretically, along with visual correlates of the time to collision
	with an approaching object. Although laboratory psychophysics can
	identify putative neural mechanisms by showing which of the known
	correlates are processed by the human visual system independently
	of other visual information, it is only field research on, for example,
	driving, aviation and sport that can show which visual cues are
	actually used in these activities. This article reviews this research
	and describes a general psychophysically based rational approach
	to the design of such field studies.},
  owner = {Ale},
  pii = {S1364661399014424},
  pmid = {10689344},
  timestamp = {2007.03.13}
}

@ARTICLE{Regan1997,
  author = {D. Regan},
  title = {Visual factors in hitting and catching.},
  journal = {J Sports Sci},
  year = {1997},
  volume = {15},
  pages = {533--558},
  number = {6},
  month = {Dec},
  abstract = {To hit or catch an approaching ball, it is necessary to move a bat
	or hand to the right place at the right time. The performance of
	top sports players is remarkable: positional errors of less than
	5 cm and temporal errors of less than 2 or 3 ms are reliably maintained.
	There are three schools of thought about how this is achieved. One
	holds that predictive visual information about where the ball will
	be at some future instance (when) is used to achieve the hit or
	catch. The second holds that the bat or hand is moved to the correct
	position by exploiting some relation between visual information
	and the required movement. The third focuses on the use of prior
	knowledge to supplement inadequate visual information. For a rigid
	spherical ball travelling at constant speed along or close to the
	line of sight, the retinal images contain both binocular and monocular
	correlates of the ball's instantaneous direction of motion in depth.
	Also, the retinal images contain both binocular and monocular information
	about time of arrival. Humans can unconfound and use this visual
	information, but they are unable to estimate the absolute distance
	of the ball or its approach speed other than crudely. In cricket,
	this visual inadequacy allows a slow bowler to cause the batsman
	to misjudge where the ball will hit the ground. Such a bowler uses
	a three-pronged strategy: first, to deliver the ball in such a way
	as to prevent the batsman from obtaining the necessary visual information
	until it is too late to react; secondly, to force the batsman to
	rely entirely on inadequate retinal image information; thirdly,
	to allow the batsman to learn a particular relationship between
	the early part of the ball's flight and the point where the ball
	hits the ground, and then to change the relationship with such skill
	that the batsman does not detect the change.},
  keywords = {Algorithms; Baseball; Feedback; Forecasting; Humans; Learning; Motion
	Perception; Motor Skills; Psychomotor Performance; Reaction Time;
	Reflex; Reproducibility of Results; Retina; Space Perception; Sports;
	Time Factors; Vision, Binocular; Vision, Monocular; Visual Acuity;
	Visual Perception},
  owner = {Ale},
  pmid = {9486432},
  timestamp = {2007.03.13}
}

@INCOLLECTION{Lincoln,
  author = {D. Regan and L. Kaufman and J. Lincoln},
  title = {Motion in depth and visual acceleration.},
  booktitle = {Handbook of perception and human performance: Sensory processes and
	perception.},
  publisher = {Wiley},
  year = {1986},
  editor = {K. Boff and L. Kaufman and J. Thomas},
  pages = {1--46},
  address = {New York, NY}
}

@ARTICLE{Rizzolatti,
  author = {G. Rizzolatti and L. Craighero},
  title = {The mirror-neuron system.},
  journal = {Annu. Rev. Neurosci.},
  year = {2004},
  volume = {27},
  pages = {169--192}
}

@ARTICLE{Fogassi,
  author = {G. Rizzolatti and L. Fadiga and L. Fogassi and V. Gallese},
  title = {Resonance behaviors and mirror neurons.},
  journal = {Arch Ital Biol.},
  year = {1999},
  volume = {137},
  pages = {85--100},
  number = {2--3}
}

@ARTICLE{Rizzolatti_pet,
  author = {G. Rizzolatti and L. Fadiga and M. Matelli and V. Bettinardi and
	E. Paulesu and D. Perani and F. Fazio},
  title = {Localization of grasp representations in human by PET: 1. Observation
	versus execution.},
  journal = {Exp. Brain Res.},
  year = {1996},
  volume = {111},
  pages = {246--252}
}

@ARTICLE{Rizzolatti_2001,
  author = {G. Rizzolatti and L. Fogassi and L.Gallese},
  title = {Neurophysiological mechanisms underlying the understanding and imitation
	of action.},
  journal = {Nat. Rev. Neurosci.},
  year = {2001},
  volume = {2},
  pages = {661--670}
}

@ARTICLE{basket,
  author = {M. Romani and P.Cesari and SM. Aglioti },
  title = {Internal models of target motion: Expected dynamics overrides measured
	kinematics in timing manual interceptions.},
  journal = {International journal of sport psychology},
  year = {2003},
  volume = {2},
  pages = {1620--1634},
  month = {may}
}

@ARTICLE{Claes_muro,
  author = {Kerstin Rosander and Claes von Hofsten},
  title = {Infants' emerging ability to represent occluded object motion.},
  journal = {Cognition},
  year = {2004},
  volume = {91},
  pages = {1--22},
  number = {1},
  month = {Feb},
  abstract = {The emerging ability to represent an oscillating moving object over
	occlusions was studied in 7-21-week-old infants. The object moved
	at 0.25 Hz and was either occluded at the center of the trajectory
	(for 0.3 s) or at one turning point (for 0.7 s). Each trial lasted
	for 20 s. Both eye and head movements were measured. By using two
	kinds of motion, sinusoidal (varying velocity) and triangular (constant
	velocity), infants' ability to take velocity change into account
	when predicting the reappearance of the moving object was tested.
	Over the age period studied, performance at the central occluder
	progressed from almost total ignorance of what happened to consistent
	predictive behavior. From around 12 weeks of age, infants began
	to form representations of the moving object that persisted over
	temporary occlusions. At around 5 months of age these representations
	began to incorporate the dynamics of the represented motion. Strong
	learning effects were obtained over single trials, but there was
	no evidence of retention between trials. The individual differences
	were profound.},
  keywords = {Electrooculography; Female; Humans; Infant; Male; Motion Perception;
	Movement; Visual Perception},
  owner = {Ale},
  pii = {S0010027703001665},
  pmid = {14711489},
  timestamp = {2007.03.13}
}

@ARTICLE{Rushton,
  author = {S. K. Rushton and J. P. Wann},
  title = {Weighted combination of size and disparity : a computational model
	for timing a ball catch.},
  journal = {Nature Neuroscience},
  year = {1999},
  volume = {2},
  pages = {186--190}
}

@ARTICLE{Oculomanual,
  author = {K. Scarchilli and JL. Vercher},
  title = {The oculomanual coordination control center takes into account the
	mechanical properties of the arm.},
  journal = {Experimental Brain Results},
  year = {1999},
  volume = {124},
  pages = {42--52}
}

@MANUAL{OpenGL,
  title = {The OpenGL Graphics System: A Specification},
  author = {Mark Segal and Kurt Akeley},
  organization = {Silicon Graphics Inc.},
  month = {Jun},
  year = {1992},
  note = {Version 1.0}
}

@ARTICLE{Senot,
  author = {Patrice Senot and Pascal Provost and Joseph McIntyre},
  title = {Estimating time to contact and impact velocity when catching an accelerating
	object with the hand.},
  journal = {Journal of experimental psychology. Human perception and performance.},
  year = {2003},
  volume = {29},
  pages = {219--237},
  number = {1}
}

@ARTICLE{Senot_updown,
  author = {P. Senot and M. Zago and F. Lacquaniti and J. McIntyre},
  title = {Anticipating the Effects of Gravity When Intercepting Moving Objects:
	Differentiating Up and Down Based on Nonvisual Cues.},
  journal = {Journal of Neurophysiology},
  year = {2005},
  volume = {94},
  pages = {4471--4480}
}

@ARTICLE{Mussa_Kaw,
  author = {R. Shadmehr and F. A. Mussa-Ivaldi},
  title = {Adaptive representation of dynamics during learning of a motor task.},
  journal = {J Neurosci},
  year = {1994},
  volume = {14},
  pages = {3208--3224}
}

@ARTICLE{Vestibular,
  author = {L. Snyder},
  title = {This way up: illusions and internal models in the vestibular system.},
  journal = {Nature Neuroscience},
  year = {1999},
  volume = {2},
  pages = {396--398}
}

@BOOKLET{capStat,
  title = {Manuale di statistica per la ricerca e la professione. Statistica
	univariata e bivariata, parametrica e non parametrica per le discipline
	ambientali e biologiche.},
  author = {L. Soliani},
  month = {aprile},
  year = {2005},
  note = {capitoli 11, 12 e 13}
}

@ARTICLE{Tresilian_perception,
  author = {J. R. Tresilian},
  title = {Analysis of recent empirical challenges to an account of interceptive
	timing.},
  journal = {Perception and Psychophysics},
  year = {1999},
  volume = {61},
  pages = {515--528}
}

@ARTICLE{Tresilian_trends,
  author = {J. R. Tresilian},
  title = { Visually timed action: Time-out for tau?},
  journal = {Trends in Cognitive Sciences},
  year = {1999},
  volume = {3},
  pages = {301--310}
}

@ARTICLE{Turvey,
  author = {M. T. Turvey and C. Carello},
  title = {The ecological approach to perceiving-acting.},
  journal = {Acta Psychologica},
  year = {1986},
  volume = {63},
  pages = {133--155}
}

@ARTICLE{Werkhoven,
  author = {P. Werkhoven and H. P. Snippe and A. Toet},
  title = {Visual processing of optic acceleration.},
  journal = {Vision Research},
  year = {1992},
  volume = {32},
  pages = {2313--2329}
}

@ARTICLE{Williams,
  author = {J. H. Williams and A. Whiten and T. Suddendorf and D. I. Perrett},
  title = {Imitation, mirror neurons and autism.},
  journal = {Neurosci Biobehav Rev},
  year = {2001},
  volume = {25},
  pages = {287--295},
  number = {4},
  month = {Jun},
  abstract = {Various deficits in the cognitive functioning of people with autism
	have been documented in recent years but these provide only partial
	explanations for the condition. We focus instead on an imitative
	disturbance involving difficulties both in copying actions and in
	inhibiting more stereotyped mimicking, such as echolalia. A candidate
	for the neural basis of this disturbance may be found in a recently
	discovered class of neurons in frontal cortex, 'mirror neurons'
	(MNs). These neurons show activity in relation both to specific
	actions performed by self and matching actions performed by others,
	providing a potential bridge between minds. MN systems exist in
	primates without imitative and 'theory of mind' abilities and we
	suggest that in order for them to have become utilized to perform
	social cognitive functions, sophisticated cortical neuronal systems
	have evolved in which MNs function as key elements. Early developmental
	failures of MN systems are likely to result in a consequent cascade
	of developmental impairments characterised by the clinical syndrome
	of autism.},
  keywords = {Autistic Disorder; Behavior; Humans; Neurons},
  owner = {Ale},
  pii = {S0149-7634(01)00014-8},
  pmid = {11445135},
  timestamp = {2007.03.13}
}

@ARTICLE{Wolpert_social,
  author = {Daniel M Wolpert and Kenji Doya and Mitsuo Kawato},
  title = {A unifying computational framework for motor control and social interaction.},
  journal = {Philos Trans R Soc Lond B Biol Sci},
  year = {2003},
  volume = {358},
  pages = {593--602},
  number = {1431},
  month = {Mar},
  abstract = {Recent empirical studies have implicated the use of the motor system
	during action observation, imitation and social interaction. In
	this paper, we explore the computational parallels between the processes
	that occur in motor control and in action observation, imitation,
	social interaction and theory of mind. In particular, we examine
	the extent to which motor commands acting on the body can be equated
	with communicative signals acting on other people and suggest that
	computational solutions for motor control may have been extended
	to the domain of social interaction.},
  doi = {10.1098/rstb.2002.1238},
  keywords = {Humans; Imitative Behavior; Interpersonal Relations; Models, Psychological;
	Social Behavior},
  owner = {Ale},
  pmid = {12689384},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1098/rstb.2002.1238}
}

@ARTICLE{Wolpert,
  author = {Daniel M. Wolpert and R. Chris Miall and Mitsuo Kawato },
  title = {Internal models in the cerebellum.},
  journal = {Trends in Cognitive Sciences },
  year = {1998},
  volume = {2},
  pages = {546--553},
  number = {9}
}

@ARTICLE{Lacquaniti,
  author = {M. Zago and G. Bosco and V. Maffei and M. Iosa and Y.P. Ivanenko
	and F. Lacquaniti},
  title = {Internal models of target motion: Expected dynamics overrides measured
	kinematics in timing manual interceptions.},
  journal = {Journal of Neurophysiology},
  year = {2004},
  volume = {91},
  pages = {1620--1634}
}

@ARTICLE{Zago_internal,
  author = {M. Zago and G. Bosco and V. Maffei and M. Iosa and Y. P. Ivanenko
	and F. Lacquaniti},
  title = {Fast Adaptation of the Internal Model of Gravity for Manual Interceptions:
	Evidence for Event-Dependent Learning.},
  journal = {Journal of Neurophysiology},
  year = {2005},
  volume = {93},
  pages = {1055--1068}
}

@ARTICLE{Lacquaniti_internal,
  author = {Myrka Zago and Francesco Lacquaniti},
  title = {Internal model of gravity for hand interception: parametric adaptation
	to zero-gravity visual targets on Earth.},
  journal = {J Neurophysiol},
  year = {2005},
  volume = {94},
  pages = {1346--1357},
  number = {2},
  month = {Aug},
  abstract = {Internal model is a neural mechanism that mimics the dynamics of an
	object for sensory motor or cognitive functions. Recent research
	focuses on the issue of whether multiple internal models are learned
	and switched to cope with a variety of conditions, or single general
	models are adapted by tuning the parameters. Here we addressed this
	issue by investigating how the manual interception of a moving target
	changes with changes of the visual environment. In our paradigm,
	a virtual target moves vertically downward on a screen with different
	laws of motion. Subjects are asked to punch a hidden ball that arrives
	in synchrony with the visual target. By using several different
	protocols, we systematically found that subjects do not develop
	a new internal model appropriate for constant speed targets, but
	they use the default gravity model and reduce the central processing
	time. The results imply that adaptation to zero-gravity targets
	involves a compression of temporal processing through the cortical
	and subcortical regions interconnected with the vestibular cortex,
	which has previously been shown to be the site of storage of the
	internal model of gravity.},
  doi = {10.1152/jn.00215.2005},
  keywords = {Adaptation, Physiological; Adult; Analysis of Variance; Female; Gravity
	Perception; Hand; Humans; Male; Models, Neurological; Photic Stimulation;
	Predictive Value of Tests; Probability; Psychomotor Performance;
	Signal Detection (Psychology); Time Factors; Time Perception; Visual
	Perception; Weightlessness},
  owner = {Ale},
  pii = {00215.2005},
  pmid = {15817649},
  timestamp = {2007.03.13},
  url = {http://dx.doi.org/10.1152/jn.00215.2005}
}

@ARTICLE{Zago,
  author = {Myrka Zago and Francesco Lacquaniti},
  title = {Review: Cognitive, perceptual and action-oriented representations
	of falling objects.},
  journal = {Neuropsychologia},
  year = {2005},
  volume = {43},
  pages = {178--188}
}

