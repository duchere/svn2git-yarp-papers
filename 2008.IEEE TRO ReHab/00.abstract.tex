The state-of-the-art in active (myoelectric) hand prosthetics is
rather poor if considered from the point of view of control by the
patient. The most advanced commercial prosthesis, that is Touch
Bionics's i-LIMB, has five degrees of freedom and can mimic a number
of human-like grips, but (a) no force control is provided, (b) the
patient has to learn how to drive the prosthesis to the required grip
in a totally innatural way. For instance, opening of the hand is
generally actuated using the remnant of the wrist flexor muscle.

In this paper we describe and discuss in detail the positive outcome
of an experiment in which three amputees were asked to train a machine
learning system in order to drive an advanced active hand prosthesis,
both (a) controlling its force and (b) naturally commanding the
required grip. We then expand briefly and discuss how this system
could be practically realised, miniaturised and embedded in a
prosthesis.

All in all we are proposing a framework for adaptive prosthetics, that
is a scenario in which, rather than having to learn how to use a
prosthesis, a patient will train it upon its own data, and enter a
positive feedback loop of reciprocal learning, which will lead to
shorter training times and a better quality of life.
