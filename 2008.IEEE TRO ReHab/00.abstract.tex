The state-of-the-art in active (myoelectric) hand prosthetics is
rather poor if considered from the point of view of control.
Even the most advanced commercial prostheses, gifted with
several degrees of freedom and able to mimic a number of human-like
grips, provide no force control and enforce non-natural feed-forward
actuation, so that the patient has to learn how to drive them from
scratch. For instance, closing the hand is generally actuated using
the remnant of the wrist flexor.

We hereby describe an experiment in which three amputees train a machine
learning system with surface electromyography signals, while asked to
imagine, with their missing hands, complex grip postures and different
degrees of force involved in the grip. Even though some patients have been
operated \emph{decades} ago, we show that they can still produce remarkably
distinct and precise signals for each grip and force value, therefore
potentially feed-forward controlling a dexterous active hand prosthesis
to a degree of finesse unknown so far.

This result hints at a scenario in
which prostheses adapt to the patient, entering a positive feedback loop
of reciprocal learning, leading to shorter training times and a better
quality of life for the patients.
