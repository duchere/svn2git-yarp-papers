
Infants and robots both face the challenge of perceiving and acting on
the world around them.  For infants, we evaluate how that challenge is
met through analysis; for robots, we engage in synthesis.  We expect
that there will be commonality between how infants and successful
robots operate at the information-processing level, because natural
environments are of mixed, inconstant observability -- there are
properties of the environment that can be perceived under some
circumstances and not under others.  This network of opportunities and
frustrations should place limits on information processing that apply
both to humans and robots with human-like sensors.

We identify opportunities that can be exploited by both robots and
infants to perceive properties of their environment that cannot be
directly perceived in other circumstances.  We review what is known of
how robots and infants can exploit such opportunities to learn to make
reasonable inferences of hidden object properties through correlations
with observable properties, grounding those inferences in prior
experience.

Topics:

\begin{itemize}

\item Object segregation --
  Infant research: Amy Needham.
  Robotics work: Paul Fitzpatrick and Giorgio Metta. ....

\item Intermodal integration --
  Infant resesarch: Lorraine Bahrick and Robert Lickliter.
  Robotics work: Artur Arsenio and Paul Fitzpatrick. ...

\item Object permanence --
  Infant resesarch: Scott Johnson.
  Robotics work: Yi Chen and Juyang Weng. ....

\end{itemize}


\subsection{Importance of motion?}

We are talking about the {\em development} of perception from an
immature form.  We assume that this development relies on acquiring
some information from the outside world (this isn't necessarily so).
How is this information acquired?  Sensory input is not 
uniformly difficult to interpret -- there are situations in
which it becomes simpler.  One particularly striking case is
the presence of motion.  Coherent group motion of part of the 
scene can be relatively easy to detect, and is a good cue for
the existence and extent of a corresponding object.  
So motion is one good place to start.
%
Moving objects are salient to infants and seem to play an
important role in perceptual learning (BACK THIS UP).
%
In robotics motion has frequently been used in all sorts of
ways.
%
Mention the technical status of motion detection versus
detection of other features (e.g. ``material'').
%
Of course this is by no means the end of the story, there 
are many other features... depth cues etc.

Egomotion is not very useful (relatively speaking).  Movemement of
others or caused by others is useful.  Motion caused by the robot
itself is particularly useful; this could be true of infants but is
moot given the limited motor control available initially.

\subsection{Preamble}

What is perception for?  One classic answer from robotics is that the
goal of perception is to recover, as faithfully as possible, the state
of the world.  That is, some model is made of the world, with some
number of free parameters, and the goal of perception is to find
values for those parameters to bring the model into as close an
alignment as possible with the world.

This view is my no means unquestioned; to achieve a particular
task, the most useful model to estimate may vary.  It may be
trivial, or the robot's behavior may be easier to produce or
describe in alternate ways that don't use the language of
model estimation.

In this paper, we will assume that the robot is engaged
in manipulation tasks (as opposed to, for example, navigation).

{\bf Behavioral view}: strategies that make it likely for the robot
to be looking somewhere useful (hand/eye coordination).
{\bf Model view}: ability to demonstrate flexible knowledge of presence of 
objects and some of their properties.


