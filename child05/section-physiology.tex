\subsection{View based vs. feature based}

There are two opposite theories that describe object recognition in the brain namely: view-based and the so-called structural description theory. The first posits that object recognition is carried out by the brain by analyzing and blending together multiple views of the same object. The latter presupposes an internal representation by which the visual data is remapped into a set of geometric primitives (e.g. geons and the like).

To exemplify the latter, recognition by components (RBC) is briefly considered, where object recognition is built through the mapping of certain visual features (e.g. an overcomplete set) into the identification of certain volumetric visuo-geometric primitives (the above mentioned geons) and eventually recognition is carried out by an invariant process of identification of these primitives.

In the view based approach instead various views are thought to be typically acquired by the brain and used ``almost raw'' to build the basis (also overcomplete) of a space. Recognition in this case is thought to be performed by mapping the actual visual input into this space. Each point in this vector space thus represents the object as seen from a particular view point (sort of).

The question of whether any of the two views is correct is still under debate. There are results supporting both models both in human and monkey.

Another part of our understanding of object recognition in the brain comes from considering feedforward and/or feedback circuits: there are, in fact, two possibilities here, the first considers only a fast feedforward loop which is believed to end up in activating high-level neurons that somewhat code for the recognition of a specific object. Certain results on the timing of visual recognition favor a similar hypothesis. There is an alternative based on the inclusion of feedback signals (which are known to exist in the brain). This theory is known as ``analysis by synthesis'' and basically says that several options are internally enacted by the brain and the one whose predictions are in agreement most with the perceived input is selected then leading to object recognition. Prediction error is used both to correct the current recognition in real-time and to tune the internal models by learning. Several results also support this possibility.

This is for what traditional object recognition is concerned. More recently neurophysiology has found a plethora of new and puzzling results (not so puzzling a posteriori). The pre-motor cortex (in the frontal lobe) seems to respond to the sight of objects. The more traditional view of the pre-motor cortex does not leave room for a visual (or sensory in general) response: a motor signal, area, cortex, etc. were considered as purely motor. The reality is somewhat different. Neurons in the pre-motor cortex respond to the fixation of objects and simultaneously they are truly motoric since they also respond to a grasping action directed at the same object. The two representations - motoric and visual - coexist in the same brain areas, even more so, in the same population of neurons.

Finally, similar responses have been found in the parietal cortex. This forms a conspicuous bi-directional connection with the pre-motor cortex so that it is possible to speak of the fronto-parietal system/circuit. Parietal neurons have been found that respond to geometric global object features (e.g. their orientation in 3D) which seem in fact well tuned for the control of action. But clearly the fronto-parietal circuitry is active also when an extant movement does not become an actual one. The natural question to be posed is then what is the purpose of this activation: potential motor action or true object recognition (Fadiga)?

Links to imitation, learning by imitation, and speech make the study of the fronto-parietal system extremely interesting both for neuroscience and robotics.

\subsection{Temporal lobe contribution}

The traditional circuitry believed to activate for object recognition is linked to the visual cortex (primary V1, extrastriate areas V2, V4) and then to the inferotemporal cortex (IT). The general properties of this pathway (known as the ventral pathway) see an ever increasing complexity of neural responses with an ever increasing size of the receptive fields: that is, while the specialization of neurons increase as considering the connections from V1, V2, V4, and IT, their spatial resolution decreases. It is like spatial invariance increases as the neural response specialize to recognition of certain objects (the total number of neurons remaining somewhat constant -- the order of magnitude at least). Eventually, there are results showing the extreme specialization to (important) objects like faces (cite) and hands (Perrett et al.).

The study of this pathway leading from the visual cortex to the IT lobule can be traced back to the seminal work of Hubel and Wiesel (cite), and subsequently to others (e.g. Perrett). They have shown that the hierarchy of the so-called ventral pathway for object recognition builds receptive fields (RF) of increasing robustness to various variations in the visual stimulus: e.g. scale, orientation. From the RF of V1 cells responding to oriented bars to the complexity of face and/or hand cells in IT (cite Perrett again). Other studies have shown (Perrett 93, Booth 98, Logothetis 95, Hietanen 92) that neurons have a preferred object view ``direction'' and show sensitivity to illumination.

[This section will include a more detailed description of certain specific results]


\subsection{Parietal object recognition}
Sakata et al. have studied the response of neurons in area AIP (anterior intra-parietal) and have found neurons that are sensitive to the 3D orientation of objects. Area AIP is known to connect bi-directionally with area F5 in the premotor cortex (see below). Others (Arbib) have interpreted (and modeled) these results by showing that the combination parietal and premotor responses might actually participate to the ``perception'' of object affordances: the combination of visual and motor properties that link perception to action.

[More results are available and details will be added here].


\subsection{Objects and action}

Ungerleider and Mishkin first proposed the theory that visual processing in the brain splits in two, specializing for localization (where, dorsal pathway) or recognizing (what, ventral pathway) the object. Milner and Goodale subsequently linked this theory to vision for action (the dorsal pathway) and vision for perception -- only -- (the ventral pathway). This is a useful distinction (and segregation of competences) that is dramatically shown in the case of stroke patients. For example, patient XY (described in Jeannerod 1995) suffered a parietal lesion and acted poorly when asked to grasp generic objects (e.g. cylinders), meaning that the ``action pathway'' was interrupted and proper judgment of the size/orientation of the object (for preshaping the hand) was impaired. Grasping of familiar objects was not affected since the object perception subsumes the experience of size and shape (but see the case of illusions -- cite). Agnosia was manifest in another patient YX with a lesioned temporal lobe who could perfectly grasp any object (as measured through preshaping) although she cannot recognize the identity of the grasped object nor judge certain aspects of shape.

In addition, the dorsal stream seems to be working almost oblivious of consciousness, while the ventral one is pretty much ``conscious''. That is, the action of grasping an object (and describing it in these terms) does not require conscious control (once initiated perhaps) while recognition with a semantic value (e.g. judging the identity of the objects) requires consciousness. Other differences include the purported shape of the circuit of object recognition. It is well know that feedback (bi-directional) connections are present in the fronto-parietal circuit, while it seems that the reaction times (150ms) of object recognition by IT do not leave much space for a role of feedback (at least not a direct one).

Armed with this theory we can now interpret object recognition in the brain as a multi-system recognizer. Objects seem to be represented in the brain by multiple processing procedures depending on the specific use of the information being processed (e.g. action vs. identification).

One particular and interesting class of neurons code for a combination of visual cues and motor actions that allow grasping the object: that is, the object identity (in grasping terms) is linked to the set of actions that can be applied to that same object. In other words, a population of neurons is sensitive to the affordances of objects - with respect to grasping/manipulation in this case. These neurons were identified in area F5 of the pre-motor cortex and respond precisely to the presentation of various object and to the actions that are likely to be applied to grasp these same objects (Sakata, Fadiga). Finally, links between F5 and IT are known to exist indirectly, thus, blending together again the information about objects, the manipulators (hands), the actors (faces) of certain actions.

More recently, a link between attention and feedback in the fronto-parietal circuit has been investigated (see Craighero et al. 2004). Grossly speaking, the theory goes by showing that attention is defective when objects are out of reach -- for example, because a limit of movement is reached. The explanation is that attention is built by the selective modulation of the visual processing on the basis of the current motor goal: that is, ``if I want to eat an apple, then visual processing is modulated so to enhance the chances of localizing/recognizing apples -- red, approximately round in shape, etc.''. This process seems to be implemented as descending (feedback) connections and form part of the cited fronto-parietal circuit.


\subsection{Relevance to robots}
[This section will be completed by including some important considerations for robotics -- see also \cite{metta03early}].

This work relates to the literature of multi-modal integration by adding yet another modality: that is, motor signals [elaborate on this]. 

