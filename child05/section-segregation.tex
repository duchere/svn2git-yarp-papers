

The world around us is made of objects, some of which can more or less
move independently. As adults, we can judge which parts of the world
are likely to move as a group. This is computationally a difficult
judgement to make, since regions grouped by easily-defined visual
features do not reliably correspond to physical groups. Robots and
infants could attempt to learn to make such judgements based on
experience. There is evidence of this in infants, and initial attempts
with robots.


The kinds of experiences infants and robots might learn from include a
wide range of The kinds of experiences a na\"{i}ve observer might find
useful in this regard are many and have not been well characterized.
However, it is clear that human infants do learn generic principles
for making educated guesses about which surfaces belong together as
part of the same unit and which do not.  By 4 to 5 months of age,
infants can parse simple displays into units based on something like
static gestalt principles, probably some subset of these (e.g.,
Needham, 1998, 2000).

Similar results have been obtained by researchers using partly
occluded objects (Johnson--+ display??)



Initial studies indicated that infants used some collection of
features to parse the displays (Needham, 1998; Needham, \& Baillargeon,
1997, 1998); subsequent studies suggested that object shape is the key
feature that young infants use to identify boundaries between adjacent
objects (Needham, 1999).



These principles may lead to many incorrect parsings, but they will
also provide reasonable best guess interpretations of uniform objects
in complex displays.  So, it might be that extensive amounts of
experience are required to `train up' this system.
However, it might also be that infants learn on the basis of
relatively few exposures to key events (Baillargeon, 1999).  This
possibility was investigated within the context of object segregation
by asking how infants' parsing of a display would be altered
by a brief prior exposure to one of the objects in the test display.



In this paradigm, a test display was used that was ambiguous to
4.5-month-old infants who had no prior experience with the display.
Prior experience was given that would help disambiguate the display
for infants.  This experience consisted of a brief prior exposure
(visual only) to a portion of the test display.  If infants used this
prior experience to help them parse the test display, they should see
the display as two separate objects and look relaibly longer when they
moved as a whole than when they move separately.  Alternately, if the
prior experience was ineffective in altering infants'
interpretation of the display, they should look about equally at the
display, just as the infants in the initial study with no particular
prior experience did (Needham \& Baillargeon, 1998).  Prior experiences
with either portion of the test display were effective in facilitating
infants' parsing of the test display.  However, when we
introduced changes between the box seen during familiarization and
that seen as part of the test display, an unexpected pattern emerged.
Nearly any change in the object's features introduced between
familiarization and test prevented infants from benefitting from this
prior experience.  So, even when infants saw a blue box with yellow
squares prior to testing, and the box used in testing had white
squares but was otherwise identical, they did not apply this prior
experience to the parsing of the test display.  However, infants did
benefit from the prior exposure when it was not in the features of the
object but rather in its orientation (Needham, 2001).  A change in the
orientation of the box from horizontally to vertically oriented led to
the facilitation in parsing seen in some prior experiments.  Thus,
infants even as young as 4.5- to 5-months of age know that to probe
whether they have seen an object before, they must attend to the
object's features rather than its spatial orientation
(Needham, 2001).

These results also support two additional conclusions.  First,
infants' object representations include detailed information
about the object's features.  Because infants'
application of their prior experience to the parsing of the test
display was so dependent on something close to an exact match between
the features, one much conclude that a highly detailed representation
is formed on the initial exposure and maintained during the
inter-trial-interval.  Because these features are remebered and used
in the absence of the initial item and in the presence of a different
item, this is strong evidence for infants' representational
abilities.  Secondly, 4.5-month-old infants are conservative
generalizers'they do not extend information from one object to
another very readily.  But would they extend information from a {\bf group}
of objects to a new object that is a member of that group?

This question was investigated by Needham, Dueker, \& Lockhead (2005)
in a study using the same test display and a similar procedure as in
Needham (2001).  Infants were given prior experiences with collections
of objects, no one of which was an effective cue to the composition of
the test display when seen prior to testing.  A set of three similar
objects seen simultaneously prior to test did facilitate 4.5-month-old
infants segregation of the test display.  But no subset of these three
objects seen prior to testing facilitated infants' segregation
of the test display.  Also, not just any three objects functioned in
this way -- sets that had no variation within them or that were
too different from the relevant test item provided no facilitation.
Thus, experience with multiple objects that are varied but that are
similar to the target item is important to infants' transfer
of their experience to the target display.



This finding was brought into the ``real'' world by investigating
infants' parsing of a test display consisting of a novel key
ring (Needham et al., submitted; see Figure X).  According to a strict
application of organizational principles using object features, the
display should be seen as composed of (at least) two separate
objects -- the keys on one side of the screen and the separate
ring on the other side.  However, to the extent that infants recognize
the display as a member of a familiar category -- key
rings -- they should group the keys and ring into a single unit
that should move as a whole.  Our findings indicate that by 8.5 months
of age, infants parse the display into a single unit, expecting the
keys and ring to move together.  Younger infants do not see the
display as a single unit, and instead parse the keys and ring into
separate units.  Infants of both ages parsed an altered display, in
which the identifiable portions of the key ring were hidden by
patterned covers, as composed of two separate units.  Together, these
findings provide evidence that the studies of controlled prior
exposure described in the previous section are consistent with the
process as it occurs under natural circumstances.  Infants'
ordinary experiences present them with multiple similar exemplars of
key rings, and these exposures build a representation that can then be
applied to novel (and yet similar) instances of the key ring category,
altering the interpretation that would come from featurally-based
principles alone.



\subsection{How does generalization change with development?}

Supporting a differentiation view of the development of
generalization, Bahrick's findings suggest that young (i.e.,
2-month-old) infants are more likely to generalize farther from the
specific experiences they received than infants just a few months
older (get citation).  This finding suggests that experience might
serve to initially narrow and then extend the range of stimuli over
which young children will generalize.

\subsection{Role of behavior in the development of these skills}

Infants do not come prepared to segregate objects into units that
adults would consider meaningful.  Rather, infants learn how object
features can be used to predict object boundaries.  More than twenty
years ago, Kellman \& Spelke (1983) suggested that infants may be born
with knowledge about solid, three-dimensional objects and that this
knowledge could help them interpret portions of a moving object as
connected to other portions that were moving in unison.  However, this
assertion was put to the test by Slater and his colleagues (19XX), a
test that resulted in a new conception of the neonate's visual
world.  Rather than interpreting common motion as a cue to object
unity, they interpreted the visible portions of a partly occluded
object as clearly separate from each other, even when undergoing
common motion.  This finding was important because it revealed one way
in which learning likely changes how infants interpret their visual
world.

Evidence from of one set of studies reveals that young
infants' difficulty in collecting the relevant information
from visual displays may limit their success in these tasks (Johnson \&
Aslin 1995, 1996, then Johnson's eye tracking stuff showing
that infants who look to the other side of the occluder, sampling
information from both sides of it, are the ones who perceive the
object parts as connected.  So, eye movements are an important factor
in this picture)

Although adjacent objects present a very similar kind of perceptual
problem (are these surfaces connected or not), the critical components
of success might be quite different.  Early work with adjacent objects
indicated that at 3 months of age, infants tend to group all touching
surfaces into a single unit (Kestenbaum, Termine, \& Spelke, 1987).
Subsequent experiments have revealed that soon after this point in
development, infants begin to analyze the perceptual differences
between adjacent surfaces and segregate surfaces with different
features (but not those with similar features) into separate units
(Needham 2000).  Although infants can use the boundary seam between
two objects as a source of information about the likely separation
between them (Kaufman \& Needham, submitted), other work comparing
boundary-occluded and fully visible versions of the same displays
suggests that boundary information is not the only information infants
use to parse the objects in a display (Needham, 1998).

These changes in perception do not occur in a vaccuum but rather in a
child who is also experiencing a range of other develomental changes.
One of these changes occurs in object
exploration -- infants' visual, oral, and manual
investigation of objects are showing huge improvements during this
same time period (Rochat, 1989).  Relations between infants'
tendency to explore objects more or less actively and their accurate
parsing of an object display has been shown (Needham, 2000), paving
the way for future studies of connections between object exploration
and object perception.




A central question:

\begin{quote}

How could perception change with experience?

\end{quote}





For young infants, common motion is an important cue for 
perception of object unity.  Others: alignment, good form,
depth cues.  Spatial separation.

Infants also use information about specific objects or
classes of objects to guide their judgement.  
NEEDHAM, CANTLON, \& ORMSBEE 2005.

Can use information from just one experience.

Reorganize based on: judgements based on fairly general
principles, versus judgements based on specific object
knowledge.

In robotics, work related to object segregation is quite
primitive.  It is strongly influenced by the field
of computer vision, where ``object segmentation'' is a classic,
much studied problem.  See FOO for a fuller review than we give
here.  Representative work in computer vision,
see eg Berkeley (Malik and co).

How is the problem formalized in vision?  We want a function
which maps a matrix of pixels to a matrix of labels, where
any pair of locations should have the same label if and
only if their pixels are from the same object.
This is not well-defined in general; for example, in some
circumstances a person and everything they wear should be
considered a single object, in other cases they to clothes
should be separated; every object is composed of smaller
objects, etc.

What is omitted from this formalization?

What other problems are addressed in computer vision that
are relevant?



