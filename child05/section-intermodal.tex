
We have talked about ``key events'' in which object boundaries are
easier to perceive.  In general, the ease with which any particular
object property can be estimated varies from situation to situation.
Robots and infants can exploit the easy times to learn statistical
correlates that are available in less clear-cut situations.  For
example, {\em cross-modal} signals are a particularly rich source of
correlates, and have been investigated in robotics and machine
perception.
% (especially lip movement during speech).
%
%
%Events in the world have complicated effects, and can often have
%a detectable impact on many of our senses.  Determining which
%components of what we sense are due to the same event can be a 
%difficult judgement to make.  %It is a useful exercise, though.
%(List reasons why)
%
Most events have components that are accessible through different
senses: A bouncing ball can be seen as well as heard; the position of
the observer's own hand can be seen and felt as it moves through the
visual field.  Although these perceptual experiences are clearly
separate from each other, composing separate `channels', we also
recognize meaningful correspondences between the input from these
channels.
%
%
How these channels are related
%
in humans 
%
is not entirely clear.  Different
approaches to the development of intermodal perception posit that
infants' sensory experiences are (a) unified at birth and must be
differentiated from each other over development, or (b) separated at
birth and must be linked through repeated pairings. Although the time
frame over which either of these processes would occur has not been
well defined, research findings do suggest that intermodal
correspondences are detected early in development.

On what basis do infants detect these correspondences?  Some of the
earliest work on this topic revealed that even newborn infants look
for the source of a sound \cite{butterworth76coordination} and by 4
months of age have specific expectations about what they should see
when they find the source of the sound \cite{spelke76infants}.  More recent
investigations of infants' auditory-visual correspondences have
identified important roles for synchrony and other amodal properties
of objects -- properties that can be detected across multiple
perceptual modalities.  An impact (e.g., a ball bouncing) provides
amodal information because the sound of the ball hitting the surface
is coincident with a sudden change in direction of the ball's path of
motion.  Some researchers have argued (Bahrick) that detection
and use of amodal object properties serves to bootstrap the use of
more idiosyncratic properties (e.g., the kind of sound made by an
object when it hits a surface).
%
%
Bahrick \& Lickliter
have shown that babies (and bobwhite quail) learn better and
faster from multimodal stimulation (see their
Intermodal Redundancy Hypothesis \cite{bahrick00intersensory}).

In robotics, amodal properties such as {\em location} have been
used~-- for example, sound localization can aid visual detection of a
talking person.  {\em Timing} has also been used.  
\citeasnoun{prince05synching} develop
specific models of audio-visual synchrony detection and
evaluates compatibility with infant performance.
\citeasnoun{arsenio05exploiting} exploit the specific timing cue 
of {\em regular repetition}
to form correspondences across sensor modalities.  
From an engineering perspective,
the redundant information supplied by repetition makes this
form of timing information easier to detect reliably 
than synchrony of a single event in the presence of background 
activity.  However, in the model of \citeasnoun{lewkowicz00development},
the ordering during infant development is opposite.
%
This suggests the engineers just haven't found a good enough algorithm,
or regular repetition just doesn't happen enough to be important.






