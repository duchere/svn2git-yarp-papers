TPAMI-2007-10-0718, "On-line Independent Support Vector Machines for Cognitive Systems"
Manuscript Type: Regular

Dear Dr. Francesco Orabona,

We now have reviews of your above referenced submission to IEEE Transactions 
on Pattern Analysis and Machine Intelligence. Copies of the review comments 
are enclosed.

Unfortunately, based on these reviews, the editor, Prof. Bernhard Scholkopf , 
is not able to recommend this submission for publication in its curent form. 
Based on the Associate Editor's report, the changes needed are significant 
enough to require another set of reviews.

You may resubmit your paper along with a summary of changes, but it will be 
treated as a NEW submission and given a new log number.  If you choose to 
resubmit your paper please refer to this original log number 
(TPAMI-2007-10-0718), and we will include your previous manuscript's history 
in it's files and forward the necessary information to the Editor-in-Chief 
and Associate Editor.  Although your paper will receive a new log number, it 
shall be treated as another major revision. Meaning, it will be assigned to 
the same associate editor and reviewers.

The manuscript will then undergo a new review process.  Dr. Scholkopf has the 
following comments for you:

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-
Editor: 1
Comments to the Author:
One reviewer recommends a resubmit, and the other two also indicate that even 
with the recommended changes, the contribution of this paper is unlikely be 
significant enough for publication in TPAMI.

Regarding the technical content of the paper, I do believe that it is useful, 
although I can see reviewer 2's point that the paper to some extent lacks 
focus (is it about cognitive systems, or about online SVMs).
I also agree that some of the ideas have been around for a while. For 
instance, the idea that given a kernel expansion, one can incrementally 
remove the one that's best approximated as a linear combination of the other 
ones (i.e. the one with minimal projection distance to the span of the other 
ones), has been stated already in Section 18.4 of reference [32] (btw, the 
order of the authors of that reference is incorrect). Another relevant piece 
of existing work to look at would be the Forgetron of Dekel et al.

If you decide to resubmit the paper, and if I get to handle it, I would try to 
send it to the same reviewers. My feeling, however, is that it would take a 
major rewrite and substantial experiments to convince them. Whichever way you 
decide, I wish you good luck and I want to encourage you to continue with 
this work and to publish it.
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-

We hope that you will find the comments from the reviewers to be useful in 
your future work.  If you have any questions, feel free to contact the Editor 
or the EIC.

As always, we appreciate that you chose to submit your work to TPAMI and we 
thank you for your interest in TPAMI.  We hope that you will continue to 
submit your work to TPAMI in the future.  If you have suggestions about the 
journal or the manuscript handling, feel free to send a note to the EIC or 
Associate EIC.

Sincerely,


Ms. Elaine Stephenson on behalf of Prof. Bernhard Scholkopf
IEEE Computer Society
10662 Los Vaqueros Circle
Los Alamitos, CA 90720-2513
USA
Phone: +714.821.8380
Fax: +714.821.9975
tpami@computer.org

=======================================Reviewer Comments






























*****************************************************************************
Reviewer: 1

Recommendation: Author Should Prepare A Major Revision For A Second Review

Comments:
The manuscript is well written and easy to read. The different sections are 
well introduced and the motivations of the authors are clearly expressed. 
Theoretical results are well referenced and appear to be correct and 
experimental results seem to be promising.

It would also have been interesting for the authors to compare their algorithm 
with an other online SVM: for example, LASVM for binary classification 
(bordes et al. "Fast Kernel Classifiers with Online and Active Learning" JMLR 
2005) or MIRA for the multiclass classification case (Crammer and 
Singer "Ultraconservative Online Algorithms for Multiclass Problems" JMLR 
2003). Perhaps these methods do not match the sparsity criteria required by 
the motivations of the authors, but comparing behavior of an online SVM with 
an other online SVM could be instructive. These algorithms should at least be 
cited in the paper.

In the experimental part many datasets have been used but only accuracies and 
number of support vectors are provided. As the authors expect to save 
training and test time with their algorithm it could be relevant to display 
training and test durations for the different experiments and to compare them 
with the speed of an other online SVM. This is important to validate the 
method.

This manuscript is finally quite close from the previously published paper. 
The main idea of selecting linear independent vectors was already there. The 
new theoretical results do not change the model (the subsection II.A 
explaining SVMs could even be reduced). The experimental part is exactly 
organised in the same way. That's why it would be interesting to present some 
new results (training, test times, value of the objective function, ...) and 
new comparisons (why not a kernelized perceptron.) and not only new datasets. 

For these reasons I recommend a major revision of the manuscript.
=================
1. Which category describes this manuscript?: Research/Technology

2. How relevant is this manuscript to the readers of this periodical? If you 
answer Not very relevant or Irrelevant please explain your rating under 
Public Comments below.: Relevant

1. Please evaluate the significance of the manuscript’s research 
contribution.: Fair  - Even with the recommended changes, the contribution of 
this paper is unlikely be significant enough for publication in TPAMI.

2.  Please explain how this manuscript advances this field of research and/or 
contributes something new to the literature. : The manuscript displays an 
on-line version of the SVM algorithm. Authors design their work for cognitive 
systems and in particular robot navigation and grasping recognition.

Their algorithm called OISVM can be trained on-line as it does not require to 
know the size of the training set and updates its solution after the study of 
each new vector.
OISVM uses an incremental procedure to recursively add new vectors to its 
working set followed by a classical SVM training phase.

The main interest of the algorithm as long as the main contribution of the 
manuscript is to check whether a vector is linearly independent to the matrix 
of basis vectors composing the working set before adding it.
Doing this provides a good way to obtain a solution with a small number of 
support vectors while not reducing generalization performances. Having less 
support vectors is thus interesting as it should reduce training and test 
times.
The manuscript provides empirical evidences of the efficiency of this approach 
on a variety of tasks.

3. Is the manuscript technically sound? In the Public Comments section, please 
provide detailed explanations to support your assessment: Appears to be - but 
didn't check completely

4. How thorough is the experimental validation (where appropriate)? Please 
discuss any shortcomings in the Public Comments section.: Lacking in some 
respects; some cases of interest not tested

1. Are the title, abstract, and keywords appropriate? If not, please comment 
in the Public Comments section.: Yes

2.  Does the manuscript contain sufficient and appropriate references?  Please 
comment and include additional suggested references in the Public Comments 
section.: Important references are missing; more references are needed

3.  Does the introduction state the objectives of the manuscript in terms that 
encourage the reader to read on? If not, please explain your answer in the 
Public Comments section.: Yes

4.  How would you rate the organization of the manuscript? Is it focused? 
Please elaborate with suggestions for reorganization in the Public Comments 
section.: Satisfactory

5. Please rate the readability of the manuscript. Explain your rating under 
Public Comments below. : Easy to read

6. How is the length of the manuscript?  If changes are suggested, please make 
explicit recommendations in the Public Comments section.: Should be trimmed a 
bit

Please rate the manuscript overall. Explain your choice.: Fair
***********************************************








































*****************************************************************************
Reviewer: 2

Recommendation: Revise and resubmit as “new”

Comments:
General comments:
-----------------

The paper presents an approach for on-line learning using SVM. The advantage 
of the approach is that the number of support vectors eventually stabilizes 
after a certain number of training examples are learned. 

The idea is good because it limits the number of data needed to be stored in a 
long-term learning process.

My main concern with respect the paper is its scope. The introduction of the 
paper is quite confusing an does not clarify which is the main goal of the 
paper. It is not clear for me if the approach presented is to solve general 
cognitive problems, or if it is a general solution for online learning, or if 
it is an improvement of a SVM.

From my point of view the work here presented has little to do with cognition. 
As it concentrates on SVM. If the scope of the paper was to solve cognition 
problems using this method (as the introduction suggests), then the paper 
should compare other different learning methods (not only SVM). 

If, on the other hand, the paper is presented as a solution for the general 
problem of on-line learning (as the introduction also suggests), then it 
should compare other methods for on-line learning (not only SVM). 

If, finally, the paper is an improvement with respect previous SVM-based 
on-line methods (like the ones described in [15] and [27]), then a more 
detailed comparison with them must be done.

I think the authors must concentrate in one of this aspects and rewrite the 
paper. They should motivate the paper best and give a clear goal. 



Specific comments:
------------------  


Section I
----------
Basic concepts are mixed in this section and the rest of the paper, mainly 
localization vs place recognition and. incremental vs online. 

Localization from the point of view of mobile robotics means to estimate the 
coordinates of the robot in an environment. Place recognition does not do 
this. 

Incremental learning does not mean on-line. In the first case the method can 
used batches of training examples each time. In on-line learning only example 
one is used each time. 

I think these different concepts must be clear at the beginning of the paper.

The requirements for an online methods are not clear. Issues (2), (3), (4) are 
general for all learning methods, not only on-line ones. It seems to me that 
authors mixed on-line with real time.

In page 4, the dicussion about online extensions for learning algorithms 
refers only to SVM. Either make this explicit, or give a more general 
dicussion with other methods.


Section II.A
--------------
Explain what "x" and "y" represent in an example. I suppose feature vector and 
label, respectively. But that must be always be explained.


Section III.A
-------------
Describe in more detailed what is a "basis" vector. This definition does not 
appear in Section II.A, but "basis" vectors are used to construct expression 
(11).

The sentence in lines 48-49 describing the notation is unclear. This can be 
problematic when reading the rest of the section.  


Section III.B
-------------
Pag 11, I think some commas are missed in the sentence in lines 23-27. It is 
unclear.

The authors talk about large and small values for \eta. Examples of its range 
can be useful.


Section III.C
-------------
Page 14, lines 20-21. I think the minimum number of iterations have to be 1, 0 
means no iterations.


Section III.D
-------------
The proposed method is only explained for the 2-class problem. I think a more 
detailed explanation about how this method generalizes to the case of 
multi-class extension is needed.  Is the complexity of training increased as 
we have more SVMs? Is the number of final support vectors similar in all the 
SVM when using ONE-to-ALL? Does the different SVM stabilize the number of 
support vectors at similar times?


Section IV
----------
I think a more detailed comparison between the method here presented and the 
methods in [15] and [27] is needed, since they present a similar solution. 

Paragraph 3 in page 15, the authors say they use all training examples at each 
iteration. This does not seem to be a good solution to issues (3) and (4) of 
your requirements for on-line learning methods explained in the introduction. 



Section V
---------

The implementation of the approach uses MATLAB, which is more slower than, for 
example C++. This contradicts issue (4) in the introduction. Some comments 
are needed here.

More details have to be given with respect LIBSVM. Which kind of 
implementation is it? Is an online SVM? Is it based on some of the related 
papers [15] or [27]? If not, how can you compare your approach with the ones 
in [15] or [27]?

In fig 1, different kernels are used for the different experiments. I assume 
this is to show that the improvement is valid for different kernels. In any 
case a short explanation would be of interest. 

Cross validation is used to find the best parameters.  I think, that is not 
on-line any more. Which are the training examples used for cross validation?

From my point of view, the difference with RSVM, although significant 
according to [48], are not very big. More comments are needed here.


Section V.B
-----------

The experiments of this section compare the proposed approach with the one in 
[26], and with batch methods. I think the methods to compare must be the same 
as in the previous section, where the authors compare with LIBSVM-2.

How do you estimate the values for \eta in these experiments? 


Section V.C
-----------

The structure of this subsection is totally different from the rest of the 
paper (materials and methods, data analysis, ...) It is adequate for a 
journal of medicine or biology, but not for this journal.  I think it must be 
rewritten.


Some Typos
----------
- Page 6, line 51. "be" repeated.
- Pag 8, "representer theorem" in lower case --> Pag 9,  "Representer Theorem" 
capitalized. Choose one.
- Pag 11, I think some commas are missed in the sentence in lines 23-27. It is 
unclear.
- Pag 16, line 40, "Authors" --> "authors"

====================
1. Which category describes this manuscript?: Research/Technology

2. How relevant is this manuscript to the readers of this periodical? If you 
answer Not very relevant or Irrelevant please explain your rating under 
Public Comments below.: Not very relevant

1. Please evaluate the significance of the manuscript’s research 
contribution.: Fair  - Even with the recommended changes, the contribution of 
this paper is unlikely be significant enough for publication in TPAMI.

2.  Please explain how this manuscript advances this field of research and/or 
contributes something new to the literature. : The main contribution of this 
paper is a method for on-line SVM, in which at some point the number of 
supports vectors maintan stable.

3. Is the manuscript technically sound? In the Public Comments section, please 
provide detailed explanations to support your assessment: Partially

4. How thorough is the experimental validation (where appropriate)? Please 
discuss any shortcomings in the Public Comments section.: Lacking in some 
respects; some cases of interest not tested

1. Are the title, abstract, and keywords appropriate? If not, please comment 
in the Public Comments section.: No

2.  Does the manuscript contain sufficient and appropriate references?  Please 
comment and include additional suggested references in the Public Comments 
section.: References are sufficient and appropriate

3.  Does the introduction state the objectives of the manuscript in terms that 
encourage the reader to read on? If not, please explain your answer in the 
Public Comments section.: Could be improved

4.  How would you rate the organization of the manuscript? Is it focused? 
Please elaborate with suggestions for reorganization in the Public Comments 
section.: Could be improved

5. Please rate the readability of the manuscript. Explain your rating under 
Public Comments below. : Readable - but requires some effort to understand

6. How is the length of the manuscript?  If changes are suggested, please make 
explicit recommendations in the Public Comments section.: About right

Please rate the manuscript overall. Explain your choice.: Fair

***************************************************







































*****************************************************************************

Reviewer: 3

Recommendation: Author Should Prepare A Major Revision For A Second Review

Comments:
Please see attached file.
=============
1. Which category describes this manuscript?: Research/Technology

2. How relevant is this manuscript to the readers of this periodical? If you 
answer Not very relevant or Irrelevant please explain your rating under 
Public Comments below.: Relevant

1. Please evaluate the significance of the manuscript’s research 
contribution.: Fair  - Even with the recommended changes, the contribution of 
this paper is unlikely be significant enough for publication in TPAMI.

2.  Please explain how this manuscript advances this field of research and/or 
contributes something new to the literature. : This manuscript tackles an 
interesting and challenging problem, which is the design of a tractable 
on-line implementation of one of the most common and well-performing 
classification techniques, namely Support Vector Machines (SVMs).

Please see attached file for further details.

3. Is the manuscript technically sound? In the Public Comments section, please 
provide detailed explanations to support your assessment: Partially

4. How thorough is the experimental validation (where appropriate)? Please 
discuss any shortcomings in the Public Comments section.: Lacking in some 
respects; some cases of interest not tested

1. Are the title, abstract, and keywords appropriate? If not, please comment 
in the Public Comments section.: Yes

2.  Does the manuscript contain sufficient and appropriate references?  Please 
comment and include additional suggested references in the Public Comments 
section.: References are sufficient and appropriate

3.  Does the introduction state the objectives of the manuscript in terms that 
encourage the reader to read on? If not, please explain your answer in the 
Public Comments section.: Yes

4.  How would you rate the organization of the manuscript? Is it focused? 
Please elaborate with suggestions for reorganization in the Public Comments 
section.: Satisfactory

5. Please rate the readability of the manuscript. Explain your rating under 
Public Comments below. : Easy to read

6. How is the length of the manuscript?  If changes are suggested, please make 
explicit recommendations in the Public Comments section.: About right

Please rate the manuscript overall. Explain your choice.: Fair
