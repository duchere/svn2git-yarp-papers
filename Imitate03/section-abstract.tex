
\abstract{
%
Imitative behavior requires a mapping between the action of another
and one's own action.  This is a challenging perceptual problem.  We
show how a robot can expand its perceptual abilities far beyond an
initial set of primitives by acquiring high-quality visual experience
within the context of a simple object manipulation activity.
%
The robot pokes objects and watches a human companion poke the same
objects, and uses motion cues to segment the object, its own arm, and
the human's hand.  
%
From the data collected, the robot learns about object motion and
recognition, about the appearance of the human hand, and 
can train up a low-level orientation filter not present in its
primitive set of filters.
%
The representation of objects and motion used is analogous to
canonical and mirror neurons, and so is fundamentally well suited
to imitation.
%
%
%
}
