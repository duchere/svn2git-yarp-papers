\section{Conclusions}
In this paper we have described the implementation of a reaching
behavior that integrates together an open loop and a closed 
loop controller. The open loop controller
allows the robot to perform faster movements and does not require visual 
feedback from the hand. When sight of the hand is available the closed
loop controller allows for precise positioning of the hand in the 
image plane. 

We describe an explorative strategy by which the robot autonomously 
acquires the forward motor map and the visual Jacobian transformations. 
Among the other things this strategy 
allows the estimation of the eye-to-hand visual Jacobian of the robot. 
The estimation of the Jacobian is a well studied task for which several 
solutions have been proposed \cite{Hosoda94versatile,Mansard06jacobian,
Lapreste04efficient}. None of these works, however, addresses the 
problem of the redundancy of both the head and the arm. In the experiments 
reported here the estimation of the Jacobian is performaed with good 
accuracy for a subset of the arm workspace and for 
\emph{different head postures}. We believe
this is an important contribution with respect to the state of the art.

We do not rely on any prior information about the 
kinematic structure of the robot. The only simplification was that we used 
a color marker to visually localize the hand of the robot. Our assumption
is that the hand localization/identification is a separate problem
that needs to be solved before learning reaching. Previous work
by the same and other authors have suggested procedures by which 
the robot could autonomously learn to solve this task 
(\cite{Natale05,edsinger06what}). It will be interesting to see
how these approaches can be integrated with the work described 
in this paper.
