\section{Results}
\label{sec:results}

In this section we describe the reaching performance obtained with 
the reaching controller described in the previous section. Within this context,
it is important to note that a formal definition of the performance 
index is a nontrivial task. 

If we were to consider a robot which operates in an highly structured
environment, the definition of the performance index would have been much easier. 
Specifically, for an industrial robot, the reaching task can be identified 
with the problem of positioning the hand accurately with respect to a world 
reference frame\footnote{Typical industrial robots do not use vision. Their 
grasping movement is the result of 3-D positioning the gripper exactly in the 
position where they know the object to be grasped will be positioned. The problem
of positioning the object is then left to the user.}. In this case, the reaching 
precision can be measured in terms of the distance between the desired and 
actual position of the hand in the world reference frame.
 
In our case, a similar performance index definition cannot be applied. James has not 
been designed to operate in an industrial scenario. Moreover, in our context, the definition of a reference 
frame fixed with respect to the external world does not play the same crucial 
role played in the industrial framework. In our mind, it is more important to 
precisely locate the hand with respect to the object than to precisely locate 
the hand in the external world frame. Therefore, our reaching performance index 
should measure the Cartesian distance between the object to be grasped and the final 
position of the hand. However, measuring this distance is not an easy task. In this section
we approximate the real distance with the (stereo) \emph{image plane distance}. Practically speaking, suppose the 
robot sees a target $\utarget$ to be grasped. Following our strategy, in order to reach the 
target we need to fixate it, i.e. $\utarget = 0$. Using the available sensor (i.e. vision) the best we can do to precisely reach the target is moving the hand to the fixation point, i.e. $
{\uhand} \longrightarrow 0$. Clearly, the image plane distance $\| \uhand - \utarget \|$ can be used as a rough estimate of the reaching precision, i.e. of the Cartesian distance between the target to be reached and the position of the hand. Specifically, assuming infinite resolution of the camera sensor, if $\| \uhand - \utarget\| = 0$ then the hand has exactly reached the target. In a more realistic case, when the image plane distance is null, we can only guarantee that the Cartesian target-hand distance is upper bounded by a quantity which depends only on the camera intrinsic parameters\footnote{
Computing this upper bound is out of the scope of this paper.}. 

\subsection{Open Loop}
The first attempt to reach the target consists in using (\ref{Eq:reaching2})
to choose the arm configuration $\q_{arm}$ which brings the hand to the center 
of the image planes. Clearly, if the forward 
kinematic function (\ref{Eq:forward}) were perfectly represented and if the target were reachable, we would have $\mathbf x_{hand} =  \mathbf x_{target}$, which implies that the target-hand Cartesian distance 
 is null (see Section \ref{sec:reaching} for details). Therefore, in this ideal case, the open loop 
 strategy already results in $\| \uhand - \utarget \| = 0$. In practice, the model 
 (\ref{Eq:forward}) cannot exactly represent the system kinematic\footnote{Part of the representational 
 errors are related to the way we have chosen the represent the kinematic function, in this case the
 so called Receptive Field Weighted Regression model. Part are due to the mechanical plays of the
 kinematic structure.}. Therefore, even tough we can find $\q_{arm}$ such that $\mathbf x_{hand}=
 \hat f_{arm}(\mathbf q_{arm})$ it is not guaranteed that after the movement execution 
 $\| \uhand - \utarget \| = 0$. Figure \ref{Fig:ImagePlaneOpenLoopErrors}
 shows the image plane errors after the execution of the open loop movement. The plot has been obtained
 by fixating a target and performing a series of open loop movements. Each open loop
 movement was different because (\ref{Eq:reaching2}) was solved 
 by choosing a different value $q_{20}$. Let us denote the open loop movements $\q_{arm}^1$, $\dots$, 
 $\q_{arm}^K$ such that:
 
 \begin{eqnarray} \label{Eq:OpenLoopMovements}
 \q_{arm}^k = \arg \min_{\mathbf q_{arm}}
  \left[
  \left\| \hat f_{arm}(\mathbf q_{arm}) - \mathbf x_{target}\right\|^2 + \left(q_{arm,2}-q_{20}^k\right)^2
  \right].
 \end{eqnarray}
 
 The above minimization is such that $\hat f_{arm}(\mathbf q_{arm}^k) = \mathbf x_{target}$. Ideally, in absence
 of modeling errors we would have $ \mathbf x_{hand} = \mathbf x_{target}$ since $\mathbf x_{hand} = f_{arm}(\mathbf q_{arm}^k)$. In practice we have $\mathbf x_{hand} \simeq \hat f_{arm}(\mathbf q_{arm})$ 
 so that we can only achieve an approximate reaching $ \mathbf x_{hand} \simeq \mathbf x_{target}$ 
 which reflects into small image plane errors $\| \uhand - \utarget\| \simeq 0$. Different choices 
 of the free variables $q_{20}^1$, $\dots$, $q_{20}^K$ lead to different image plane errors as shown 
 in Figure \ref{Fig:ImagePlaneOpenLoopErrors}.



\begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/LeftEyeOpenLoop.eps}}  & \hspace{2cm} &
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/RightEyeOpenLoop.eps}}
	  \\
	  \parbox{40mm}{\centering Left eye } & \hspace{2cm} & \parbox{40mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The figure shows the open loop image plane errors $\uhand$ for different
choices of the redundant variable $q_{20}$. For both pictures, on the horizontal axis 
we have $u_r$ and $u_l$ while on the vertical axis we have $v_r$ and $v_l$ (always in pixels).
In this specific case the target is in the middle of the two image planes 
$[u_{r, target}, v_{r, target}] =[0,0]$ and $[u_{l, target}, v_{l, target}]=[0,0]$.
The hand position in the image plane is instead represented 
by the small circles.  Each circle corresponds to the hand position 
after a different open loop movement, i.e. a different value of $q_{20}$.
}\label{Fig:ImagePlaneOpenLoopErrors}
  \end{figure}

\subsection{Closed Loop} \label{Sec:ResultsClosedLoop}

As we described in Section \ref{Eq:ClosedLoop} the residual image plane errors 
due to imperfections in the forward kinematic model can be reduced by a visual closed loop
control strategy. This control strategy moves the arm so as to progressively 
drive the hand position in the image planes ($\uhand$) to zero. Of course this is guaranteed 
only if the  Jacobian matrix has been learned in a sufficient accuracy. Figures 
\ref{Fig:ImagePlaneClosedLoopErrors}, \ref{Fig:TimeResponseClosedLoopErrors},  \ref{Fig:TimeResponseOpenClosedLoop} and \ref{Fig:TimeResponseOpenClosedLoopErrors} 
show how the hand is actually driven to the 
exact image center in both the image planes. Moreover, it is important to notice the
approximative linearity of the path followed by the hand. This linearity denotes 
a good accuracy of the learned Jacobian.

\newpage 
\subsection{Superimposed Open and Closed Loop}

Finally, we tested an alternative control strategy based on activating the closed loop 
phase immediately after the hand becomes visible on both image planes. This second strategy
is such that the open a closed loop strategies will be active at the same time for a 
certain period. The structure is based on a classical control scheme, which can be represented as follows:

\begin{figure*}[th!]
\begin{center}
\includegraphics[scale = 0.25]{Figure/OpenVSClosedLoop.eps}
\end{center}
\end{figure*}

Practically, the feedforward control corresponds to the open loop part of the reaching movement.
It is activated exactly as described in Section \ref{sec:openReaching} and therefore it does not
require the hand to be visible in the image plane. The feedback control
instead corresponds to the closed loop part of the movement and can be activated when the hand
has been localized in both the image planes. Practically, the final solution can be described by the 
following scheme:

\begin{figure*}[th!]
\begin{center}
\includegraphics[scale = 0.25]{Figure/OpenVSClosedLoopSwitch.eps}
\end{center}
\end{figure*}

Clearly, when both the open and closed loop controllers are active, the system receives position 
and velocity control simultaneously\footnote{A position command ${\mathbf q}_{arm,d}$ is 
always translated into a trajectory following command by moving 
the hand along a trajectory $\mathbf q_{arm}(t)$, $t \in [0, T]$ such that: $T$ is the execution time,
$\mathbf q_{arm}(0)$ is the arm position when the command is received, $\mathbf q_{arm}(T) = {\mathbf q}_{arm,d}$ is the desired final position. If a velocity command $\dot {\mathbf q}_{arm,d}$ is received while executing a position
command $\mathbf q_{arm}(t)$, the original velocity command is transformed into a different
one which takes into account the position command. In particular, the resulting commanded 
velocity is $\dot {\mathbf q}_{arm} = \dot {\mathbf q}_{arm}(t) + \dot {\mathbf q}_{arm, d}$.}. 

A comparison between this control strategy and the one proposed in Section \ref{Sec:ResultsClosedLoop}
is given in Figure \ref{Fig:TimeResponseOpenVSClosedLoopErrors} and \ref{Fig:TimeResponseOpenVSClosedLoop}. 
Performances are clearly improved. First the image plane movement (Figure \ref{Fig:TimeResponseOpenVSClosedLoopErrors})
is much more regular resulting in a unique linear movement instead of begin divided into two segments. Secondly, the
execution time is clearly reduced as it can be noted in Figure \ref{Fig:TimeResponseOpenVSClosedLoop}.

\begin{figure}[th!]
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/LeftEyeClosedLoop.eps}}  & \hspace{2cm} &
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/RightEyeClosedLoop.eps}}
	  \\
	  \parbox{40mm}{\centering Left eye } & \hspace{2cm} & \parbox{40mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The picture shows different closed loop control actions. Each trace correspond to a different Cartesian position of the target to be reached (which 
is always at the center of the image planes). The traces start exactly after the execution of the open loop movement, so that the initial position corresponds to the initial open loop error. Notice that all the traces end up in the image center (both left and right image planes) thus indicating that the visual errors are completely eliminated by the closed loop controller.}\label{Fig:ImagePlaneClosedLoopErrors}
  \end{figure}

\begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/TimeReponseLeftClosedLoop.eps}}  & \hspace{2cm} &
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/TimeReponseRightClosedLoop.eps}}
	  \\
	  \parbox{40mm}{\centering Left eye } & \hspace{2cm} & \parbox{40mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The picture shows the time response of the closed loop controller. The solid lines corresponds to the hand horizontal position in the left ($u_l$) and right ($u_r$) image planes. The dashed lines correspond to the vertical position, $v_l$ and $v_r$. Clearly, the hand is driven to the image center with a null steady state error. Even if velocity was not our primarily concern, the time response is reasonably fast (an error of thirty pixels is eliminated in about 
three seconds). }\label{Fig:TimeResponseClosedLoopErrors}
  \end{figure}


\begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/LeftEyeOpenClosedLoop.eps}}  & \hspace{2cm} &
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/RightEyeOpenClosedLoop.eps}}
	  \\
	  \parbox{40mm}{\centering Left eye } & \hspace{2cm} & \parbox{40mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The figure shows the movement of the hand on the image planes 
during the execution of different reaching actions. For both pictures, 
on the horizontal axis 
we have $u_r$ and $u_l$ while on the vertical axis we have $v_r$ and $v_l$ (always in pixels).
The traces correspond to the hand position during the movement. The solid line is the hand movement
during the closed loop phase. The dashed trace is instead the hand movement during the open loop 
phase. Clearly the open loop movement drives the hand to the target (the image centers) with a 
relatively small error. The closed loop phase reduces this error to zero.}\label{Fig:TimeResponseOpenClosedLoopErrors}
  \end{figure}
  
  \begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{50mm}{\includegraphics[width=40mm]{Figure/LeftEyeOpenClosedLoopTimeResponse.eps}}  & \hspace{2cm} &
	  \parbox{50mm}{\includegraphics[width=40mm]{Figure/RightEyeOpenClosedLoopTimeResponse.eps}}
	  \\
	  \parbox{50mm}{\centering Left eye } & \hspace{2cm} & \parbox{50mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The picture shows the time response of the closed loop and open loop strategy. The solid lines correspond to the hand horizontal position in the left ($u_l$) and right ($u_r$) image planes. The dashed lines correspond to the vertical position, $v_l$ and $v_r$. Remarkably, the open loop phase is faster but does not drive the hand exactly on the target. The closed loop is slower but more accurate.}\label{Fig:TimeResponseOpenClosedLoop}
  \end{figure}
  
  
  \begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/LeftEyeOpenVSClosedLoop.eps}}  & \hspace{2cm} &
	  \parbox{40mm}{\includegraphics[width=40mm]{Figure/RightEyeOpenVSClosedLoop.eps}}
	  \\
	  \parbox{40mm}{\centering Left eye } & \hspace{2cm} & \parbox{40mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The figure shows the movement of the hand on the image planes 
during the execution of a single reaching movement. For both pictures, 
on the horizontal axis 
we have $u_r$ and $u_l$ while on the vertical axis we have $v_r$ and $v_l$ (always in pixels).
The traces correspond to the hand position during the movement. The dashed line is the hand movement
during an open loop movement followed by a closed loop phase. The solid trace is instead the hand movement during 
the superposition of open and closed loop strategies. Clearly this second control architecture is more effective 
in terms of driving the hand directly to the target in spite of waiting the end of open loop movement.}\label{Fig:TimeResponseOpenVSClosedLoopErrors}
  \end{figure}
  
  \begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{50mm}{\includegraphics[width=40mm]{Figure/OpenVSClosedLoopTimeResponse1.eps}}  & \hspace{2cm} &
	  \parbox{50mm}{\includegraphics[width=40mm]{Figure/OpenVSClosedLoopTimeResponse2.eps}}
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The pictures show the time response of $u_l$ (left picture) and $v_l$ (right picture). The dashed line is the hand movement
during an open loop movement followed by a closed loop phase. The solid trace is instead the hand movement during 
the superposition of open and closed loop strategies. Remarkably, this second control architecture results in a faster response because when the hand becomes visible it is directly driven to the target without waiting for the open loop phase end.}\label{Fig:TimeResponseOpenVSClosedLoop}
  \end{figure}
  
  
    
  \begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\begin{tabular}{ccc}
	  \parbox{60mm}{\includegraphics[width=60mm]{Figure/RedundancyLeft.eps}}  & \hspace{1cm} &
	  \parbox{60mm}{\includegraphics[width=60mm]{Figure/RedundancyRight.eps}}
	  \\
	  \parbox{40mm}{\centering Left eye } & \hspace{1cm} & \parbox{40mm}{\centering Right eye }
	  %	  \end{t\\
	  %	Top view & & Lateral view
  \end{tabular}
\end{center}
\caption{The figure shows image plane movements during a three phase movement. First the open loop movement, then the closed loop movement and finally a movement in the null space of the given task (keeping the hand in fixations). Remarkably, there's a minor image plane movement (less then ten pixels) during the null space movement, thus indicating a very good jacobian estimation.}\label{Fig:RedundancyImagePlane}
  \end{figure}
  
  \begin{figure}
  % Requires \usepackage{graphicx}
  \begin{center}
	\includegraphics[width=80mm]{Figure/RedundancyArm.eps}
	\end{center}
\caption{The picture shows the arm movement corresponding to the image plane movements shown in Figure \ref{Fig:RedundancyImagePlane}. Remarkably, the null space movement is characterized by large joint movements which are however not visible in the image plane due to the jacobian based compensation.} \label{Fig:RedundancyArm}
  \end{figure}