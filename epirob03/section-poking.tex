
\section{Segmentation on a robot}

\label{sect:poking}


The most well-known instance of active perception is active vision.
The term ``active vision'' is essentially synonymous with moving
cameras.  Active vision work on Cog is oriented towards opening up the
potentially rich area of manipulation-aided vision, which is still
largely unexplored.
%
But there is much to be gained by taking advantage of the fact that
robots are actors in their environment, not simply passive observers.
They have the opportunity to examine the world using causality, by
performing probing actions and learning from the response.  
%This
%paper shows how active strategies can be used to ground operational
%definitions of entities that the robot cannot initially perceive,
%including objects, manipulators (both the robot's own arm and human
%hands), and even very low-level features such as orientation.  The
In conjunction with a developmental framework, this could allow the robot's
experience to expand outward from its sensors into its environment,
from its own arm to the objects it encounters, and from those objects
both back to the robot itself and outwards to other actors that
encounter those same objects.


As a concrete example of this idea,
Cog was given a simple ``poking'' behavior, whereby it selects
locations in its environment, and sweeps through
them with its arm~\cite[]{fitzpatrick02towards}.
%
If an object is within the area swept, then the motion signature
generated by the impact of the arm with that object greatly simplifies
segmenting that object from its background, and obtaining a reasonable
estimate of its boundary (see Figure~\ref{fig:separate-simple}).
%
The image processing involved
relies only on the ability to fixate the robot's gaze in the
direction of its arm.
This coordination is easy to achieve either as a hard-wired primitive
or through learning~\cite[]{fitzpatrick02towards}.  Within this context,
it is possible to collect excellent views of the objects the robot
pokes, and the robot's own arm.

%A robot (Cog) equipped with an arm and an active vision head was given a
%simple ``poking'' behavior, whereby it selected objects in its
%environment and struck them~\citep{fitzpatrick02towards}.

Since the robot had a limited reach,
this activity required the cooperation of a human
companion to bring the robot interesting objects to poke.
The behavior could also be preempted by the companion; when the robot
fixated an object and was about to reach for it, the companion
could choose to poke the object instead, in which case the robot
would refrain from acting.

This choice of activity has many benefits.  
%
{\em (i)}
The motion signature
generated by the impact of the arm with a rigid object greatly
simplifies segmenting that object from its background, and obtaining a
reasonable estimate of its boundary (see
Figure~\ref{fig:separate-simple}).  
This ``active segmentation''
procedure is key to automatically acquiring training data of
sufficient quality to support the many forms of learning described in
the remainder of this paper.
%
{\em (ii)}
The poking activity also leads to object-specific consequences, since
different objects respond to poking in different ways.  For example,
a toy car will tend to roll forward, while a bottle will roll along its
side.
%
{\em (iii)} The basic operation involved, striking objects, can be
performed by either the robot or its human companion, creating a
controlled point of comparison between robot and human action.


%Get lots of object segmentations, tracked motion.  
%Cluster them.  Now can differentiate between objects,
%can see how they respond to poking individually.
%
%At this point can support basic mimicry (figures?).



\begin{figure}[bt]
\includegraphics[width=\columnwidth]{fig-poking-schematic}\\
\includegraphics[width=\columnwidth]{fig-separate-simple}
\caption
{
\label{fig:separate-simple}
%
Cartoon motivation (top) for active segmentation (bottom).
Human vision is excellent at figure/ground separation (top left),
but machine vision is not (top center).  Coherent motion is a 
powerful cue (top right) and the robot can invoke it by 
simply reaching out and poking around.  
The lower row of images
show the processing steps involved.  The moment of impact between
the robot arm and an object, if it occurs, is
easily detected~-- and then
the total motion after contact, when compared to the motion before
contact and grouped using a minimum cut approach, gives a very
good indication of the object boundary. %%~\protect\cite[]{}.
Active segmentation.  The robot arm is deliberately driven
to collide with an object.
 The
apparent motion after contact, when masked by the motion before
contact, identifies a seed foreground (object) region.  Such motion
will generally contain fragments of the arm and environmental motion
that escaped masking.  Motion present before contact is used to
identify background (non-object) regions.  
An optimal object region is computed from the foreground and
background information using graph cuts~\citep{boykov01experimental}.
%
%This prevents the region
%assigned to the object motion from growing to include these fragments.
%The largest connected region, with a minor post-processing clean-up,
%is taken as the official segmentation of the object.
%
}
\end{figure}

