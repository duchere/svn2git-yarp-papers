In previous work \cite{2008.ICRA,2008.BioCyb} we have shown that
forearm surface electromyography (EMG) can be effectively used to
control a dexterous mechanical hand, thus laying the basis of
EMG-based control of polyarticulate hand prostheses, such as, e.g.,
Touch Bionics's i-LIMB hand. Forearm surface EMG is relatively cheap
and totally non-invasive, thus avoiding the problems normally
associated to surgical prosthetics.

So far, the analysis has been concerned with one subject only, fully
able-bodied, and in highly controlled conditions, i.e., with the arm
relaxed and still on a table. In this paper we carry the analysis on
and solve some of the problems left open in the aforementioned
paper. Namely, we describe the outcome of a similar experiment, in
which the task was to press a force sensor in different grasping
ways. In this experiment however, $10$ healthy subjects participated,
and they were also left free to walk, raise their hands and arms, sit
down and stand up, etc., as a patient is supposed to do during
Daily-Life Activities. The experiment reveals that machine learning
techniques such as Support Vector Machines are able to achieve
excellent results in this situation, too.

We also propose a cross-subject model analysis, i.e., training a model
on a subject and testing it on another one, which reveals that a
certain degree of cross-subject compatibility is present. This hints
at the possibility of pre-building a ``common'' model, which could be
shipped along with the prosthesis (rather than having to train it from
scratch) thus shortening the patient's training time.
